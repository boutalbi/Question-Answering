{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1. DrQA - Document reader Question Answering.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dksifoua/Question-Answering/blob/master/1.%20DrQA%20-%20Document%20reader%20Question%20Answering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwsiprY7pMVw",
        "outputId": "518819c6-5e69-4d4a-c356-c8fc9e6e629d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Oct 19 09:15:07 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.23.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_h9hVHEzrilz"
      },
      "source": [
        "## Load Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5F9JhdaNrVUs"
      },
      "source": [
        "!pip install tqdm --upgrade >> /dev/null 2>&1\n",
        "!pip install torchtext --upgrade >> /dev/null 2>&1\n",
        "!pip install spacy --upgrade >> /dev/null 2>&1\n",
        "!python -m spacy download en >> /dev/null 2>&1"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLfWd1KErkbM"
      },
      "source": [
        "import re\n",
        "import json\n",
        "import tqdm\n",
        "import spacy\n",
        "import string\n",
        "import warnings\n",
        "import collections\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchtext.data import Dataset, Example, Field\n",
        "from torchtext.data.iterator import BucketIterator"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atwALYPxr89L",
        "outputId": "6082d6bc-5028-47fa-d56d-4dba12f44c7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "warnings.simplefilter(action='ignore', category=UserWarning)\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
        "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
        "\n",
        "SEED = 546\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Device: {DEVICE}')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BauDCqB6sI0t"
      },
      "source": [
        "## Prepare Data\n",
        "\n",
        "***Donwload data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4g2TLNTyr9YE",
        "outputId": "bfe9f38d-19e8-4bbc-f395-552d9ce26ff3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "%%time\n",
        "!mkdir -p ./data\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    https://worksheets.codalab.org/rest/bundles/0x7e0a0a21057c4d989aa68da42886ceb9/contents/blob/ \\\n",
        "    -O ./data/train.json\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    https://worksheets.codalab.org/rest/bundles/0x8f29fe78ffe545128caccab74eb06c57/contents/blob/ \\\n",
        "    -O ./data/valid.json"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-19 09:15:36--  https://worksheets.codalab.org/rest/bundles/0x7e0a0a21057c4d989aa68da42886ceb9/contents/blob/\n",
            "Resolving worksheets.codalab.org (worksheets.codalab.org)... 40.114.41.203\n",
            "Connecting to worksheets.codalab.org (worksheets.codalab.org)|40.114.41.203|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Syntax error in Set-Cookie: codalab_session=\"\"; expires=Thu, 01 Jan 1970 00:00:00 GMT; Max-Age=-1; Path=/ at position 70.\n",
            "Length: unspecified [application/json]\n",
            "Saving to: ‘./data/train.json’\n",
            "\n",
            "./data/train.json       [      <=>           ]  28.88M  24.3MB/s    in 1.2s    \n",
            "\n",
            "2020-10-19 09:15:38 (24.3 MB/s) - ‘./data/train.json’ saved [30288272]\n",
            "\n",
            "--2020-10-19 09:15:38--  https://worksheets.codalab.org/rest/bundles/0x8f29fe78ffe545128caccab74eb06c57/contents/blob/\n",
            "Resolving worksheets.codalab.org (worksheets.codalab.org)... 40.114.41.203\n",
            "Connecting to worksheets.codalab.org (worksheets.codalab.org)|40.114.41.203|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Syntax error in Set-Cookie: codalab_session=\"\"; expires=Thu, 01 Jan 1970 00:00:00 GMT; Max-Age=-1; Path=/ at position 70.\n",
            "Length: unspecified [application/json]\n",
            "Saving to: ‘./data/valid.json’\n",
            "\n",
            "./data/valid.json       [   <=>              ]   4.63M  9.94MB/s    in 0.5s    \n",
            "\n",
            "2020-10-19 09:15:39 (9.94 MB/s) - ‘./data/valid.json’ saved [4854279]\n",
            "\n",
            "CPU times: user 16.4 ms, sys: 19.4 ms, total: 35.8 ms\n",
            "Wall time: 2.95 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4NvE3J_sRgM"
      },
      "source": [
        "***Load data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Igx9jwwisO4a"
      },
      "source": [
        "def load_json(path):\n",
        "    with open(path, mode='r', encoding='utf-8') as file:\n",
        "        return json.load(file)['data']"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0ykhvuHsTwD",
        "outputId": "27d847c5-3d8c-49d8-c268-9331dd15f66a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "train_raw_data = load_json(path='./data/train.json')\n",
        "valid_raw_data = load_json(path='./data/valid.json')\n",
        "print(f'Length of raw train data: {len(train_raw_data):,}')\n",
        "print(f'Length of raw valid data: {len(valid_raw_data):,}')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of raw train data: 442\n",
            "Length of raw valid data: 48\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzmme91esbmW"
      },
      "source": [
        "***Parse data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6L4v8MI2sZJ6"
      },
      "source": [
        "def parse_json(data):\n",
        "    qas = []\n",
        "    for paragraphs in data:\n",
        "        for para in paragraphs['paragraphs']:\n",
        "            for qa in para['qas']:\n",
        "                for ans in qa['answers']:\n",
        "                    qas.append({\n",
        "                        'id': qa['id'],\n",
        "                        'context': para['context'],\n",
        "                        'question': qa['question'],\n",
        "                        'answer': ans['text'],\n",
        "                        'answer_start': ans['answer_start'],\n",
        "                    })\n",
        "    return qas"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KO8fIMPHso_k",
        "outputId": "97aed03e-11eb-4720-96e2-2a541c98c885",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "train_qas = parse_json(train_raw_data)\n",
        "valid_qas = parse_json(valid_raw_data)\n",
        "print(f'Length of train qa pairs: {len(train_qas):,}')\n",
        "print(f'Length of valid qa pairs: {len(valid_qas):,}')\n",
        "\n",
        "print('Id:', train_qas[0]['id'])\n",
        "print('Context:', train_qas[0]['context'])\n",
        "print('Question:', train_qas[0]['question'])\n",
        "print('Answer starts at:', train_qas[0]['answer_start'])\n",
        "print('Answer:', train_qas[0]['answer'])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of train qa pairs: 87,599\n",
            "Length of valid qa pairs: 34,726\n",
            "Id: 5733be284776f41900661182\n",
            "Context: Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\n",
            "Question: To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?\n",
            "Answer starts at: 515\n",
            "Answer: Saint Bernadette Soubirous\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmDA7j8NtB3v"
      },
      "source": [
        "for i in range(len(train_qas)): # Test answer_start are correct in train set\n",
        "    assert train_qas[i]['answer'] == train_qas[i]['context'][train_qas[i]['answer_start']:train_qas[i]['answer_start'] + len(train_qas[i]['answer'])]\n",
        "\n",
        "for i in range(len(valid_qas)): # Test answer_start are correct in validation set\n",
        "    assert valid_qas[i]['answer'] == valid_qas[i]['context'][valid_qas[i]['answer_start']:valid_qas[i]['answer_start'] + len(valid_qas[i]['answer'])]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDmhP4kUvvD9"
      },
      "source": [
        "***Add targets***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0x5HTy7tRlT"
      },
      "source": [
        "def add_targets(qas, nlp=spacy.load('en')):\n",
        "    for qa in tqdm.tqdm(qas):\n",
        "        context = nlp(qa['context'], disable=['parser','tagger','ner'])\n",
        "        answer = nlp(qa['answer'], disable=['parser','tagger','ner'])\n",
        "        ans_start = qa['answer_start']\n",
        "        for i in range(len(context)):\n",
        "            if context[i].idx == ans_start:\n",
        "                ans = context[i:i + len(answer)]\n",
        "                qa['target'] = (ans[0].i, ans[-1].i)\n",
        "                break"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0Yaahbfv4RQ",
        "outputId": "9f975dd0-2117-4bbc-c410-21341f92a6d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "add_targets(train_qas)\n",
        "add_targets(valid_qas)\n",
        "print()\n",
        "print(f'Length of train qa pairs: {len(train_qas):,}')\n",
        "print(f'Length of valid qa pairs: {len(valid_qas):,}')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 87599/87599 [01:22<00:00, 1065.65it/s]\n",
            "100%|██████████| 34726/34726 [00:34<00:00, 997.19it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Length of train qa pairs: 87,599\n",
            "Length of valid qa pairs: 34,726\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sqv15GeYv_a3"
      },
      "source": [
        "def filter_qas(qa, nlp=spacy.load('en')):\n",
        "    if 'target' in [*qa.keys()]:\n",
        "        context = nlp(qa['context'], disable=['parser','tagger','ner'])\n",
        "        start, end = qa['target']\n",
        "        return context[start:end+1].text == qa['answer']\n",
        "    return False"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvu5BeNWwC6R",
        "outputId": "176250a2-e1bc-493f-a571-f2e4be2d023a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "%%time\n",
        "train_qas = [*filter(filter_qas, train_qas)]\n",
        "valid_qas = [*filter(filter_qas, valid_qas)]\n",
        "print(f'Length of train qa pairs after filtering out bad qa pairs: {len(train_qas):,}')\n",
        "print(f'Length of valid qa pairs after filtering out bad qa pairs: {len(valid_qas):,}')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of train qa pairs after filtering out bad qa pairs: 86,597\n",
            "Length of valid qa pairs after filtering out bad qa pairs: 34,295\n",
            "CPU times: user 1min 46s, sys: 329 ms, total: 1min 46s\n",
            "Wall time: 1min 46s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FiohtqEwIww"
      },
      "source": [
        "def test_targets(qas, nlp=spacy.load('en')):\n",
        "    for qa in tqdm.tqdm(qas):\n",
        "        if 'target' in [*qa.keys()]:\n",
        "            context = nlp(qa['context'], disable=['parser','tagger','ner'])\n",
        "            start, end = qa['target']\n",
        "            assert context[start:end + 1].text == qa['answer']"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qb7D_8RAwLka",
        "outputId": "d30430dd-d424-4516-ac47-9932972329d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "test_targets(train_qas)\n",
        "test_targets(valid_qas)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 86597/86597 [01:19<00:00, 1083.27it/s]\n",
            "100%|██████████| 34295/34295 [00:31<00:00, 1079.06it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwLcpPyEx9h1"
      },
      "source": [
        "***Add features***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSY0WXF9yAe0"
      },
      "source": [
        "def add_features(qas, nlp=spacy.load('en')):\n",
        "    for qa in tqdm.tqdm(qas):\n",
        "        question = [token.text for token in nlp(qa['question'], disable=['parser','tagger','ner'])]\n",
        "        context = nlp(qa['context'], disable=['parser'])\n",
        "        qa['pos'], qa['ner'] = zip(*map(lambda token: (token.tag_, token.ent_type_ if token.ent_type_ != '' else 'None'), context))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHLsz3Qh1p81",
        "outputId": "81b9d6a3-4d61-40bc-a4e4-f3cdc7984169",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "add_features(train_qas)\n",
        "add_features(valid_qas)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 86597/86597 [18:04<00:00, 79.82it/s]\n",
            "100%|██████████| 34295/34295 [07:25<00:00, 76.90it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnmJYtVBwRMz"
      },
      "source": [
        "***Build datasets***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tukx3UoIwQzg"
      },
      "source": [
        "ID = Field(tokenize=None, batch_first=True)\n",
        "POS = Field(tokenize=None, batch_first=True)\n",
        "NER = Field(tokenize=None, batch_first=True)\n",
        "TEXT = Field(lower=True, tokenizer_language='en', tokenize='spacy', batch_first=True)\n",
        "TARGET = Field(sequential=False, use_vocab=False, batch_first=True)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aj5cpRtC3ucE",
        "outputId": "5350ecb1-7fd4-4b3f-81f9-1230da4b69fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "train_dataset = Dataset([Example.fromdict(data=qa, fields={\n",
        "    'id': ('id', ID),\n",
        "    'context': ('cxt', TEXT),\n",
        "    'question': ('qst', TEXT),\n",
        "    'answer': ('ans', TEXT),\n",
        "    'pos': ('pos', POS),\n",
        "    'ner': ('ner', NER),\n",
        "    'target': ('trg', TARGET)\n",
        "}) for qa in tqdm.tqdm(train_qas)], fields={\n",
        "    'id': ID,\n",
        "    'cxt': TEXT,\n",
        "    'qst': TEXT,\n",
        "    'ans': TEXT,\n",
        "    'pos': POS,\n",
        "    'ner': NER,\n",
        "    'trg': TARGET\n",
        "})\n",
        "\n",
        "valid_dataset = Dataset([Example.fromdict(data=qa, fields={\n",
        "    'id': ('id', ID),\n",
        "    'context': ('cxt', TEXT),\n",
        "    'question': ('qst', TEXT),\n",
        "    'answer': ('ans', TEXT),\n",
        "    'pos': ('pos', POS),\n",
        "    'ner': ('ner', NER),\n",
        "    'target': ('trg', TARGET)\n",
        "}) for qa in tqdm.tqdm(valid_qas)], fields={\n",
        "    'id': ID,\n",
        "    'cxt': TEXT,\n",
        "    'qst': TEXT,\n",
        "    'ans': TEXT,\n",
        "    'pos': POS,\n",
        "    'ner': NER,\n",
        "    'trg': TARGET\n",
        "})\n",
        "print()\n",
        "print(f'Length of train dataset: {len(train_dataset.examples):,}')\n",
        "print(f'Length of valid dataset: {len(valid_dataset.examples):,}')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 86597/86597 [01:54<00:00, 757.59it/s]\n",
            "100%|██████████| 34295/34295 [00:47<00:00, 715.84it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Length of train dataset: 86,597\n",
            "Length of valid dataset: 34,295\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVG7DeCS5VDL",
        "outputId": "c08f0b1f-d151-49b1-f327-cbebee9e0a04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "ID.build_vocab([*map(lambda x: x.id, train_dataset.examples)] + [*map(lambda x: x.id, valid_dataset.examples)])\n",
        "TEXT.build_vocab(train_dataset)\n",
        "POS.build_vocab(train_dataset)\n",
        "NER.build_vocab(train_dataset)\n",
        "print(f'Length of ID vocabulary: {len(ID.vocab):,}')\n",
        "print(f'Length of TEXT vocabulary: {len(TEXT.vocab):,}')\n",
        "print(f'Length of POS vocabulary: {len(POS.vocab):,}')\n",
        "print(f'Length of NER vocabulary: {len(NER.vocab):,}')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of ID vocabulary: 97,108\n",
            "Length of TEXT vocabulary: 91,446\n",
            "Length of POS vocabulary: 52\n",
            "Length of NER vocabulary: 21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4sUa7385vZ-"
      },
      "source": [
        "***Download pretrained GloVe embedding***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0j7q5s55xX4",
        "outputId": "c2c01b83-8fc5-4947-a9c1-0457bf85651a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "%%time\n",
        "!wget --no-check-certificate \\\n",
        "    http://nlp.stanford.edu/data/glove.840B.300d.zip \\\n",
        "    -O ./data/glove.840B.300d.zip\n",
        "!unzip -q ./data/glove.840B.300d.zip -d ./data\n",
        "!rm -r ./data/glove.840B.300d.zip"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-19 09:49:36--  http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.840B.300d.zip [following]\n",
            "--2020-10-19 09:49:37--  https://nlp.stanford.edu/data/glove.840B.300d.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip [following]\n",
            "--2020-10-19 09:49:37--  http://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2176768927 (2.0G) [application/zip]\n",
            "Saving to: ‘./data/glove.840B.300d.zip’\n",
            "\n",
            "./data/glove.840B.3 100%[===================>]   2.03G  2.14MB/s    in 16m 54s \n",
            "\n",
            "2020-10-19 10:06:31 (2.05 MB/s) - ‘./data/glove.840B.300d.zip’ saved [2176768927/2176768927]\n",
            "\n",
            "CPU times: user 2.96 s, sys: 741 ms, total: 3.71 s\n",
            "Wall time: 18min 46s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKGPiljI55eO"
      },
      "source": [
        "def load_glove(path):\n",
        "    glove = {}\n",
        "    with open(path, mode='r', encoding='utf-8') as file:\n",
        "        for line in tqdm.tqdm(file):\n",
        "            values = line.split(' ')\n",
        "            glove[values[0]] = np.asarray(values[1:], dtype='float32')\n",
        "        return glove"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YO2dEmr258Mg",
        "outputId": "ab80cb21-8625-46a9-da1c-3cad3b8bd4b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "%%time\n",
        "glove = load_glove(path='./data/glove.840B.300d.txt')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2196017it [02:45, 13297.81it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2min 38s, sys: 5.92 s, total: 2min 44s\n",
            "Wall time: 2min 45s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGJghoCy5-8x"
      },
      "source": [
        "def load_embeddings(glove, field, embedding_size=300, most_common=1000):\n",
        "    most_common_words, most_common_indexes = [*map(lambda x: x[0], field.vocab.freqs.most_common(most_common))], []\n",
        "    embedding_matrix = np.zeros((len(field.vocab), embedding_size))\n",
        "    n_words = 0\n",
        "    for index, word in tqdm.tqdm(enumerate(field.vocab.freqs), total=len(field.vocab)):\n",
        "        if word in most_common_words:\n",
        "            most_common_indexes.append(index)\n",
        "        try:\n",
        "            embedding_matrix[index] = glove[word]\n",
        "            n_words += 1\n",
        "        except KeyError:\n",
        "            pass\n",
        "    return embedding_matrix, n_words, most_common_indexes"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SrTMgXs6BLH",
        "outputId": "648344b4-04dd-473d-ce2f-f3a2bca44927",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "embedding_matrix, n_words, most_common_indexes = load_embeddings(glove, TEXT)\n",
        "print(f'\\nWords found: {n_words}/{len(TEXT.vocab)}')\n",
        "np.save('./data/GloVe_DrQA.npy', embedding_matrix)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 91444/91446 [00:01<00:00, 51354.74it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Words found: 64754/91446\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlaFbXfvPoB5"
      },
      "source": [
        "# Free up the RAM\n",
        "del glove\n",
        "del embedding_matrix"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6o2SPOFH6E9d"
      },
      "source": [
        "## Modeling\n",
        "\n",
        "***Stacked Bidirectional LSTM Layer***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdYGHa6t6JLy"
      },
      "source": [
        "class StackedBiLSTMsLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, n_layers, dropout):\n",
        "        super(StackedBiLSTMsLayer, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.lstms = nn.ModuleList([nn.LSTM(input_size if i == 0 else hidden_size * 2, hidden_size,\n",
        "                                            num_layers=n_layers, bidirectional=True) for i in range(n_layers)])\n",
        "    \n",
        "    def forward(self, inputs):\n",
        "        \"\"\"\n",
        "        :param Tensor[batch_size, seq_len, input_size] inputs\n",
        "        :return Tensor[batch_size, seq_len, hidden_size * n_layers * 2]\n",
        "        \"\"\"\n",
        "        outputs = [inputs]\n",
        "        for lstm in self.lstms:\n",
        "            out, _ = lstm(self.dropout(outputs[-1])) # [batch_size, seq_len, hidden_size * 2]\n",
        "            outputs.append(out)\n",
        "        return self.dropout(torch.cat(outputs[1:], dim=-1))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hA_h6tl-JlV"
      },
      "source": [
        "***Aligned Question Embedding Layer***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDF-OkXw-PaK"
      },
      "source": [
        "class AlignQuestionEmbeddingLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden_size):\n",
        "        super(AlignQuestionEmbeddingLayer, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.linear = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, cxt_embed, qst_embed, qst_mask):\n",
        "        \"\"\"\n",
        "        :param Tensor[batch_size, cxt_len, embedding_size] cxt_embded\n",
        "        :param Tensor[batch_size, qst_len, embedding_size] qst_embed\n",
        "        :param Tensor[batch_size, qst_len] qst_mask\n",
        "        :return Tensor[batch_size, cxt_len, hidden_size]\n",
        "        \"\"\"\n",
        "        cxt_embed = F.relu(self.linear(cxt_embed)) # [batch_size, cxt_len, hidden_size]\n",
        "        qst_embed = F.relu(self.linear(qst_embed)) # [batch_size, qst_len, hidden_size]\n",
        "        scores = torch.bmm(cxt_embed, qst_embed.transpose(-1, -2)) # [batch_size, cxt_len, qst_len]\n",
        "        scores = scores.masked_fill(qst_mask.unsqueeze(1) == 0, 1e-18)\n",
        "        attention_weights = F.softmax(scores, dim=-1) # [batch_size, cxt_len, qst_len]\n",
        "        return torch.bmm(attention_weights, qst_embed)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDgZjcbkBtAc"
      },
      "source": [
        "***Question Encoding Layer***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGe68fl-Bsjh"
      },
      "source": [
        "class QuestionEncodingLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, dropout, n_layers):\n",
        "        super(QuestionEncodingLayer, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_layers = n_layers\n",
        "        self.stacked_bilstms_layer = StackedBiLSTMsLayer(input_size=input_size, hidden_size=hidden_size, n_layers=n_layers, dropout=dropout)\n",
        "        self.linear = nn.Linear(input_size, 1)\n",
        "    \n",
        "    def linear_self_attention(self, qst_embed, qst_mask):\n",
        "        \"\"\"\n",
        "        :param Tensor[batch_size, qst_len, embedding_size] qst_embed\n",
        "        :param Tensor[batch_size, qst_len] qst_mask\n",
        "        :return Tensor[batch_size, qst_len]\n",
        "        \"\"\"\n",
        "        scores = self.linear(qst_embed).squeeze(-1) # [batch_size, qst_len]\n",
        "        scores = scores.masked_fill(qst_mask == 0, 1e-18)\n",
        "        return F.softmax(scores, dim=-1)\n",
        "\n",
        "    \n",
        "    def forward(self, qst_embed, qst_mask):\n",
        "        \"\"\"\n",
        "        :param Tensor[batch_size, qst_len, embedding_size] qst_embed\n",
        "        :param Tensor[batch_size, qst_len] qst_mask\n",
        "        :return Tensor[batch_size, hidden_size * n_layers * 2]\n",
        "        \"\"\"\n",
        "        attention_weights = self.linear_self_attention(qst_embed=qst_embed, qst_mask=qst_mask) # [batch_size, qst_len]\n",
        "        lstm_outputs = self.stacked_bilstms_layer(inputs=qst_embed) # [batch_size, qst_len, hidden_size * n_layers * 2]\n",
        "        return torch.bmm(attention_weights.unsqueeze(1), lstm_outputs).squeeze(1)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Y9icfoaFo9x"
      },
      "source": [
        "***BiLinear Attention Layer***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtEJqs2VFocN"
      },
      "source": [
        "class BiLinearAttentionLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, cxt_size, qst_size):\n",
        "        super(BiLinearAttentionLayer, self).__init__()\n",
        "        self.cxt_size = cxt_size\n",
        "        self.qst_size = qst_size\n",
        "        self.linear = nn.Linear(qst_size, cxt_size)\n",
        "    \n",
        "    def forward(self, cxt_encoded, qst_encoded, cxt_mask):\n",
        "        \"\"\"\n",
        "        :param Tensor[batch_size, cxt_len, cxt_size] cxt_encoded\n",
        "        :param Tensor[batch_size, qst_size] qst_encoded\n",
        "        :param Tensor[batch_size, cxt_len] cxt_mask\n",
        "        :return Tensor[batch_size, cxt_len, hidden_size]\n",
        "        \"\"\"\n",
        "        qst_encoded = self.linear(qst_encoded) # [batch_size, cxt_size]\n",
        "        scores = torch.bmm(cxt_encoded, qst_encoded.unsqueeze(-1)) # [batch_size, cxt_len, 1]\n",
        "        scores = scores.squeeze(-1).masked_fill(cxt_mask == 0, 1e-18) # [batch_size, cxt_len]\n",
        "        return scores"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XGXeFMpIqYw"
      },
      "source": [
        "***Document reader Question Answering Model***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FPLlPwKIpzK"
      },
      "source": [
        "class DrQA(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_size, n_extra_features, hidden_size, n_layers, dropout, pad_index):\n",
        "        super(DrQA, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.n_extra_features = n_extra_features\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.pad_index = pad_index\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_size, padding_idx=pad_index)\n",
        "        self.align_question_embedding_layer = AlignQuestionEmbeddingLayer(hidden_size=embedding_size)\n",
        "        self.cxt_stacked_bi_lstm_layer = StackedBiLSTMsLayer(input_size=embedding_size * 2 + n_extra_features,\n",
        "                                                             hidden_size=hidden_size, n_layers=n_layers, dropout=dropout)\n",
        "        self.qst_encoding_layer = QuestionEncodingLayer(input_size=embedding_size, hidden_size=hidden_size, dropout=dropout, n_layers=n_layers)\n",
        "        self.bilinear_attention_layer_start = BiLinearAttentionLayer(cxt_size=hidden_size * n_layers * 2, qst_size=hidden_size * n_layers * 2)\n",
        "        self.bilinear_attention_layer_end = BiLinearAttentionLayer(cxt_size=hidden_size * n_layers * 2, qst_size=hidden_size * n_layers * 2)\n",
        "    \n",
        "    def load_glove_embeddings(self, path, most_common_indexes, tune=True):\n",
        "        def tune_embeddings(grad, words=most_common_indexes):\n",
        "            grad[most_common_indexes] = 0\n",
        "            return grad\n",
        "        \n",
        "        self.embedding.weight = nn.Parameter(torch.FloatTensor(np.load(path)))\n",
        "        if tune:\n",
        "            self.embedding.weight.register_hook(tune_embeddings) # Only fine-tune the 1000 most frequent question words\n",
        "    \n",
        "    def make_cxt_mask(self, cxt_sequences):\n",
        "        \"\"\"\n",
        "        :param Tensor[batch_size, cxt_len]\n",
        "        :return Tensor[batch_size, cxt_len]\n",
        "        \"\"\"\n",
        "        return cxt_sequences != self.pad_index\n",
        "    \n",
        "    def make_qst_mask(self, qst_sequences):\n",
        "        \"\"\"\n",
        "        :param Tensor[batch_size, qst_len]\n",
        "        :return Tensor[batch_size, qst_len]\n",
        "        \"\"\"\n",
        "        return qst_sequences != self.pad_index\n",
        "    \n",
        "    @staticmethod\n",
        "    def decode(starts, ends):\n",
        "        \"\"\"\n",
        "        :param Tensor[batch_size, cxt_len] starts\n",
        "        :param Tensor[batch_size, cxt_len] ends\n",
        "        :return list(int) start_indexes\n",
        "        :return list(int) end_indexes\n",
        "        :return list(float) pred_probas\n",
        "        \"\"\"\n",
        "        start_indexes, end_indexes, pred_probas = [], [], []\n",
        "        for i in range(starts.size(0)):\n",
        "            probas = torch.ger(starts[i], ends[i]) # [cxt_len, cxt_len]\n",
        "            proba, index = torch.topk(probas.view(-1), k=1)\n",
        "            start_indexes.append(index.tolist()[0] // probas.size(0))\n",
        "            end_indexes.append(index.tolist()[0] % probas.size(1))\n",
        "            pred_probas.append(proba.tolist()[0])\n",
        "        return start_indexes, end_indexes, pred_probas\n",
        "\n",
        "    @staticmethod\n",
        "    def build_exact_match(cxt_sequences, qst_sequences):\n",
        "        \"\"\"\n",
        "        :param Tensor[batch_size, cxt_len] cxt_sequences\n",
        "        :param Tensor[batch_size, qst_len] qst_sequences\n",
        "        :return Tensor[batch_size, cxt_len]\n",
        "        \"\"\"\n",
        "        em_sequences = []\n",
        "        for i, cxt_sequence in enumerate(cxt_sequences):\n",
        "            em = [word in qst_sequences[i] for word in cxt_sequence]\n",
        "            em_sequences.append(em)\n",
        "        return torch.tensor(em_sequences, dtype=torch.float, device=cxt_sequences.device)\n",
        "\n",
        "    @staticmethod\n",
        "    def build_normalized_term_frequency(cxt_sequences):\n",
        "        \"\"\"\n",
        "        :param Tensor[batch_size, cxt_len] cxt_sequences\n",
        "        :return Tensor[batch_size, cxt_len]\n",
        "        \"\"\"\n",
        "        ntfs = []\n",
        "        for i, cxt_sequence in enumerate(cxt_sequences):\n",
        "            counts = collections.Counter(cxt_sequence.tolist())\n",
        "            count_norm = sum(counts.values())\n",
        "            ntfs.append([counts[indice] / count_norm for indice in cxt_sequence.tolist()])\n",
        "        return torch.tensor(ntfs, dtype=torch.float, device=cxt_sequences.device)\n",
        "    \n",
        "    def forward(self, cxt_sequences, pos_sequences, ner_sequences, qst_sequences):\n",
        "        \"\"\"\n",
        "        :param Tensor[batch_size, cxt_len] cxt_sequences\n",
        "        :param Tensor[batch_size, cxt_len] pos_sequences\n",
        "        :param Tensor[batch_size, cxt_len] ner_sequences\n",
        "        :param Tensor[batch_size, qst_len] qst_sequences\n",
        "        :param Tensor[batch_size, cxt_len] cxt_mask\n",
        "        :param Tensor[batch_size, qst_len] qst_mask\n",
        "        :return Tensor[batch_size, cxt_len] starts\n",
        "        :return Tensor[batch_size, cxt_len] ends\n",
        "        \"\"\"\n",
        "        cxt_mask = self.make_cxt_mask(cxt_sequences) # [batch_size, cxt_len]\n",
        "        qst_mask = self.make_qst_mask(qst_sequences) # [batch_size, qst_len]\n",
        "        cxt_embedded = self.dropout(self.embedding(cxt_sequences)) # [batch_size, cxt_len, embedding_size]\n",
        "        qst_embedded = self.dropout(self.embedding(qst_sequences)) # [batch_size, cxt_len, embedding_size]\n",
        "        cxt_aligned = self.align_question_embedding_layer(cxt_embed=cxt_embedded, qst_embed=qst_embedded,\n",
        "                                                          qst_mask=qst_mask) # [batch_size, cxt_len, embedding_size]\n",
        "        # em_sequences = self.build_exact_match(cxt_sequences=cxt_sequences, qst_sequences=qst_sequences)\n",
        "        # tf_sequences = self.build_normalized_term_frequency(cxt_sequences=cxt_sequences)\n",
        "        cxt_encoded = torch.cat([cxt_embedded, # [batch_size, cxt_len, embedding_size]\n",
        "                                #  em_sequences.unsqueeze(-1), # [batch_size, cxt_len, 1]\n",
        "                                 pos_sequences.unsqueeze(-1), # [batch_size, cxt_len, 1]\n",
        "                                 ner_sequences.unsqueeze(-1), # [batch_size, cxt_len, 1]\n",
        "                                #  tf_sequences.unsqueeze(-1), # [batch_size, cxt_len, 1]\n",
        "                                 cxt_aligned # [batch_size, cxt_len, embedding_size]\n",
        "                                 ], dim=-1) # [batch_size, cxt_len, embedding_size * 2 + 4]\n",
        "        cxt_encoded = self.cxt_stacked_bi_lstm_layer(inputs=cxt_encoded) # [batch_size, cxt_len, hidden_size * n_layers * 2]\n",
        "        qst_encoded = self.qst_encoding_layer(qst_embed=qst_embedded, qst_mask=qst_mask) # [batch_size, hidden_size * n_layers * 2]\n",
        "        starts = self.bilinear_attention_layer_start(cxt_encoded=cxt_encoded, qst_encoded=qst_encoded, cxt_mask=cxt_mask)\n",
        "        ends = self.bilinear_attention_layer_end(cxt_encoded=cxt_encoded, qst_encoded=qst_encoded, cxt_mask=cxt_mask)\n",
        "        return starts, ends"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSpwpOK8QBWV"
      },
      "source": [
        "***Training routines***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uu_ziZuDPSyX"
      },
      "source": [
        "class AverageMeter:\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.value = 0.\n",
        "        self.sum = 0.\n",
        "        self.count = 0\n",
        "        self.average = 0.\n",
        "        \n",
        "    def reset(self):\n",
        "        self.value = 0.\n",
        "        self.sum = 0.\n",
        "        self.count = 0\n",
        "        self.average = 0.\n",
        "        \n",
        "    def update(self, value, n=1):\n",
        "        self.value = value\n",
        "        self.sum += value * n\n",
        "        self.count += n\n",
        "        self.average = self.sum / self.count"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1TOIhXBQGcB"
      },
      "source": [
        "def normalize_answer(s):\n",
        "    \"\"\"Performs a series of cleaning steps on the ground truth and predicted answer.\"\"\"\n",
        "    def remove_articles(text):\n",
        "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
        "\n",
        "    def white_space_fix(text):\n",
        "        return ' '.join(text.split())\n",
        "\n",
        "    def remove_punc(text):\n",
        "        exclude = set(string.punctuation)\n",
        "        return ''.join(ch for ch in text if ch not in exclude)\n",
        "\n",
        "    def lower(text):\n",
        "        return text.lower()\n",
        "\n",
        "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
        "\n",
        "\n",
        "def metric_max_over_ground_truths(metric_fn, prediction, ground_truths):\n",
        "    \"\"\"Returns maximum value of metrics for predicition by model against\n",
        "    multiple ground truths.\n",
        "    \n",
        "    :param func metric_fn: can be 'exact_match_score' or 'f1_score'\n",
        "    :param str prediction: predicted answer span by the model\n",
        "    :param list ground_truths: list of ground truths against which\n",
        "                               metrics are calculated. Maximum values of \n",
        "                               metrics are chosen.\n",
        "    \"\"\"\n",
        "    scores_for_ground_truths = []\n",
        "    for ground_truth in ground_truths:\n",
        "        score = metric_fn(prediction, ground_truth)\n",
        "        scores_for_ground_truths.append(score)\n",
        "    return max(scores_for_ground_truths)\n",
        "\n",
        "\n",
        "def f1_score(prediction, ground_truth):\n",
        "    \"\"\"Returns f1 score of two strings.\"\"\"\n",
        "    prediction_tokens = normalize_answer(prediction).split()\n",
        "    ground_truth_tokens = normalize_answer(ground_truth).split()\n",
        "    common = collections.Counter(prediction_tokens) & collections.Counter(ground_truth_tokens)\n",
        "    num_same = sum(common.values())\n",
        "    if num_same == 0:\n",
        "        return 0\n",
        "    precision = 1.0 * num_same / len(prediction_tokens)\n",
        "    recall = 1.0 * num_same / len(ground_truth_tokens)\n",
        "    f1 = (2 * precision * recall) / (precision + recall)\n",
        "    return f1\n",
        "\n",
        "\n",
        "def exact_match_score(prediction, ground_truth):\n",
        "    \"\"\"Returns exact_match_score of two strings.\"\"\"\n",
        "    return (normalize_answer(prediction) == normalize_answer(ground_truth))"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jAP2WtVRKUy"
      },
      "source": [
        "def evaluate(predictions, path='./data/valid.json'):\n",
        "    \"\"\"Gets a dictionary of predictions with question_id as key\n",
        "    and prediction as value. The validation dataset has multiple \n",
        "    answers for a single question. Hence we compare our prediction\n",
        "    with all the answers and choose the one that gives us\n",
        "    the maximum metric (em or f1).\n",
        "\n",
        "    :param dict predictions\n",
        "    :return float exact_match: 1 if the prediction and ground truth match exactly, 0 otherwise.\n",
        "    :return float f1_score\n",
        "    \"\"\"\n",
        "    dataset = load_json(path)\n",
        "    f1 = exact_match = total = 0\n",
        "    for article in dataset:\n",
        "        for paragraph in article['paragraphs']:\n",
        "            for qa in paragraph['qas']:\n",
        "                total += 1\n",
        "                if qa['id'] not in predictions:\n",
        "                    continue\n",
        "                ground_truths = [*map(lambda x: x['text'], qa['answers'])]\n",
        "                prediction = predictions[qa['id']]\n",
        "                exact_match += metric_max_over_ground_truths(exact_match_score, prediction, ground_truths)\n",
        "                f1 += metric_max_over_ground_truths(f1_score, prediction, ground_truths)\n",
        "    exact_match = 100.0 * exact_match / total\n",
        "    f1 = 100.0 * f1 / total\n",
        "    return exact_match, f1"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20-KuPdNTu2k"
      },
      "source": [
        "class Trainer:\n",
        "    \n",
        "    def __init__(self, model, optimizer, criterion, id_field, text_field):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.criterion = criterion\n",
        "        self.id_field = id_field\n",
        "        self.text_field = text_field\n",
        "        \n",
        "    def train_step(self, loader, epoch, grad_clip):\n",
        "        loss_tracker = AverageMeter()\n",
        "        self.model.train()\n",
        "        progress_bar = tqdm.tqdm(enumerate(loader), total=len(loader))\n",
        "        for i, batch in progress_bar:\n",
        "            self.optimizer.zero_grad()\n",
        "            starts, ends = self.model(cxt_sequences=batch.cxt, pos_sequences=batch.pos, ner_sequences=batch.ner,\n",
        "                                      qst_sequences=batch.qst) # [batch_size, cxt_len]\n",
        "            loss = self.criterion(starts, batch.trg[:, 0]) + self.criterion(ends, batch.trg[:, 1])\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(self.model.parameters(), grad_clip)\n",
        "            self.optimizer.step()\n",
        "            loss_tracker.update(loss.item())\n",
        "            progress_bar.set_description(f'Epoch: {epoch+1:02d} -     loss: {loss_tracker.average:.3f}')\n",
        "        return loss_tracker.average\n",
        "    \n",
        "    def validate(self, loader, epoch):\n",
        "        loss_tracker, predictions = AverageMeter(), {}\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            progress_bar = tqdm.tqdm(enumerate(loader), total=len(loader))\n",
        "            for i, batch in progress_bar:\n",
        "                starts, ends = self.model(cxt_sequences=batch.cxt, pos_sequences=batch.pos, ner_sequences=batch.ner,\n",
        "                                          qst_sequences=batch.qst) # [batch_size, cxt_len]\n",
        "                loss = self.criterion(starts, batch.trg[:, 0]) + self.criterion(ends, batch.trg[:, 1])\n",
        "                start_indexes, end_indexes, _ = self.model.decode(starts=F.softmax(starts, dim=-1), ends=F.softmax(ends, dim=-1))\n",
        "                for i in range(starts.size(0)):\n",
        "                    id = self.id_field.vocab.itos[batch.id[i].item()]\n",
        "                    prediction = batch.cxt[i][start_indexes[i]:end_indexes[i]+1]\n",
        "                    predictions[id] = ' '.join([self.text_field.vocab.itos[indice.item()] for indice in prediction])\n",
        "                loss_tracker.update(loss.item())\n",
        "                progress_bar.set_description(f'Epoch: {epoch+1:02d} - val_loss: {loss_tracker.average:.3f}')\n",
        "        return loss_tracker.average, predictions\n",
        "    \n",
        "    def train(self, train_loader, valid_loader, n_epochs, grad_clip):\n",
        "        history, best_loss = {'loss': [], 'val_loss': [], 'em': [], 'f1': []}, np.inf\n",
        "        for epoch in range(n_epochs):\n",
        "            loss = self.train_step(train_loader, epoch, grad_clip)\n",
        "            val_loss, predictions = self.validate(valid_loader, epoch)\n",
        "            em, f1 = evaluate(predictions)\n",
        "            print(f'\\nF1={f1:.3f}% - EM={em:.3f}%')\n",
        "            history['loss'].append(loss); history['val_loss'].append(val_loss)\n",
        "            history['em'].append(em); history['f1'].append(f1)\n",
        "            if best_loss > val_loss:\n",
        "                best_loss = val_loss\n",
        "                torch.save(self.model.state_dict(), './checkpoints/DrQA.pth')\n",
        "        return history"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7BcJPV_eNGJ"
      },
      "source": [
        "***Train the model***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dHfjBuUeHE6"
      },
      "source": [
        "N_LAYERS = 1\n",
        "HIDDEN_SIZE = 64\n",
        "EMBED_SIZE = 100\n",
        "DROPOUT = 0.25\n",
        "N_EPOCHS = 5\n",
        "LR = 1e-2\n",
        "BATCH_SIZE = 64\n",
        "GRAD_CLIP = 1.0"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVcHGhr-eQfB",
        "outputId": "99cbb175-d108-4665-9aed-00a5b1e38413",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "drqa = DrQA(vocab_size=len(TEXT.vocab), embedding_size=EMBED_SIZE, n_extra_features=2, hidden_size=HIDDEN_SIZE, n_layers=N_LAYERS,\n",
        "            dropout=DROPOUT, pad_index=TEXT.vocab.stoi[TEXT.pad_token])\n",
        "# drqa.load_glove_embeddings('./data/GloVe_DrQA.npy', most_common_indexes, tune=False)\n",
        "drqa.to(DEVICE)\n",
        "optimizer = optim.RMSprop(params=drqa.parameters(), lr=LR)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=TEXT.vocab.stoi[TEXT.pad_token])\n",
        "print(f'Number of parameters of the model: {sum(p.numel() for p in drqa.parameters() if p.requires_grad):,}')\n",
        "print(drqa)\n",
        "trainer = Trainer(model=drqa, optimizer=optimizer, criterion=criterion, id_field=ID, text_field=TEXT)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of parameters of the model: 9,410,033\n",
            "DrQA(\n",
            "  (dropout): Dropout(p=0.25, inplace=False)\n",
            "  (embedding): Embedding(91446, 100, padding_idx=1)\n",
            "  (align_question_embedding_layer): AlignQuestionEmbeddingLayer(\n",
            "    (linear): Linear(in_features=100, out_features=100, bias=True)\n",
            "  )\n",
            "  (cxt_stacked_bi_lstm_layer): StackedBiLSTMsLayer(\n",
            "    (dropout): Dropout(p=0.25, inplace=False)\n",
            "    (lstms): ModuleList(\n",
            "      (0): LSTM(202, 64, bidirectional=True)\n",
            "    )\n",
            "  )\n",
            "  (qst_encoding_layer): QuestionEncodingLayer(\n",
            "    (stacked_bilstms_layer): StackedBiLSTMsLayer(\n",
            "      (dropout): Dropout(p=0.25, inplace=False)\n",
            "      (lstms): ModuleList(\n",
            "        (0): LSTM(100, 64, bidirectional=True)\n",
            "      )\n",
            "    )\n",
            "    (linear): Linear(in_features=100, out_features=1, bias=True)\n",
            "  )\n",
            "  (bilinear_attention_layer_start): BiLinearAttentionLayer(\n",
            "    (linear): Linear(in_features=128, out_features=128, bias=True)\n",
            "  )\n",
            "  (bilinear_attention_layer_end): BiLinearAttentionLayer(\n",
            "    (linear): Linear(in_features=128, out_features=128, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEzloF3aewPA",
        "outputId": "03800512-183f-4fe1-b8f6-ec1786c8aea2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "!mkdir -p ./checkpoints\n",
        "train_iterator, valid_iterator = BucketIterator.splits((train_dataset, valid_dataset), batch_size=BATCH_SIZE, sort=False, device=DEVICE)\n",
        "history = trainer.train(train_loader=train_iterator, valid_loader=valid_iterator, n_epochs=N_EPOCHS, grad_clip=GRAD_CLIP)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 -     loss: 9.733: 100%|██████████| 1354/1354 [00:46<00:00, 29.42it/s]\n",
            "Epoch: 01 - val_loss: 8.952: 100%|██████████| 536/536 [00:27<00:00, 19.39it/s]\n",
            "  0%|          | 0/1354 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "F1=4.497% - EM=1.570%\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 02 -     loss: 9.281: 100%|██████████| 1354/1354 [00:45<00:00, 29.94it/s]\n",
            "Epoch: 02 - val_loss: 8.972: 100%|██████████| 536/536 [00:28<00:00, 19.00it/s]\n",
            "Epoch: 03 -     loss: 9.343:   0%|          | 1/1354 [00:00<03:10,  7.12it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "F1=4.896% - EM=1.750%\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 03 -     loss: 9.232: 100%|██████████| 1354/1354 [00:45<00:00, 29.83it/s]\n",
            "Epoch: 03 - val_loss: 9.001: 100%|██████████| 536/536 [00:27<00:00, 19.39it/s]\n",
            "Epoch: 04 -     loss: 9.336:   0%|          | 1/1354 [00:00<03:13,  6.99it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "F1=4.699% - EM=1.769%\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 04 -     loss: 9.307: 100%|██████████| 1354/1354 [00:45<00:00, 30.06it/s]\n",
            "Epoch: 04 - val_loss: 9.063: 100%|██████████| 536/536 [00:26<00:00, 20.04it/s]\n",
            "Epoch: 05 -     loss: 9.501:   0%|          | 1/1354 [00:00<03:05,  7.31it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "F1=4.363% - EM=1.741%\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 05 -     loss: 9.337: 100%|██████████| 1354/1354 [00:44<00:00, 30.25it/s]\n",
            "Epoch: 05 - val_loss: 8.998: 100%|██████████| 536/536 [00:27<00:00, 19.65it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "F1=4.885% - EM=2.044%\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPx4uFPnCZ8W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}