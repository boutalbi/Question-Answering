{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./data'):\n",
    "    !mkdir ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-03-22 18:38:21--  https://github.com/hse-aml/natural-language-processing/releases/download/project/tagged_posts.tsv\n",
      "Resolving github.com (github.com)... 140.82.112.4\n",
      "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/112112945/8156d746-7325-11e8-8049-a22b3f232b02?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200322%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200322T183821Z&X-Amz-Expires=300&X-Amz-Signature=4bfaf524ac74eafaef10b87308139b8859078c49018d7798aad465e1618860a4&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dtagged_posts.tsv&response-content-type=application%2Foctet-stream [following]\n",
      "--2020-03-22 18:38:21--  https://github-production-release-asset-2e65be.s3.amazonaws.com/112112945/8156d746-7325-11e8-8049-a22b3f232b02?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200322%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200322T183821Z&X-Amz-Expires=300&X-Amz-Signature=4bfaf524ac74eafaef10b87308139b8859078c49018d7798aad465e1618860a4&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dtagged_posts.tsv&response-content-type=application%2Foctet-stream\n",
      "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.88.243\n",
      "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.88.243|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 145677870 (139M) [application/octet-stream]\n",
      "Saving to: ‘./data/tagged_posts.tsv’\n",
      "\n",
      "./data/tagged_posts 100%[===================>] 138.93M  4.56MB/s    in 34s     \n",
      "\n",
      "2020-03-22 18:38:56 (4.08 MB/s) - ‘./data/tagged_posts.tsv’ saved [145677870/145677870]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget --no-check-certificate \\\n",
    "    https://github.com/hse-aml/natural-language-processing/releases/download/project/tagged_posts.tsv \\\n",
    "    -O ./data/tagged_posts.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-03-22 18:38:56--  https://github.com/hse-aml/natural-language-processing/releases/download/project/dialogues.tsv\n",
      "Resolving github.com (github.com)... 140.82.113.3\n",
      "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/112112945/72da0808-eda3-11e7-80c5-8ee61be1a33e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200322%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200322T183856Z&X-Amz-Expires=300&X-Amz-Signature=34ab34c7575d14578de0a89ece667df334a7f1ace74ded28ef672f5d500f4383&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Ddialogues.tsv&response-content-type=application%2Foctet-stream [following]\n",
      "--2020-03-22 18:38:56--  https://github-production-release-asset-2e65be.s3.amazonaws.com/112112945/72da0808-eda3-11e7-80c5-8ee61be1a33e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200322%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200322T183856Z&X-Amz-Expires=300&X-Amz-Signature=34ab34c7575d14578de0a89ece667df334a7f1ace74ded28ef672f5d500f4383&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Ddialogues.tsv&response-content-type=application%2Foctet-stream\n",
      "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.217.44.252\n",
      "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.217.44.252|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 18012894 (17M) [application/octet-stream]\n",
      "Saving to: ‘./data/dialogues.tsv’\n",
      "\n",
      "./data/dialogues.ts 100%[===================>]  17.18M  10.7MB/s    in 1.6s    \n",
      "\n",
      "2020-03-22 18:38:58 (10.7 MB/s) - ‘./data/dialogues.tsv’ saved [18012894/18012894]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget --no-check-certificate \\\n",
    "    https://github.com/hse-aml/natural-language-processing/releases/download/project/dialogues.tsv \\\n",
    "    -O ./data/dialogues.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tfidf_features(X_train, X_test, to_='./out'):\n",
    "    if not os.path.exists(to_):\n",
    "        !mkdir {to_}\n",
    "    vect = TfidfVectorizer(min_df=5, max_df=0.9, ngram_range=(1, 2), token_pattern='(\\S+)')\n",
    "    vect.fit(X_train)\n",
    "    with open(os.path.join(to_, 'tfidf.pkl'), 'wb') as file:\n",
    "        pickle.dump(vect, file)\n",
    "    X_train = vect.transform(X_train)\n",
    "    X_test = vect.transform(X_test)\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 781\n",
    "sample_size = 200000\n",
    "\n",
    "df_stackoverflow = pd.read_csv('./data/tagged_posts.tsv', sep='\\t').sample(sample_size, random_state=seed)\n",
    "df_dialogues = pd.read_csv('./data/dialogues.tsv', sep='\\t').sample(sample_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>title</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>631024</th>\n",
       "      <td>9071076</td>\n",
       "      <td>C++ virtual method overload/override compiler ...</td>\n",
       "      <td>c_cpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353311</th>\n",
       "      <td>5298353</td>\n",
       "      <td>Check a condition and also identify the patter...</td>\n",
       "      <td>php</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1547617</th>\n",
       "      <td>23947511</td>\n",
       "      <td>isset($_POST['x']) only works if the submit bu...</td>\n",
       "      <td>php</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70588</th>\n",
       "      <td>1353559</td>\n",
       "      <td>Trying to make this star output using a for lo...</td>\n",
       "      <td>c_cpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534998</th>\n",
       "      <td>7753016</td>\n",
       "      <td>Django+Postgres: \"current transaction is abort...</td>\n",
       "      <td>python</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          post_id                                              title     tag\n",
       "631024    9071076  C++ virtual method overload/override compiler ...   c_cpp\n",
       "353311    5298353  Check a condition and also identify the patter...     php\n",
       "1547617  23947511  isset($_POST['x']) only works if the submit bu...     php\n",
       "70588     1353559  Trying to make this star output using a for lo...   c_cpp\n",
       "534998    7753016  Django+Postgres: \"current transaction is abort...  python"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stackoverflow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>154349</th>\n",
       "      <td>What's that got to do with you?</td>\n",
       "      <td>dialogue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105643</th>\n",
       "      <td>Nooo.  Is it your story?</td>\n",
       "      <td>dialogue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122343</th>\n",
       "      <td>No Bela, that's \"incorporates.\"  Look, just sa...</td>\n",
       "      <td>dialogue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183491</th>\n",
       "      <td>For getting a divorce?</td>\n",
       "      <td>dialogue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129003</th>\n",
       "      <td>No danger of attack, as long as you don't trig...</td>\n",
       "      <td>dialogue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text       tag\n",
       "154349                    What's that got to do with you?  dialogue\n",
       "105643                           Nooo.  Is it your story?  dialogue\n",
       "122343  No Bela, that's \"incorporates.\"  Look, just sa...  dialogue\n",
       "183491                             For getting a divorce?  dialogue\n",
       "129003  No danger of attack, as long as you don't trig...  dialogue"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dialogues.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_prepare(text):\n",
    "    \"\"\"Performs tokenization and simple preprocessing.\"\"\"\n",
    "\n",
    "    replace_by_space_re = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "    bad_symbols_re = re.compile('[^0-9a-z #+_]')\n",
    "    stopwords_set = set(stopwords.words('english'))\n",
    "\n",
    "    text = text.lower()\n",
    "    text = replace_by_space_re.sub(' ', text)\n",
    "    text = bad_symbols_re.sub('', text)\n",
    "    text = ' '.join([x for x in text.split() if x and x not in stopwords_set])\n",
    "\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51.4 s, sys: 3.9 s, total: 55.3 s\n",
      "Wall time: 55.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_stackoverflow.title = df_stackoverflow.title.apply(text_prepare)\n",
    "df_dialogues.text = df_dialogues.text.apply(text_prepare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intent recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size=360000, test size=40000\n",
      "CPU times: user 17.6 s, sys: 404 ms, total: 18 s\n",
      "Wall time: 18.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = np.concatenate([df_dialogues.text.values, df_stackoverflow.title.values])\n",
    "y = ['dialogue'] * df_dialogues.shape[0] + ['stackoverflow'] * df_stackoverflow.shape[0]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=seed)\n",
    "print(f'Train size={len(X_train)}, test size={len(X_test)}')\n",
    "\n",
    "X_train_tfidf, X_test_tfidf = extract_tfidf_features(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.9 s, sys: 1.09 s, total: 20 s\n",
      "Wall time: 5.45 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=781, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "intent_recognizer = LogisticRegression(penalty='l2', C=10, random_state=seed, solver='liblinear')\n",
    "intent_recognizer.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy=0.99125\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = intent_recognizer.predict(X_test_tfidf)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f'Test accuracy={test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(intent_recognizer, open('./out/intent_recognizer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming language classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size=160000, test size=40000\n"
     ]
    }
   ],
   "source": [
    "X = df_stackoverflow.title.values\n",
    "y = df_stackoverflow.tag.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "print(f'Train size={len(X_train)}, test size={len(X_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = pickle.load(open('./out/tfidf.pkl', 'rb'))\n",
    "\n",
    "X_train_tfidf, X_test_tfidf = vectorizer.transform(X_train), vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44.6 s, sys: 2.18 s, total: 46.8 s\n",
      "Wall time: 12.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(C=5, class_weight=None,\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=100,\n",
       "                                                 multi_class='auto',\n",
       "                                                 n_jobs=None, penalty='l2',\n",
       "                                                 random_state=781,\n",
       "                                                 solver='liblinear', tol=0.0001,\n",
       "                                                 verbose=0, warm_start=False),\n",
       "                    n_jobs=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tag_classifier = OneVsRestClassifier(LogisticRegression(penalty='l2', C=5, random_state=seed, solver='liblinear'))\n",
    "tag_classifier.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy=0.801575\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = tag_classifier.predict(X_test_tfidf)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f'Test accuracy={test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tag_classifier, open('./out/tag_classifier.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking questions with embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
