{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "To detect intent of users questions we will need two text collections:\n",
    "\n",
    "- `tagged_posts.tsv` — StackOverflow posts, tagged with one programming language (positive samples).\n",
    "- `dialogues.tsv` — dialogue phrases from movie subtitles (negative samples).\n",
    "\n",
    "For those questions, that have programming-related intent, we will proceed as follow predict programming language (we allowed only one tag per question here) and rank candidates within the tag using embeddings. For the ranking part, we will need:\n",
    "\n",
    "- `word_embeddings.tsv` — word embeddings, that you trained with StarSpace in the 3rd assignment. It's not a problem if you didn't do it, because we can offer an alternative solution for you.\n",
    "\n",
    "As a result of this notebook, we should obtain the following new objects that we will then use in the running bot:\n",
    "\n",
    "- `intent_recognizer.pkl` — intent recognition model;\n",
    "- `tag_classifier.pkl` — programming language classification model;\n",
    "- `tfidf_vectorizer.pkl` — vectorizer used during training;\n",
    "- `thread_embeddings_by_tags` — folder with thread embeddings, arranged by tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./data'):\n",
    "    !mkdir ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --no-check-certificate \\\n",
    "    https://github.com/hse-aml/natural-language-processing/releases/download/project/tagged_posts.tsv \\\n",
    "    -O ./data/tagged_posts.tsv > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --no-check-certificate \\\n",
    "    https://github.com/hse-aml/natural-language-processing/releases/download/project/dialogues.tsv \\\n",
    "    -O ./data/dialogues.tsv > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 781\n",
    "sample_size = 200000\n",
    "\n",
    "df_stackoverflow = pd.read_csv('./data/tagged_posts.tsv', sep='\\t').sample(sample_size, random_state=seed)\n",
    "df_dialogues = pd.read_csv('./data/dialogues.tsv', sep='\\t').sample(sample_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>title</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>631024</th>\n",
       "      <td>9071076</td>\n",
       "      <td>C++ virtual method overload/override compiler ...</td>\n",
       "      <td>c_cpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353311</th>\n",
       "      <td>5298353</td>\n",
       "      <td>Check a condition and also identify the patter...</td>\n",
       "      <td>php</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1547617</th>\n",
       "      <td>23947511</td>\n",
       "      <td>isset($_POST['x']) only works if the submit bu...</td>\n",
       "      <td>php</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70588</th>\n",
       "      <td>1353559</td>\n",
       "      <td>Trying to make this star output using a for lo...</td>\n",
       "      <td>c_cpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534998</th>\n",
       "      <td>7753016</td>\n",
       "      <td>Django+Postgres: \"current transaction is abort...</td>\n",
       "      <td>python</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          post_id                                              title     tag\n",
       "631024    9071076  C++ virtual method overload/override compiler ...   c_cpp\n",
       "353311    5298353  Check a condition and also identify the patter...     php\n",
       "1547617  23947511  isset($_POST['x']) only works if the submit bu...     php\n",
       "70588     1353559  Trying to make this star output using a for lo...   c_cpp\n",
       "534998    7753016  Django+Postgres: \"current transaction is abort...  python"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stackoverflow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>154349</th>\n",
       "      <td>What's that got to do with you?</td>\n",
       "      <td>dialogue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105643</th>\n",
       "      <td>Nooo.  Is it your story?</td>\n",
       "      <td>dialogue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122343</th>\n",
       "      <td>No Bela, that's \"incorporates.\"  Look, just sa...</td>\n",
       "      <td>dialogue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183491</th>\n",
       "      <td>For getting a divorce?</td>\n",
       "      <td>dialogue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129003</th>\n",
       "      <td>No danger of attack, as long as you don't trig...</td>\n",
       "      <td>dialogue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text       tag\n",
       "154349                    What's that got to do with you?  dialogue\n",
       "105643                           Nooo.  Is it your story?  dialogue\n",
       "122343  No Bela, that's \"incorporates.\"  Look, just sa...  dialogue\n",
       "183491                             For getting a divorce?  dialogue\n",
       "129003  No danger of attack, as long as you don't trig...  dialogue"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dialogues.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I. Intent and language recognition\n",
    "\n",
    "We want to write a bot, which will not only **answer programming-related questions**, but also will be able to **maintain a dialogue**. We would also like to detect the *intent* of the user from the question (we could have had a 'Question answering mode' check-box in the bot, but it wouldn't fun at all). So the first thing we need to do is to **distinguish programming-related questions from general ones**.\n",
    "\n",
    "It would also be good to predict which programming language a particular question referees to. By doing so, we will speed up question search by a factor of the number of languages (10 here)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_prepare(text):\n",
    "    \"\"\"Performs tokenization and simple preprocessing.\"\"\"\n",
    "\n",
    "    replace_by_space_re = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "    bad_symbols_re = re.compile('[^0-9a-z #+_]')\n",
    "    stopwords_set = set(stopwords.words('english'))\n",
    "\n",
    "    text = text.lower()\n",
    "    text = replace_by_space_re.sub(' ', text)\n",
    "    text = bad_symbols_re.sub('', text)\n",
    "    text = ' '.join([x for x in text.split() if x and x not in stopwords_set])\n",
    "\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 47.5 s, sys: 5.2 s, total: 52.7 s\n",
      "Wall time: 52.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_stackoverflow.title = df_stackoverflow.title.apply(text_prepare)\n",
    "df_dialogues.text = df_dialogues.text.apply(text_prepare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intent recognition\n",
    "\n",
    "We will do a binary classification on TF-IDF representations of texts. Labels will be either `dialogue` for general questions or `stackoverflow` for programming-related questions. First, we prepare the data for this task:\n",
    "\n",
    "- concatenate dialogue and stackoverflow examples into one sample\n",
    "- split it into train and test in proportion 90/10 %, use random_state=0 for reproducibility\n",
    "- transform it into TF-IDF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tfidf_features(X_train, X_test, to_='./out'):\n",
    "    if not os.path.exists(to_):\n",
    "        !mkdir {to_}\n",
    "    vect = TfidfVectorizer(min_df=5, max_df=0.9, ngram_range=(1, 2), token_pattern='(\\S+)')\n",
    "    vect.fit(X_train)\n",
    "    with open(os.path.join(to_, 'tfidf_vectorizer.pkl'), 'wb') as file:\n",
    "        pickle.dump(vect, file)\n",
    "    X_train = vect.transform(X_train)\n",
    "    X_test = vect.transform(X_test)\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size=360000, test size=40000\n",
      "CPU times: user 17.5 s, sys: 302 ms, total: 17.8 s\n",
      "Wall time: 17.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = np.concatenate([df_dialogues.text.values, df_stackoverflow.title.values])\n",
    "y = ['dialogue'] * df_dialogues.shape[0] + ['stackoverflow'] * df_stackoverflow.shape[0]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=seed)\n",
    "print(f'Train size={len(X_train)}, test size={len(X_test)}')\n",
    "\n",
    "X_train_tfidf, X_test_tfidf = extract_tfidf_features(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.6 s, sys: 30.4 s, total: 43.9 s\n",
      "Wall time: 6.55 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=781, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "intent_recognizer = LogisticRegression(penalty='l2', C=10, random_state=seed, solver='liblinear')\n",
    "intent_recognizer.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy=0.99125\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = intent_recognizer.predict(X_test_tfidf)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f'Test accuracy={test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(intent_recognizer, open('./out/intent_recognizer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming Language Classifcation\n",
    "\n",
    "We will train one more classifier for the programming-related questions. It will predict exactly one tag (=programming language) and will be also based on Logistic Regression with TF-IDF features.\n",
    "\n",
    "First, let us prepare the data for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size=160000, test size=40000\n"
     ]
    }
   ],
   "source": [
    "X = df_stackoverflow.title.values\n",
    "y = df_stackoverflow.tag.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "print(f'Train size={len(X_train)}, test size={len(X_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = pickle.load(open('./out/tfidf_vectorizer.pkl', 'rb'))\n",
    "\n",
    "X_train_tfidf, X_test_tfidf = vectorizer.transform(X_train), vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.6 s, sys: 1min 27s, total: 2min 5s\n",
      "Wall time: 18.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(C=5, class_weight=None,\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=100,\n",
       "                                                 multi_class='warn',\n",
       "                                                 n_jobs=None, penalty='l2',\n",
       "                                                 random_state=781,\n",
       "                                                 solver='liblinear', tol=0.0001,\n",
       "                                                 verbose=0, warm_start=False),\n",
       "                    n_jobs=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tag_classifier = OneVsRestClassifier(LogisticRegression(penalty='l2', C=5, random_state=seed, solver='liblinear'))\n",
    "tag_classifier.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy=0.801625\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = tag_classifier.predict(X_test_tfidf)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f'Test accuracy={test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tag_classifier, open('./out/tag_classifier.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Ranking questions with embeddings\n",
    "\n",
    "To find a relevant answer (a thread from StackOverflow) on a question we will use vector representations to calculate similarity between the question and existing threads. We create `question_to_vec` function, which can make such a representation based on word vectors.\n",
    "\n",
    "However, it would be costly to compute such a representation for all possible answers in online mode of the bot (e.g. when bot is running and answering questions from many users). This is the reason why we will create a database with pre-computed representations. These representations will be arranged by non-overlaping tags (programming languages), so that the search of the answer can be performed only within one tag each time. This will make our bot even more efficient and allow not to store all the database in RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_to_vec(question, embeddings, dim=300):\n",
    "    \"\"\"\n",
    "        question: a string\n",
    "        embeddings: dict where the key is a word and a value is its' embedding\n",
    "        dim: size of the representation\n",
    "\n",
    "        result: vector representation for the question\n",
    "    \"\"\"\n",
    "    vec = []\n",
    "    for token in question.split():\n",
    "        if token in embeddings:\n",
    "            vec.append(embeddings[token])\n",
    "    if len(vec) == 0:\n",
    "        return np.zeros((dim,))\n",
    "    return np.stack(vec).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-03-30 14:03:44--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.37.158\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.37.158|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1647046227 (1.5G) [application/x-gzip]\n",
      "Saving to: ‘./data/GoogleNews-vectors-negative300.bin.gz’\n",
      "\n",
      "./data/GoogleNews-v 100%[===================>]   1.53G  11.1MB/s    in 3m 42s  \n",
      "\n",
      "2020-03-30 14:07:26 (7.08 MB/s) - ‘./data/GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -c https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz \\\n",
    "    -O ./data/GoogleNews-vectors-negative300.bin.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gunzip -c ./data/GoogleNews-vectors-negative300.bin.gz > ./data/GoogleNews-vectors-negative300.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_embeddings = KeyedVectors.load_word2vec_format('./data/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "embeddings_dim = w2v_embeddings['word'].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we want to precompute representations for all possible answers, we need to load the whole posts dataset, unlike we did for the intent classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df = pd.read_csv('./data/tagged_posts.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>title</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>Calculate age in C#</td>\n",
       "      <td>c#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>Filling a DataSet or DataTable from a LINQ que...</td>\n",
       "      <td>c#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>Reliable timer in a console application</td>\n",
       "      <td>c#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>Best way to allow plugins for a PHP application</td>\n",
       "      <td>php</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>How do I get a distinct, ordered list of names...</td>\n",
       "      <td>c#</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id                                              title  tag\n",
       "0        9                                Calculate age in C#   c#\n",
       "1       16  Filling a DataSet or DataTable from a LINQ que...   c#\n",
       "2       39            Reliable timer in a console application   c#\n",
       "3       42    Best way to allow plugins for a PHP application  php\n",
       "4       59  How do I get a distinct, ordered list of names...   c#"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tag\n",
       "c#            394451\n",
       "c_cpp         281300\n",
       "java          383456\n",
       "javascript    375867\n",
       "php           321752\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_by_tag = posts_df.groupby('tag').count().max(axis=1)\n",
    "counts_by_tag.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for each tag, we need to create two data structures, which will serve as online search index:\n",
    "\n",
    "- `tag_post_ids` — a list of post_ids with shape `(counts_by_tag[tag],)`. It will be needed to show the title and link to the thread;\n",
    "- `tag_vectors` — a matrix with shape `(counts_by_tag[tag], embeddings_dim)` where embeddings for each answer are stored.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./out/thread_embeddings_by_tags'):\n",
    "    !mkdir ./out/thread_embeddings_by_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [01:56, 11.62s/it]\n"
     ]
    }
   ],
   "source": [
    "for tag, count in tqdm.tqdm(counts_by_tag.items()):\n",
    "    tag_posts = posts_df[posts_df['tag'] == tag]\n",
    "    \n",
    "    tag_post_ids = tag_posts.post_id.tolist()\n",
    "    \n",
    "    tag_vectors = np.zeros((count, embeddings_dim), dtype=np.float32)\n",
    "    for i, title in enumerate(tag_posts['title']):\n",
    "        tag_vectors[i, :] = question_to_vec(title, w2v_embeddings, embeddings_dim)\n",
    "\n",
    "    # Dump post ids and vectors to a file.\n",
    "    filename = os.path.join('./out/thread_embeddings_by_tags', os.path.normpath('%s.pkl' % tag))\n",
    "    pickle.dump((tag_post_ids, tag_vectors), open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
