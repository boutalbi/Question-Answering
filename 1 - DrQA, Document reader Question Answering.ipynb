{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1 - DrQA, Document reader Question Answering.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNFt7onA61MXWZ0lXKmND4R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dksifoua/Question-Answering/blob/master/1%20-%20DrQA%2C%20Document%20reader%20Question%20Answering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lP-9tyjdylTg"
      },
      "source": [
        "## Load dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bm6QVw_hzHB7"
      },
      "source": [
        "!pip install tqdm --upgrade >> /dev/null 2>&1\n",
        "!pip install spacy --upgrade >> /dev/null 2>&1\n",
        "!python -m spacy download en >> /dev/null 2>&1"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJQv4DSelwnB"
      },
      "source": [
        "import tqdm\n",
        "import json\n",
        "import spacy\n",
        "import collections\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_sequence, pad_packed_sequence\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xx9pL3Hiyn7c"
      },
      "source": [
        "## Prepare data\n",
        "\n",
        "***Download data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBy3v4Pke7dq",
        "outputId": "f81d3c98-ce18-45e3-d6dd-b9c12bcaa5ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!rm -rf ./data\n",
        "!mkdir ./data\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json \\\n",
        "    -O ./data/train-v1.1.json\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json \\\n",
        "    -O ./data/dev-v1.1.json"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-31 18:25:53--  https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json\n",
            "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.111.153, 185.199.108.153, 185.199.110.153, ...\n",
            "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.111.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 30288272 (29M) [application/json]\n",
            "Saving to: ‘./data/train-v1.1.json’\n",
            "\n",
            "./data/train-v1.1.j 100%[===================>]  28.88M  38.8MB/s    in 0.7s    \n",
            "\n",
            "2020-10-31 18:25:54 (38.8 MB/s) - ‘./data/train-v1.1.json’ saved [30288272/30288272]\n",
            "\n",
            "--2020-10-31 18:25:55--  https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json\n",
            "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.111.153, 185.199.108.153, 185.199.110.153, ...\n",
            "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.111.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4854279 (4.6M) [application/json]\n",
            "Saving to: ‘./data/dev-v1.1.json’\n",
            "\n",
            "./data/dev-v1.1.jso 100%[===================>]   4.63M  16.9MB/s    in 0.3s    \n",
            "\n",
            "2020-10-31 18:25:55 (16.9 MB/s) - ‘./data/dev-v1.1.json’ saved [4854279/4854279]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9H59xUnyvAR"
      },
      "source": [
        "***Load JSON data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbZQjhA5roqo"
      },
      "source": [
        "def load(path):\n",
        "    with open(path, mode='r', encoding='utf-8') as file:\n",
        "        return json.load(file)['data']\n",
        "    raise FileNotFoundError"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqjrkTxHr3rA",
        "outputId": "e9443cd9-f8ff-4563-b616-7b36bc4a624e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_raw_data = load('./data/train-v1.1.json')\n",
        "valid_raw_data = load('./data/dev-v1.1.json')\n",
        "print(f'Length of raw train data: {len(train_raw_data):,}')\n",
        "print(f'Length of raw valid data: {len(valid_raw_data):,}')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of raw train data: 442\n",
            "Length of raw valid data: 48\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4sypWlVyxx-"
      },
      "source": [
        "***Parse JSON data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-6GE3YxsQsl"
      },
      "source": [
        "def parse(data, nlp=spacy.load('en')):\n",
        "    qas = []\n",
        "    for paragraphs in tqdm.tqdm(data):\n",
        "        for para in paragraphs['paragraphs']:\n",
        "            context = nlp(para['context'], disable=['parser'])\n",
        "            for qa in para['qas']:\n",
        "                id = qa['id']\n",
        "                question = nlp(qa['question'], disable=['parser', 'tagger', 'ner'])\n",
        "                for ans in qa['answers']:\n",
        "                    qas.append({\n",
        "                        'id': id,\n",
        "                        'context': context,\n",
        "                        'question': question,\n",
        "                        'answer': nlp(ans['text'], disable=['parser', 'tagger', 'ner']),\n",
        "                        'answer_start': ans['answer_start'],\n",
        "                    })\n",
        "    return qas"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MeqBr7Ov9ZU",
        "outputId": "fa0f2e17-fafc-45fe-b16c-5283c504d022",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_qas = parse(train_raw_data)\n",
        "valid_qas = parse(valid_raw_data)\n",
        "print()\n",
        "print(f'Length of train qa pairs: {len(train_qas):,}')\n",
        "print(f'Length of valid qa pairs: {len(valid_qas):,}')\n",
        "print('==================== Example ====================')\n",
        "print('Id:', train_qas[0]['id'])\n",
        "print('Context:', train_qas[0]['context'])\n",
        "print('Question:', train_qas[0]['question'])\n",
        "print('Answer starts at:', train_qas[0]['answer_start'])\n",
        "print('Answer:', train_qas[0]['answer'])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 442/442 [05:28<00:00,  1.35it/s]\n",
            "100%|██████████| 48/48 [00:38<00:00,  1.25it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Length of train qa pairs: 87,599\n",
            "Length of valid qa pairs: 34,726\n",
            "==================== Example ====================\n",
            "Id: 5733be284776f41900661182\n",
            "Context: Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\n",
            "Question: To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?\n",
            "Answer starts at: 515\n",
            "Answer: Saint Bernadette Soubirous\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bafKgiFv1GHa"
      },
      "source": [
        "def test_answer_start(qas):\n",
        "    \"\"\"Test answer_start are correct in train set\"\"\"\n",
        "    for qa in tqdm.tqdm(qas):\n",
        "        answer = qa['answer'].text\n",
        "        context = qa['context'].text\n",
        "        answer_start = qa['answer_start']\n",
        "        assert answer == context[answer_start:answer_start + len(answer)]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tTDTQod23-g",
        "outputId": "f8ec2739-aebe-4c3b-b1d6-acb9b0557e38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_answer_start(train_qas)\n",
        "test_answer_start(valid_qas)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 87599/87599 [00:08<00:00, 9810.06it/s]\n",
            "100%|██████████| 34726/34726 [00:03<00:00, 10883.37it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxhCfiNY28zs"
      },
      "source": [
        "***Add targets***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4bpqV3S27SQ"
      },
      "source": [
        "def add_targets(qas):\n",
        "    \"\"\"Add start and end index token\"\"\"\n",
        "    for qa in qas:\n",
        "        context = qa['context']\n",
        "        answer = qa['answer']\n",
        "        ans_start = qa['answer_start']\n",
        "        for i in range(len(context)):\n",
        "            if context[i].idx == ans_start:\n",
        "                ans = context[i:i + len(answer)]\n",
        "                qa['target'] = [ans[0].i, ans[-1].i]\n",
        "                break"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waJedA674CCH",
        "outputId": "d9d157a8-dd4d-4838-bc81-67a81a8f6d85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "add_targets(train_qas)\n",
        "add_targets(valid_qas)\n",
        "print(f'Length of train qa pairs: {len(train_qas):,}')\n",
        "print(f'Length of valid qa pairs: {len(valid_qas):,}')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of train qa pairs: 87,599\n",
            "Length of valid qa pairs: 34,726\n",
            "CPU times: user 1.55 s, sys: 45.9 ms, total: 1.59 s\n",
            "Wall time: 1.6 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT65eePm4F9w"
      },
      "source": [
        "def filter_qas(qa):\n",
        "    \"\"\"Remove bad targets\"\"\"\n",
        "    if 'target' in [*qa.keys()]:\n",
        "        start, end = qa['target']\n",
        "        return qa['context'][start:end + 1].text == qa['answer'].text\n",
        "    return False"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_nUlM_n4Mgc",
        "outputId": "48077a4f-e34b-4220-9887-14a458096f30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "train_qas = [*filter(filter_qas, train_qas)]\n",
        "valid_qas = [*filter(filter_qas, valid_qas)]\n",
        "print(f'Length of train qa pairs after filtering out bad qa pairs: {len(train_qas):,}')\n",
        "print(f'Length of valid qa pairs after filtering out bad qa pairs: {len(valid_qas):,}')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of train qa pairs after filtering out bad qa pairs: 86,597\n",
            "Length of valid qa pairs after filtering out bad qa pairs: 34,295\n",
            "CPU times: user 1.28 s, sys: 974 µs, total: 1.28 s\n",
            "Wall time: 1.28 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKEhn4eI4P5B"
      },
      "source": [
        "def test_targets(qas):\n",
        "    for qa in qas:\n",
        "        if 'target' in [*qa.keys()]:\n",
        "            start, end = qa['target']\n",
        "            assert qa['context'][start:end + 1].text == qa['answer'].text"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O_fmDJl5R7V",
        "outputId": "5d737f4f-30ce-4fef-e90e-439b11651a12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "test_targets(train_qas)\n",
        "test_targets(valid_qas)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.24 s, sys: 966 µs, total: 1.24 s\n",
            "Wall time: 1.25 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkLppZOP5Vju"
      },
      "source": [
        "***Add features***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8Y038pt5VIc"
      },
      "source": [
        "def add_features(qas):\n",
        "    \"\"\"Add extra features: Exact Match, Part-of-Speech, Name Entity Recognition & Normalized Term Frequency\"\"\"\n",
        "    for qa in tqdm.tqdm(qas):\n",
        "        question = [token.text for token in qa['question']]\n",
        "        context = qa['context']\n",
        "        counts = collections.Counter(map(lambda token: token.text.lower(), context))\n",
        "        freqs = {index: counts[token.text.lower()] for index, token in enumerate(context)}\n",
        "        freqs_norm = sum(freqs.values())\n",
        "        qa['em'], qa['pos'], qa['ner'], qa['ntf'] = zip(\n",
        "            *map(lambda index: [\n",
        "                context[index].text in question, context[index].tag_,\n",
        "                context[index].ent_type_ or 'None',\n",
        "                freqs[index] / freqs_norm\n",
        "            ], range(len(context)))\n",
        "        )"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqwcbDgPSmp8",
        "outputId": "d13024e7-7e08-46e3-ba7e-e3119bdae54c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "add_features(train_qas)\n",
        "add_features(valid_qas)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 86597/86597 [00:54<00:00, 1586.74it/s]\n",
            "100%|██████████| 34295/34295 [00:21<00:00, 1594.11it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8SrKXlfoU5y"
      },
      "source": [
        "***Build vocabularies***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LYjZhu7m6YI"
      },
      "source": [
        "class Vocab:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.vocab = None\n",
        "        self.word2count = None\n",
        "        self.word2index = None\n",
        "        self.index2word = None\n",
        "    \n",
        "    def build(self, data, specials):\n",
        "        \"\"\"\n",
        "        :param List[Union[spacy.tokens.doc.Doc, str, Tuple]] data\n",
        "        :param List[str] specials\n",
        "        \"\"\"\n",
        "        words = specials\n",
        "        type_0 = type(data[0])\n",
        "        if type_0 == spacy.tokens.doc.Doc:\n",
        "            for item in data: # context and question\n",
        "                words += [word.text.lower() for word in item]\n",
        "        elif type_0 == str: # id\n",
        "            words += data\n",
        "        elif type_0 == tuple: # pos and ner\n",
        "            for item in data:\n",
        "                words += [word.lower() for word in item]\n",
        "        self.word2count = collections.Counter(words)\n",
        "        self.vocab = sorted(self.word2count.keys())\n",
        "        self.word2index = {word: index for index, word in enumerate(self.vocab)}\n",
        "        self.index2word = {index: word for index, word in enumerate(self.vocab)}\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.vocab)\n",
        "    \n",
        "    def stoi(self, word: str):\n",
        "        return self.word2index[word]\n",
        "\n",
        "    def itos(self, index: int):\n",
        "        return self.index2word[index]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2RP28pUqYoQ",
        "outputId": "b84036f4-4f1e-418e-8e7a-89e1d8c815d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "ID, POS, NER, TEXT = Vocab(), Vocab(), Vocab(), Vocab()\n",
        "\n",
        "ids = [*map(lambda qa: qa['id'], train_qas)] + [*map(lambda qa: qa['id'], valid_qas)]\n",
        "pos, ner, contexts, questions = zip(*map(lambda qa: (qa['pos'], qa['ner'], qa['context'], qa['question']), train_qas))\n",
        "\n",
        "PAD_TOKEN = '<pad>'\n",
        "\n",
        "ID.build(data=[*set(ids)], specials=[])\n",
        "POS.build(data=[*set(pos)], specials=[PAD_TOKEN])\n",
        "NER.build(data=[*set(ner)], specials=[PAD_TOKEN])\n",
        "TEXT.build(data=[*set(contexts)] + [*set(questions)], specials=[PAD_TOKEN])\n",
        "\n",
        "print(f'Length of ID vocabulary: {len(ID):,}')\n",
        "print(f'Length of POS vocabulary: {len(POS):,}')\n",
        "print(f'Length of NER vocabulary: {len(NER):,}')\n",
        "print(f'Length of TEXT vocabulary: {len(TEXT):,}')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of ID vocabulary: 97,106\n",
            "Length of POS vocabulary: 51\n",
            "Length of NER vocabulary: 20\n",
            "Length of TEXT vocabulary: 91,445\n",
            "CPU times: user 6.51 s, sys: 95.9 ms, total: 6.61 s\n",
            "Wall time: 6.61 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t26xjG9OAikb"
      },
      "source": [
        "***Build datasets***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iotg02zlAflQ"
      },
      "source": [
        "class SQuADV1Dataset(Dataset):\n",
        "\n",
        "    def __init__(self, data, id_vocab, pos_vocab, ner_vocab, text_vocab):\n",
        "        self.data = data\n",
        "        self.id_vocab = id_vocab\n",
        "        self.pos_vocab = pos_vocab\n",
        "        self.ner_vocab = ner_vocab\n",
        "        self.text_vocab = text_vocab\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "        id = torch.LongTensor([self.id_vocab.stoi(item['id'])])\n",
        "        ctx = torch.LongTensor([*map(lambda token: self.text_vocab.stoi(token.text.lower()), item['context'])])\n",
        "        qst = torch.LongTensor([*map(lambda token: self.text_vocab.stoi(token.text.lower()), item['question'])])\n",
        "        trg = torch.LongTensor(item['target'])\n",
        "        em = torch.LongTensor(item['em'])\n",
        "        pos = torch.LongTensor([*map(lambda token: self.pos_vocab.stoi(token.lower()), item['pos'])])\n",
        "        ner = torch.LongTensor([*map(lambda token: self.ner_vocab.stoi(token.lower()), item['ner'])])\n",
        "        ntf = torch.FloatTensor(item['ntf'])\n",
        "        return id, ctx, qst, trg, em, pos, ner, ntf"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMgSisEt8ARe",
        "outputId": "e28841d8-c813-40f5-880a-3ef5b7152670",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_dataset = SQuADV1Dataset(data=train_qas, id_vocab=ID, pos_vocab=POS, ner_vocab=NER, text_vocab=TEXT)\n",
        "valid_dataset = SQuADV1Dataset(data=valid_qas, id_vocab=ID, pos_vocab=POS, ner_vocab=NER, text_vocab=TEXT)\n",
        "\n",
        "id, ctx, qst, trg, em, pos, ner, ntf = train_dataset[0]\n",
        "print(f'id shape: {id.shape}')\n",
        "print(f'ctx shape: {ctx.shape}')\n",
        "print(f'qst shape: {qst.shape}')\n",
        "print(f'trg shape: {trg.shape}')\n",
        "print(f'em shape: {em.shape}')\n",
        "print(f'pos shape: {pos.shape}')\n",
        "print(f'ner shape: {ner.shape}')\n",
        "print(f'ntf shape: {ntf.shape}')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "id shape: torch.Size([1])\n",
            "ctx shape: torch.Size([142])\n",
            "qst shape: torch.Size([14])\n",
            "trg shape: torch.Size([2])\n",
            "em shape: torch.Size([142])\n",
            "pos shape: torch.Size([142])\n",
            "ner shape: torch.Size([142])\n",
            "ntf shape: torch.Size([142])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZQaVaHt_MDc"
      },
      "source": [
        "***Build data loaders***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxy-vsK9E2W1"
      },
      "source": [
        "class DotDict(dict):\n",
        "    \"\"\"Dot notation access to dictionary attributes\"\"\"\n",
        "    __getattr__ = dict.get\n",
        "    __setattr__ = dict.__setitem__\n",
        "    __delattr__ = dict.__delitem__"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYMYz3-SBYzf"
      },
      "source": [
        "def add_padding(batch, pad_token=PAD_TOKEN, text_vocab=TEXT, pos_vocab=POS, ner_vocab=NER, include_lengths=True):\n",
        "    \"\"\"Pad batch of sequence with different lengths\"\"\"\n",
        "    batch_id, batch_ctx, batch_qst, batch_trg, batch_em, batch_pos, batch_ner, batch_ntf = zip(*batch)\n",
        "    if include_lengths:\n",
        "        len_ctx = torch.LongTensor([ctx.size(0) for ctx in batch_ctx])\n",
        "        len_qst = torch.LongTensor([qst.size(0) for qst in batch_qst])\n",
        "    batch_padded_id = pad_sequence(batch_id, batch_first=True)\n",
        "    batch_padded_ctx = pad_sequence(batch_ctx, batch_first=True, padding_value=text_vocab.stoi(pad_token))\n",
        "    batch_padded_qst = pad_sequence(batch_qst, batch_first=True, padding_value=text_vocab.stoi(pad_token))\n",
        "    batch_padded_trg = pad_sequence(batch_trg, batch_first=True)\n",
        "    batch_padded_em = pad_sequence(batch_em, batch_first=True)\n",
        "    batch_padded_pos = pad_sequence(batch_pos, batch_first=True, padding_value=pos_vocab.stoi(pad_token))\n",
        "    batch_padded_ner = pad_sequence(batch_ner, batch_first=True, padding_value=ner_vocab.stoi(pad_token))\n",
        "    batch_padded_ntf = pad_sequence(batch_ntf, batch_first=True)\n",
        "    return DotDict({\n",
        "        'id': batch_padded_id,\n",
        "        'ctx': (batch_padded_ctx, len_ctx) if include_lengths else batch_padded_ctx,\n",
        "        'qst': (batch_padded_qst, len_qst) if include_lengths else batch_padded_qst,\n",
        "        'trg': batch_padded_trg,\n",
        "        'em': batch_padded_em,\n",
        "        'pos': batch_padded_pos,\n",
        "        'ner': batch_padded_ner,\n",
        "        'ntf': batch_padded_ntf,\n",
        "    })"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zu2ovPqxA7Ix",
        "outputId": "3a3a8760-bfeb-4527-d589-526fb484cee4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=add_padding, pin_memory=True)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=add_padding, pin_memory=True)\n",
        "\n",
        "for batch in train_dataloader:\n",
        "    print('batch.id shape:', batch.id.shape)\n",
        "    print('batch.ctx shape:', batch.ctx[0].shape, batch.ctx[1].shape)\n",
        "    print('batch.qst shape:', batch.qst[0].shape, batch.qst[1].shape)\n",
        "    print('batch.trg shape:', batch.trg.shape)\n",
        "    print('batch.em shape:', batch.em.shape)\n",
        "    print('batch.pos shape:', batch.pos.shape)\n",
        "    print('batch.ner shape:', batch.ner.shape)\n",
        "    print('batch.ntf shape:', batch.ntf.shape)\n",
        "    break"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch.id shape: torch.Size([64, 1])\n",
            "batch.ctx shape: torch.Size([64, 253]) torch.Size([64])\n",
            "batch.qst shape: torch.Size([64, 19]) torch.Size([64])\n",
            "batch.trg shape: torch.Size([64, 2])\n",
            "batch.em shape: torch.Size([64, 253])\n",
            "batch.pos shape: torch.Size([64, 253])\n",
            "batch.ner shape: torch.Size([64, 253])\n",
            "batch.ntf shape: torch.Size([64, 253])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2O79r_CLvGu"
      },
      "source": [
        "***TODO: Download pretrained GloVe embedding***\n",
        "\n",
        "It will take about 16 minutes to download from Colab!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxnYdks-L31E"
      },
      "source": [
        "## Modeling\n",
        "\n",
        "***Stacked Bidirectional LSTM Layer***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoHYvqQQCEGw"
      },
      "source": [
        "class StackedBiLSTMsLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_size, hidden_size, n_layers, dropout):\n",
        "        super(StackedBiLSTMsLayer, self).__init__()\n",
        "        self.embedding_size = embedding_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.lstms = nn.ModuleList([nn.LSTM(embedding_size if i == 0 else hidden_size * 2, embedding_size,\n",
        "                                            batch_first=True, num_layers=n_layers, bidirectional=True)\n",
        "                                    for i in range(n_layers)])\n",
        "    \n",
        "    def apply_lstm(self, layer, inputs, lengths):\n",
        "        \"\"\"\n",
        "        :param nn.LSTM layer\n",
        "        :param FloatTensor[batch_size, seq_len, embedding_size] inputs\n",
        "        :param LongTensor[batch_size, seq_len] lengths\n",
        "        :return FloatTensor[batch_size, seq_len, hidden_size * 2] out_padded\n",
        "        \"\"\"\n",
        "        packed = pack_padded_sequence(inputs, lengths, batch_first=True, enforce_sorted=False)\n",
        "        out_packed, _ = layer(self.dropout(packed))\n",
        "        out_padded, out_lengths = pad_packed_sequence(out_packed, batch_first=True) # [batch_size, seq_len, hidden_size * 2]\n",
        "        return out_padded, out_lengths\n",
        "    \n",
        "    def forward(self, input_embedded, sequence_lengths):\n",
        "        \"\"\"\n",
        "        :param FloatTensor[batch_size, seq_len, embedding_size] input_embedded\n",
        "        :param LongTensor[batch_size, seq_len] sequence_lengths\n",
        "        :return FloatTensor[batch_size, seq_len, hidden_size * n_layers * 2]\n",
        "        \"\"\"\n",
        "        packed = nn.utils.rnn.pack_padded_sequence(input_embedded, sequence_lengths)\n",
        "        outputs, lens = [packed], sequence_lengths\n",
        "        for lstm in self.lstms:\n",
        "            out, lens = self.apply_lstm(layer=lstm, inputs=outputs[-1], lengths=lens)\n",
        "            outputs.append(out)\n",
        "        return self.dropout(torch.cat(outputs[1:], dim=-1))"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oazq30eW3_T"
      },
      "source": [
        "***Aligned Question Embedding Layer***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATOQC6-pWzq_"
      },
      "source": [
        "class AlignQuestionEmbeddingLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden_size):\n",
        "        super(AlignQuestionEmbeddingLayer, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.linear = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, ctx_embed, qst_embed, qst_mask):\n",
        "        \"\"\"\n",
        "        :param FloatTensor[batch_size, ctx_len, embedding_size] ctx_embed\n",
        "        :param FloatTensor[batch_size, qst_len, embedding_size] qst_embed\n",
        "        :param IntTensor[batch_size, qst_len] qst_mask\n",
        "        :return FloatTensor[batch_size, ctx_len, hidden_size]\n",
        "        \"\"\"\n",
        "        ctx_embed = F.relu(self.linear(ctx_embed)) # [batch_size, ctx_len, hidden_size]\n",
        "        qst_embed = F.relu(self.linear(qst_embed)) # [batch_size, qst_len, hidden_size]\n",
        "        scores = torch.bmm(ctx_embed, qst_embed.transpose(-1, -2)) # [batch_size, ctx_len, qst_len]\n",
        "        scores = scores.masked_fill(qst_mask.unsqueeze(1) == 0, 1e-18)\n",
        "        attention_weights = F.softmax(scores, dim=-1) # [batch_size, ctx_len, qst_len]\n",
        "        return torch.bmm(attention_weights, qst_embed)"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImX8ayztYjsK"
      },
      "source": [
        "***Question Encoding Layer***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Whil-FgVYhgy"
      },
      "source": [
        "class QuestionEncodingLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_size, hidden_size, dropout, n_layers):\n",
        "        super(QuestionEncodingLayer, self).__init__()\n",
        "        self.embedding_size = embedding_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_layers = n_layers\n",
        "        self.stacked_bilstms_layer = StackedBiLSTMsLayer(embedding_size=embedding_size, hidden_size=hidden_size, n_layers=n_layers, dropout=dropout)\n",
        "        self.linear = nn.Linear(embedding_size, 1)\n",
        "    \n",
        "    def linear_self_attention(self, qst_embed, qst_mask):\n",
        "        \"\"\"\n",
        "        :param FloatTensor[batch_size, qst_len, embedding_size] qst_embed\n",
        "        :param IntTensor[batch_size, qst_len] qst_mask\n",
        "        :return FloatTensor[batch_size, qst_len]\n",
        "        \"\"\"\n",
        "        scores = self.linear(qst_embed).squeeze(-1) # [batch_size, qst_len]\n",
        "        scores = scores.masked_fill(qst_mask == 0, 1e-18)\n",
        "        return F.softmax(scores, dim=-1)\n",
        "\n",
        "    \n",
        "    def forward(self, qst_embed, qst_lengths, qst_mask):\n",
        "        \"\"\"\n",
        "        :param FloatTensor[batch_size, qst_len, embedding_size] qst_embed\n",
        "        :param IntTensor[batch_size, qst_len] qst_lengths\n",
        "        :param IntTensor[batch_size, qst_len] qst_mask\n",
        "        :return FloatTensor[batch_size, hidden_size * n_layers * 2]\n",
        "        \"\"\"\n",
        "        attention_weights = self.linear_self_attention(qst_embed=qst_embed, qst_mask=qst_mask) # [batch_size, qst_len]\n",
        "        lstm_outputs = self.stacked_bilstms_layer(input_embedded=qst_embed, sequence_lengths=qst_lengths) # [batch_size, qst_len, hidden_size * n_layers * 2]\n",
        "        return torch.bmm(attention_weights.unsqueeze(1), lstm_outputs).squeeze(1)"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hFIZnmUaFAu"
      },
      "source": [
        "***BiLinear Attention Layer***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZGOH3IhaEZw"
      },
      "source": [
        "class BiLinearAttentionLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, ctx_size, qst_size):\n",
        "        super(BiLinearAttentionLayer, self).__init__()\n",
        "        self.ctx_size = ctx_size\n",
        "        self.qst_size = qst_size\n",
        "        self.linear = nn.Linear(qst_size, ctx_size)\n",
        "    \n",
        "    def forward(self, ctx_encoded, qst_encoded, ctx_mask):\n",
        "        \"\"\"\n",
        "        :param FloatTensor[batch_size, ctx_len, ctx_size] ctx_encoded\n",
        "        :param FloatTensor[batch_size, qst_size] qst_encoded\n",
        "        :param IntTensor[batch_size, ctx_len] ctx_mask\n",
        "        :return FloatTensor[batch_size, ctx_len, hidden_size]\n",
        "        \"\"\"\n",
        "        qst_encoded = self.linear(qst_encoded) # [batch_size, ctx_size]\n",
        "        scores = torch.bmm(ctx_encoded, qst_encoded.unsqueeze(-1)) # [batch_size, ctx_len, 1]\n",
        "        scores = scores.squeeze(-1).masked_fill(ctx_mask == 0, 1e-18) # [batch_size, ctx_len]\n",
        "        return scores"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzrmk6D7agHH"
      },
      "source": [
        "***Document reader Question Answering Model***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlZlTFXOae_o"
      },
      "source": [
        "class DrQA(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_size, n_extra_features, hidden_size, n_layers, dropout, pad_index):\n",
        "        super(DrQA, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.n_extra_features = n_extra_features\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.pad_index = pad_index\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_size, padding_idx=pad_index)\n",
        "        self.align_question_embedding_layer = AlignQuestionEmbeddingLayer(hidden_size=embedding_size)\n",
        "        self.ctx_stacked_bi_lstm_layer = StackedBiLSTMsLayer(embedding_size=embedding_size * 2 + n_extra_features,\n",
        "                                                             hidden_size=hidden_size, n_layers=n_layers, dropout=dropout)\n",
        "        self.qst_encoding_layer = QuestionEncodingLayer(embedding_size=embedding_size, hidden_size=hidden_size, dropout=dropout, n_layers=n_layers)\n",
        "        self.bilinear_attention_layer_start = BiLinearAttentionLayer(ctx_size=hidden_size * n_layers * 2, qst_size=hidden_size * n_layers * 2)\n",
        "        self.bilinear_attention_layer_end = BiLinearAttentionLayer(ctx_size=hidden_size * n_layers * 2, qst_size=hidden_size * n_layers * 2)\n",
        "    \n",
        "    def make_ctx_mask(self, ctx_sequences):\n",
        "        \"\"\"\n",
        "        :param LongTensor[batch_size, ctx_len] ctx_sequences\n",
        "        :return IntTensor[batch_size, ctx_len]\n",
        "        \"\"\"\n",
        "        return ctx_sequences != self.pad_index\n",
        "    \n",
        "    def make_qst_mask(self, qst_sequences):\n",
        "        \"\"\"\n",
        "        :param LongTensor[batch_size, qst_len] qst_sequences\n",
        "        :return IntTensor[batch_size, qst_len]\n",
        "        \"\"\"\n",
        "        return qst_sequences != self.pad_index\n",
        "    \n",
        "    @staticmethod\n",
        "    def decode(starts, ends):\n",
        "        \"\"\"\n",
        "        :param IntTensor[batch_size, ctx_len] starts\n",
        "        :param IntTensor[batch_size, ctx_len] ends\n",
        "        :return list(int) start_indexes\n",
        "        :return list(int) end_indexes\n",
        "        :return list(float) pred_probas\n",
        "        \"\"\"\n",
        "        start_indexes, end_indexes, pred_probas = [], [], []\n",
        "        for i in range(starts.size(0)):\n",
        "            probas = torch.ger(starts[i], ends[i]) # [ctx_len, ctx_len]\n",
        "            proba, index = torch.topk(probas.view(-1), k=1)\n",
        "            start_indexes.append(index.tolist()[0] // probas.size(0))\n",
        "            end_indexes.append(index.tolist()[0] % probas.size(1))\n",
        "            pred_probas.append(proba.tolist()[0])\n",
        "        return start_indexes, end_indexes, pred_probas\n",
        "    \n",
        "    def forward(self, ctx_sequences, ctx_lengths, qst_sequences, qst_lengths, em_sequences, pos_sequences, ner_sequences, ntf_sequences):\n",
        "        \"\"\"\n",
        "        :param LongTensor[batch_size, ctx_len] ctx_sequences\n",
        "        :param Tensor[batch_size,] ctx_lengths\n",
        "        :param LongTensor[batch_size, qst_len] qst_sequences\n",
        "        :param Tensor[batch_size,] qst_lengths\n",
        "        :param LongTensor[batch_size, ctx_len] em_sequences\n",
        "        :param LongTensor[batch_size, ctx_len] pos_sequences\n",
        "        :param LongTensor[batch_size, ctx_len] ner_sequences\n",
        "        :param LongTensor[batch_size, ctx_len] ntf_sequences\n",
        "        :return Tensor[batch_size, ctx_len] starts\n",
        "        :return Tensor[batch_size, ctx_len] ends\n",
        "        \"\"\"\n",
        "        ctx_mask = self.make_ctx_mask(ctx_sequences) # [batch_size, ctx_len]\n",
        "        qst_mask = self.make_qst_mask(qst_sequences) # [batch_size, qst_len]\n",
        "        ctx_embedded = self.dropout(self.embedding(ctx_sequences)) # [batch_size, ctx_len, embedding_size]\n",
        "        qst_embedded = self.dropout(self.embedding(qst_sequences)) # [batch_size, ctx_len, embedding_size]\n",
        "        ctx_aligned = self.align_question_embedding_layer(ctx_embed=ctx_embedded, qst_embed=qst_embedded,\n",
        "                                                          qst_mask=qst_mask) # [batch_size, ctx_len, embedding_size]\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}