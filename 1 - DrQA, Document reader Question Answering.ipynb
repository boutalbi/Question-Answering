{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1 - DrQA, Document reader Question Answering.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPCAmT8kRFRha6V3OmRPCJd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dksifoua/Question-Answering/blob/master/1%20-%20DrQA%2C%20Document%20reader%20Question%20Answering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMGpLvYNKR78",
        "outputId": "11833491-53a3-494d-ec4f-3388b07b6751",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Nov  1 00:16:14 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.32.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   30C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lP-9tyjdylTg"
      },
      "source": [
        "## Load dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bm6QVw_hzHB7"
      },
      "source": [
        "!pip install tqdm --upgrade >> /dev/null 2>&1\n",
        "!pip install spacy --upgrade >> /dev/null 2>&1\n",
        "!python -m spacy download en >> /dev/null 2>&1"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJQv4DSelwnB"
      },
      "source": [
        "import re\n",
        "import json\n",
        "import time\n",
        "import tqdm\n",
        "import spacy\n",
        "import string\n",
        "import collections\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_sequence, pad_packed_sequence\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 317,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cw16-fZCDHHu",
        "outputId": "9064526b-34a7-4ba0-aae0-fab56468b390",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "SEED = 546\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Device: {DEVICE}')"
      ],
      "execution_count": 318,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xx9pL3Hiyn7c"
      },
      "source": [
        "## Prepare data\n",
        "\n",
        "***Download data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBy3v4Pke7dq",
        "outputId": "4016d958-c705-48e6-e37a-11a86700476d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!rm -rf ./data\n",
        "!mkdir ./data\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json \\\n",
        "    -O ./data/train-v1.1.json\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json \\\n",
        "    -O ./data/dev-v1.1.json"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-01 00:18:50--  https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json\n",
            "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n",
            "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.108.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 30288272 (29M) [application/json]\n",
            "Saving to: ‘./data/train-v1.1.json’\n",
            "\n",
            "./data/train-v1.1.j 100%[===================>]  28.88M  73.3MB/s    in 0.4s    \n",
            "\n",
            "2020-11-01 00:18:52 (73.3 MB/s) - ‘./data/train-v1.1.json’ saved [30288272/30288272]\n",
            "\n",
            "--2020-11-01 00:18:52--  https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json\n",
            "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n",
            "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.108.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4854279 (4.6M) [application/json]\n",
            "Saving to: ‘./data/dev-v1.1.json’\n",
            "\n",
            "./data/dev-v1.1.jso 100%[===================>]   4.63M  20.5MB/s    in 0.2s    \n",
            "\n",
            "2020-11-01 00:18:53 (20.5 MB/s) - ‘./data/dev-v1.1.json’ saved [4854279/4854279]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9H59xUnyvAR"
      },
      "source": [
        "***Load JSON data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbZQjhA5roqo"
      },
      "source": [
        "def load(path):\n",
        "    with open(path, mode='r', encoding='utf-8') as file:\n",
        "        return json.load(file)['data']\n",
        "    raise FileNotFoundError"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqjrkTxHr3rA",
        "outputId": "22ef1aab-1489-4cfe-a6c3-8e55b943c1e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_raw_data = load('./data/train-v1.1.json')\n",
        "valid_raw_data = load('./data/dev-v1.1.json')\n",
        "print(f'Length of raw train data: {len(train_raw_data):,}')\n",
        "print(f'Length of raw valid data: {len(valid_raw_data):,}')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of raw train data: 442\n",
            "Length of raw valid data: 48\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4sypWlVyxx-"
      },
      "source": [
        "***Parse JSON data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-6GE3YxsQsl"
      },
      "source": [
        "def parse(data, nlp=spacy.load('en')):\n",
        "    qas = []\n",
        "    for paragraphs in tqdm.tqdm(data):\n",
        "        for para in paragraphs['paragraphs']:\n",
        "            context = nlp(para['context'], disable=['parser'])\n",
        "            for qa in para['qas']:\n",
        "                id = qa['id']\n",
        "                question = nlp(qa['question'], disable=['parser', 'tagger', 'ner'])\n",
        "                for ans in qa['answers']:\n",
        "                    qas.append({\n",
        "                        'id': id,\n",
        "                        'context': context,\n",
        "                        'question': question,\n",
        "                        'answer': nlp(ans['text'], disable=['parser', 'tagger', 'ner']),\n",
        "                        'answer_start': ans['answer_start'],\n",
        "                    })\n",
        "    return qas"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MeqBr7Ov9ZU",
        "outputId": "6c6c28ef-ea15-42f4-8198-b70e15f10954",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_qas = parse(train_raw_data)\n",
        "valid_qas = parse(valid_raw_data)\n",
        "print()\n",
        "print(f'Length of train qa pairs: {len(train_qas):,}')\n",
        "print(f'Length of valid qa pairs: {len(valid_qas):,}')\n",
        "print('==================== Example ====================')\n",
        "print('Id:', train_qas[0]['id'])\n",
        "print('Context:', train_qas[0]['context'])\n",
        "print('Question:', train_qas[0]['question'])\n",
        "print('Answer starts at:', train_qas[0]['answer_start'])\n",
        "print('Answer:', train_qas[0]['answer'])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 442/442 [04:53<00:00,  1.51it/s]\n",
            "100%|██████████| 48/48 [00:34<00:00,  1.41it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Length of train qa pairs: 87,599\n",
            "Length of valid qa pairs: 34,726\n",
            "==================== Example ====================\n",
            "Id: 5733be284776f41900661182\n",
            "Context: Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\n",
            "Question: To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?\n",
            "Answer starts at: 515\n",
            "Answer: Saint Bernadette Soubirous\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bafKgiFv1GHa"
      },
      "source": [
        "def test_answer_start(qas):\n",
        "    \"\"\"Test answer_start are correct in train set\"\"\"\n",
        "    for qa in tqdm.tqdm(qas):\n",
        "        answer = qa['answer'].text\n",
        "        context = qa['context'].text\n",
        "        answer_start = qa['answer_start']\n",
        "        assert answer == context[answer_start:answer_start + len(answer)]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tTDTQod23-g",
        "outputId": "14edc2f3-3969-4e54-bd18-af6554ae2d2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_answer_start(train_qas)\n",
        "test_answer_start(valid_qas)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 87599/87599 [00:08<00:00, 10567.86it/s]\n",
            "100%|██████████| 34726/34726 [00:03<00:00, 11420.74it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxhCfiNY28zs"
      },
      "source": [
        "***Add targets***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4bpqV3S27SQ"
      },
      "source": [
        "def add_targets(qas):\n",
        "    \"\"\"Add start and end index token\"\"\"\n",
        "    for qa in qas:\n",
        "        context = qa['context']\n",
        "        answer = qa['answer']\n",
        "        ans_start = qa['answer_start']\n",
        "        for i in range(len(context)):\n",
        "            if context[i].idx == ans_start:\n",
        "                ans = context[i:i + len(answer)]\n",
        "                qa['target'] = [ans[0].i, ans[-1].i]\n",
        "                break"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waJedA674CCH",
        "outputId": "76a61f04-1d7d-41d0-f7ea-91e4746686c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "add_targets(train_qas)\n",
        "add_targets(valid_qas)\n",
        "print(f'Length of train qa pairs: {len(train_qas):,}')\n",
        "print(f'Length of valid qa pairs: {len(valid_qas):,}')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of train qa pairs: 87,599\n",
            "Length of valid qa pairs: 34,726\n",
            "CPU times: user 1.52 s, sys: 16 ms, total: 1.53 s\n",
            "Wall time: 1.54 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT65eePm4F9w"
      },
      "source": [
        "def filter_qas(qa):\n",
        "    \"\"\"Remove bad targets\"\"\"\n",
        "    if 'target' in [*qa.keys()]:\n",
        "        start, end = qa['target']\n",
        "        return qa['context'][start:end + 1].text == qa['answer'].text\n",
        "    return False"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_nUlM_n4Mgc",
        "outputId": "0006ad2e-922e-473a-ebb3-eaa0ef9333f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "train_qas = [*filter(filter_qas, train_qas)]\n",
        "valid_qas = [*filter(filter_qas, valid_qas)]\n",
        "print(f'Length of train qa pairs after filtering out bad qa pairs: {len(train_qas):,}')\n",
        "print(f'Length of valid qa pairs after filtering out bad qa pairs: {len(valid_qas):,}')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of train qa pairs after filtering out bad qa pairs: 86,597\n",
            "Length of valid qa pairs after filtering out bad qa pairs: 34,295\n",
            "CPU times: user 1.15 s, sys: 4.99 ms, total: 1.16 s\n",
            "Wall time: 1.16 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKEhn4eI4P5B"
      },
      "source": [
        "def test_targets(qas):\n",
        "    for qa in qas:\n",
        "        if 'target' in [*qa.keys()]:\n",
        "            start, end = qa['target']\n",
        "            assert qa['context'][start:end + 1].text == qa['answer'].text"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O_fmDJl5R7V",
        "outputId": "f5543b24-3aa4-4a6f-95d2-ccf2cc08acff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "test_targets(train_qas)\n",
        "test_targets(valid_qas)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.12 s, sys: 980 µs, total: 1.12 s\n",
            "Wall time: 1.13 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkLppZOP5Vju"
      },
      "source": [
        "***Add features***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8Y038pt5VIc"
      },
      "source": [
        "def add_features(qas):\n",
        "    \"\"\"Add extra features: Exact Match, Part-of-Speech, Name Entity Recognition & Normalized Term Frequency\"\"\"\n",
        "    for qa in tqdm.tqdm(qas):\n",
        "        question = [token.text.lower() for token in qa['question']]\n",
        "        context = qa['context']\n",
        "        counts = collections.Counter(map(lambda token: token.text.lower(), context))\n",
        "        freqs = {index: counts[token.text.lower()] for index, token in enumerate(context)}\n",
        "        freqs_norm = sum(freqs.values())\n",
        "        qa['em'], qa['pos'], qa['ner'], qa['ntf'] = zip(\n",
        "            *map(lambda index: [\n",
        "                context[index].text.lower() in question, context[index].tag_,\n",
        "                context[index].ent_type_ or 'None',\n",
        "                freqs[index] / freqs_norm\n",
        "            ], range(len(context)))\n",
        "        )"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqwcbDgPSmp8",
        "outputId": "0987df46-749c-4d97-e4ed-acc1d8860582",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "add_features(train_qas)\n",
        "add_features(valid_qas)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 86597/86597 [00:51<00:00, 1668.80it/s]\n",
            "100%|██████████| 34295/34295 [00:21<00:00, 1624.91it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8SrKXlfoU5y"
      },
      "source": [
        "***Build vocabularies***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LYjZhu7m6YI"
      },
      "source": [
        "class Vocab:\n",
        "\n",
        "    def __init__(self, pad_token, unk_token):\n",
        "        self.pad_token = pad_token\n",
        "        self.unk_token = unk_token\n",
        "        self.vocab = None\n",
        "        self.word2count = None\n",
        "        self.word2index = None\n",
        "        self.index2word = None\n",
        "    \n",
        "    def build(self, data, min_freq):\n",
        "        \"\"\"\n",
        "        :param List[Union[spacy.tokens.doc.Doc, str, Tuple]] data\n",
        "        :param int min_freq\n",
        "        \"\"\"\n",
        "        words = [self.pad_token, self.unk_token]\n",
        "        type_0 = type(data[0])\n",
        "        if type_0 == spacy.tokens.doc.Doc:\n",
        "            for item in data: # context and question\n",
        "                words += [word.text.lower() for word in item]\n",
        "        elif type_0 == str: # id\n",
        "            words += data\n",
        "        elif type_0 == tuple: # pos and ner\n",
        "            for item in data:\n",
        "                words += [word.lower() for word in item]\n",
        "        self.word2count = collections.Counter(words)\n",
        "        self.vocab = sorted(filter(\n",
        "            lambda word: self.word2count[word] >= min_freq or word == self.pad_token or word == self.unk_token, self.word2count\n",
        "        ))\n",
        "        self.word2index = {word: index for index, word in enumerate(self.vocab)}\n",
        "        self.index2word = {index: word for index, word in enumerate(self.vocab)}\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.vocab)\n",
        "    \n",
        "    def stoi(self, word):\n",
        "        return self.word2index.get(str(word), self.word2index[self.unk_token])\n",
        "\n",
        "    def itos(self, index):\n",
        "        return self.index2word[index]"
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2RP28pUqYoQ",
        "outputId": "4d6da430-4e61-4139-8324-196c2be1aeb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "PAD_TOKEN = '<pad>'\n",
        "UNK_TOKEN = '<unk>'\n",
        "\n",
        "ID = Vocab(pad_token=PAD_TOKEN, unk_token=UNK_TOKEN)\n",
        "POS = Vocab(pad_token=PAD_TOKEN, unk_token=UNK_TOKEN)\n",
        "NER = Vocab(pad_token=PAD_TOKEN, unk_token=UNK_TOKEN)\n",
        "TEXT = Vocab(pad_token=PAD_TOKEN, unk_token=UNK_TOKEN)\n",
        "\n",
        "ids = [*map(lambda qa: qa['id'], train_qas)] + [*map(lambda qa: qa['id'], valid_qas)]\n",
        "pos, ner, contexts, questions = zip(*map(lambda qa: (qa['pos'], qa['ner'], qa['context'], qa['question']), train_qas))\n",
        "\n",
        "ID.build(data=[*set(ids)], min_freq=0)\n",
        "POS.build(data=[*set(pos)], min_freq=0)\n",
        "NER.build(data=[*set(ner)], min_freq=0)\n",
        "TEXT.build(data=[*set(contexts)] + [*set(questions)], min_freq=5)\n",
        "\n",
        "print(f'Length of ID vocabulary: {len(ID):,}')\n",
        "print(f'Length of POS vocabulary: {len(POS):,}')\n",
        "print(f'Length of NER vocabulary: {len(NER):,}')\n",
        "print(f'Length of TEXT vocabulary: {len(TEXT):,}')"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of ID vocabulary: 97,108\n",
            "Length of POS vocabulary: 52\n",
            "Length of NER vocabulary: 21\n",
            "Length of TEXT vocabulary: 26,885\n",
            "CPU times: user 5.61 s, sys: 12.6 ms, total: 5.63 s\n",
            "Wall time: 5.63 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t26xjG9OAikb"
      },
      "source": [
        "***Build datasets***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iotg02zlAflQ"
      },
      "source": [
        "class SQuADV1Dataset(Dataset):\n",
        "\n",
        "    def __init__(self, data, id_vocab, pos_vocab, ner_vocab, text_vocab):\n",
        "        self.data = data\n",
        "        self.id_vocab = id_vocab\n",
        "        self.pos_vocab = pos_vocab\n",
        "        self.ner_vocab = ner_vocab\n",
        "        self.text_vocab = text_vocab\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "        id = torch.LongTensor([self.id_vocab.stoi(item['id'])])\n",
        "        ctx = torch.LongTensor([*map(lambda token: self.text_vocab.stoi(token.text.lower()), item['context'])])\n",
        "        qst = torch.LongTensor([*map(lambda token: self.text_vocab.stoi(token.text.lower()), item['question'])])\n",
        "        trg = torch.LongTensor(item['target'])\n",
        "        em = torch.LongTensor(item['em'])\n",
        "        pos = torch.LongTensor([*map(lambda token: self.pos_vocab.stoi(token.lower()), item['pos'])])\n",
        "        ner = torch.LongTensor([*map(lambda token: self.ner_vocab.stoi(token.lower()), item['ner'])])\n",
        "        ntf = torch.FloatTensor(item['ntf'])\n",
        "        return id, ctx, qst, trg, em, pos, ner, ntf"
      ],
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMgSisEt8ARe",
        "outputId": "3abef599-760f-43ae-f70d-2a4c525c2de4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_dataset = SQuADV1Dataset(data=train_qas, id_vocab=ID, pos_vocab=POS, ner_vocab=NER, text_vocab=TEXT)\n",
        "valid_dataset = SQuADV1Dataset(data=valid_qas, id_vocab=ID, pos_vocab=POS, ner_vocab=NER, text_vocab=TEXT)\n",
        "\n",
        "id, ctx, qst, trg, em, pos, ner, ntf = train_dataset[0]\n",
        "print(f'id shape: {id.shape}')\n",
        "print(f'ctx shape: {ctx.shape}')\n",
        "print(f'qst shape: {qst.shape}')\n",
        "print(f'trg shape: {trg.shape}')\n",
        "print(f'em shape: {em.shape}')\n",
        "print(f'pos shape: {pos.shape}')\n",
        "print(f'ner shape: {ner.shape}')\n",
        "print(f'ntf shape: {ntf.shape}')"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "id shape: torch.Size([1])\n",
            "ctx shape: torch.Size([142])\n",
            "qst shape: torch.Size([14])\n",
            "trg shape: torch.Size([2])\n",
            "em shape: torch.Size([142])\n",
            "pos shape: torch.Size([142])\n",
            "ner shape: torch.Size([142])\n",
            "ntf shape: torch.Size([142])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZQaVaHt_MDc"
      },
      "source": [
        "***Build data loaders***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPKrJOpKTlN1"
      },
      "source": [
        "class DotDict(dict):\n",
        "    __getattr__ = dict.get"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYMYz3-SBYzf"
      },
      "source": [
        "def add_padding(batch, pad_token=PAD_TOKEN, text_vocab=TEXT, pos_vocab=POS, ner_vocab=NER, include_lengths=True, device=DEVICE):\n",
        "    \"\"\"Pad batch of sequence with different lengths\"\"\"\n",
        "    batch_id, batch_ctx, batch_qst, batch_trg, batch_em, batch_pos, batch_ner, batch_ntf = zip(*batch)\n",
        "    if include_lengths:\n",
        "        len_ctx = torch.LongTensor([ctx.size(0) for ctx in batch_ctx]).to(device)\n",
        "        len_qst = torch.LongTensor([qst.size(0) for qst in batch_qst]).to(device)\n",
        "    batch_padded_id = pad_sequence(batch_id, batch_first=True).to(device)\n",
        "    batch_padded_ctx = pad_sequence(batch_ctx, batch_first=True, padding_value=text_vocab.stoi(pad_token)).to(device)\n",
        "    batch_padded_qst = pad_sequence(batch_qst, batch_first=True, padding_value=text_vocab.stoi(pad_token)).to(device)\n",
        "    batch_padded_trg = pad_sequence(batch_trg, batch_first=True).to(device)\n",
        "    batch_padded_em = pad_sequence(batch_em, batch_first=True).to(device)\n",
        "    batch_padded_pos = pad_sequence(batch_pos, batch_first=True, padding_value=pos_vocab.stoi(pad_token)).to(device)\n",
        "    batch_padded_ner = pad_sequence(batch_ner, batch_first=True, padding_value=ner_vocab.stoi(pad_token)).to(device)\n",
        "    batch_padded_ntf = pad_sequence(batch_ntf, batch_first=True).to(device)\n",
        "    return DotDict({\n",
        "        'id': batch_padded_id,\n",
        "        'ctx': (batch_padded_ctx, len_ctx) if include_lengths else batch_padded_ctx,\n",
        "        'qst': (batch_padded_qst, len_qst) if include_lengths else batch_padded_qst,\n",
        "        'trg': batch_padded_trg,\n",
        "        'em': batch_padded_em,\n",
        "        'pos': batch_padded_pos,\n",
        "        'ner': batch_padded_ner,\n",
        "        'ntf': batch_padded_ntf,\n",
        "    })"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zu2ovPqxA7Ix",
        "outputId": "3f94c073-2df0-4d9d-f3ea-6b5f8560d60e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=add_padding)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, collate_fn=add_padding)\n",
        "\n",
        "for batch in train_dataloader:\n",
        "    print('batch.id shape:', batch.id.shape)\n",
        "    print('batch.ctx shape:', batch.ctx[0].shape, batch.ctx[1].shape)\n",
        "    print('batch.qst shape:', batch.qst[0].shape, batch.qst[1].shape)\n",
        "    print('batch.trg shape:', batch.trg.shape)\n",
        "    print('batch.em shape:', batch.em.shape)\n",
        "    print('batch.pos shape:', batch.pos.shape)\n",
        "    print('batch.ner shape:', batch.ner.shape)\n",
        "    print('batch.ntf shape:', batch.ntf.shape)\n",
        "    break"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch.id shape: torch.Size([64, 1])\n",
            "batch.ctx shape: torch.Size([64, 253]) torch.Size([64])\n",
            "batch.qst shape: torch.Size([64, 19]) torch.Size([64])\n",
            "batch.trg shape: torch.Size([64, 2])\n",
            "batch.em shape: torch.Size([64, 253])\n",
            "batch.pos shape: torch.Size([64, 253])\n",
            "batch.ner shape: torch.Size([64, 253])\n",
            "batch.ntf shape: torch.Size([64, 253])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2O79r_CLvGu"
      },
      "source": [
        "***TODO: Download pretrained GloVe embedding***\n",
        "\n",
        "It will take about 16 minutes to download from Colab!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxnYdks-L31E"
      },
      "source": [
        "## Modeling\n",
        "\n",
        "***Stacked Bidirectional LSTM Layer***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoHYvqQQCEGw"
      },
      "source": [
        "class StackedBiLSTMsLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_size, hidden_size, n_layers, dropout):\n",
        "        super(StackedBiLSTMsLayer, self).__init__()\n",
        "        self.embedding_size = embedding_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.lstms = nn.ModuleList([nn.LSTM(embedding_size if i == 0 else hidden_size * 2, hidden_size,\n",
        "                                            batch_first=True, num_layers=n_layers, bidirectional=True)\n",
        "                                    for i in range(n_layers)])\n",
        "    \n",
        "    def apply_lstm(self, layer, inputs, lengths):\n",
        "        \"\"\"\n",
        "        :param nn.LSTM layer\n",
        "        :param FloatTensor[batch_size, seq_len, embedding_size | hidden_size * 2] inputs\n",
        "        :param LongTensor[batch_size, seq_len] lengths\n",
        "        :return FloatTensor[batch_size, seq_len, hidden_size * 2] out_padded\n",
        "        \"\"\"\n",
        "        inputs = self.dropout(inputs)\n",
        "        packed = pack_padded_sequence(inputs, lengths, batch_first=True, enforce_sorted=False)\n",
        "        out_packed, _ = layer(packed)\n",
        "        out_padded, out_lengths = pad_packed_sequence(out_packed, batch_first=True) # [batch_size, seq_len, hidden_size * 2]\n",
        "        return out_padded, out_lengths\n",
        "    \n",
        "    def forward(self, input_embedded, sequence_lengths):\n",
        "        \"\"\"\n",
        "        :param FloatTensor[batch_size, seq_len, embedding_size] input_embedded\n",
        "        :param LongTensor[batch_size, seq_len] sequence_lengths\n",
        "        :return FloatTensor[batch_size, seq_len, hidden_size * n_layers * 2]\n",
        "        \"\"\"\n",
        "        outputs, lens = [input_embedded], sequence_lengths\n",
        "        for lstm in self.lstms:\n",
        "            out, lens = self.apply_lstm(layer=lstm, inputs=outputs[-1], lengths=lens)\n",
        "            outputs.append(out)\n",
        "        return self.dropout(torch.cat(outputs[1:], dim=-1))"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oazq30eW3_T"
      },
      "source": [
        "***Aligned Question Embedding Layer***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATOQC6-pWzq_"
      },
      "source": [
        "class AlignQuestionEmbeddingLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden_size):\n",
        "        super(AlignQuestionEmbeddingLayer, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.linear = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, ctx_embed, qst_embed, qst_mask):\n",
        "        \"\"\"\n",
        "        :param FloatTensor[batch_size, ctx_len, embedding_size] ctx_embed\n",
        "        :param FloatTensor[batch_size, qst_len, embedding_size] qst_embed\n",
        "        :param IntTensor[batch_size, qst_len] qst_mask\n",
        "        :return FloatTensor[batch_size, ctx_len, hidden_size]\n",
        "        \"\"\"\n",
        "        ctx_embed = F.relu(self.linear(ctx_embed)) # [batch_size, ctx_len, hidden_size]\n",
        "        qst_embed = F.relu(self.linear(qst_embed)) # [batch_size, qst_len, hidden_size]\n",
        "        scores = torch.bmm(ctx_embed, qst_embed.transpose(-1, -2)) # [batch_size, ctx_len, qst_len]\n",
        "        scores = scores.masked_fill(qst_mask.unsqueeze(1) == 0, 1e-18)\n",
        "        attention_weights = F.softmax(scores, dim=-1) # [batch_size, ctx_len, qst_len]\n",
        "        return torch.bmm(attention_weights, qst_embed)"
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImX8ayztYjsK"
      },
      "source": [
        "***Question Encoding Layer***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Whil-FgVYhgy"
      },
      "source": [
        "class QuestionEncodingLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_size, hidden_size, dropout, n_layers):\n",
        "        super(QuestionEncodingLayer, self).__init__()\n",
        "        self.embedding_size = embedding_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_layers = n_layers\n",
        "        self.stacked_bilstms_layer = StackedBiLSTMsLayer(embedding_size=embedding_size, hidden_size=hidden_size, n_layers=n_layers, dropout=dropout)\n",
        "        self.linear = nn.Linear(embedding_size, 1)\n",
        "    \n",
        "    def linear_self_attention(self, qst_embed, qst_mask):\n",
        "        \"\"\"\n",
        "        :param FloatTensor[batch_size, qst_len, embedding_size] qst_embed\n",
        "        :param IntTensor[batch_size, qst_len] qst_mask\n",
        "        :return FloatTensor[batch_size, qst_len]\n",
        "        \"\"\"\n",
        "        scores = self.linear(qst_embed).squeeze(-1) # [batch_size, qst_len]\n",
        "        scores = scores.masked_fill(qst_mask == 0, 1e-18)\n",
        "        return F.softmax(scores, dim=-1)\n",
        "\n",
        "    \n",
        "    def forward(self, qst_embed, qst_lengths, qst_mask):\n",
        "        \"\"\"\n",
        "        :param FloatTensor[batch_size, qst_len, embedding_size] qst_embed\n",
        "        :param IntTensor[batch_size, qst_len] qst_lengths\n",
        "        :param IntTensor[batch_size, qst_len] qst_mask\n",
        "        :return FloatTensor[batch_size, hidden_size * n_layers * 2]\n",
        "        \"\"\"\n",
        "        attention_weights = self.linear_self_attention(qst_embed=qst_embed, qst_mask=qst_mask) # [batch_size, qst_len]\n",
        "        lstm_outputs = self.stacked_bilstms_layer(input_embedded=qst_embed, sequence_lengths=qst_lengths)\n",
        "        # lstm_outputs: [batch_size, qst_len, hidden_size * n_layers * 2]\n",
        "        return torch.bmm(attention_weights.unsqueeze(1), lstm_outputs).squeeze(1)"
      ],
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hFIZnmUaFAu"
      },
      "source": [
        "***BiLinear Attention Layer***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZGOH3IhaEZw"
      },
      "source": [
        "class BiLinearAttentionLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, ctx_size, qst_size):\n",
        "        super(BiLinearAttentionLayer, self).__init__()\n",
        "        self.ctx_size = ctx_size\n",
        "        self.qst_size = qst_size\n",
        "        self.linear = nn.Linear(qst_size, ctx_size)\n",
        "    \n",
        "    def forward(self, ctx_encoded, qst_encoded, ctx_mask):\n",
        "        \"\"\"\n",
        "        :param FloatTensor[batch_size, ctx_len, ctx_size] ctx_encoded\n",
        "        :param FloatTensor[batch_size, qst_size] qst_encoded\n",
        "        :param IntTensor[batch_size, ctx_len] ctx_mask\n",
        "        :return FloatTensor[batch_size, ctx_len, hidden_size]\n",
        "        \"\"\"\n",
        "        qst_encoded = self.linear(qst_encoded) # [batch_size, ctx_size]\n",
        "        scores = torch.bmm(ctx_encoded, qst_encoded.unsqueeze(-1)) # [batch_size, ctx_len, 1]\n",
        "        scores = scores.squeeze(-1).masked_fill(ctx_mask == 0, 1e-18) # [batch_size, ctx_len]\n",
        "        return scores"
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzrmk6D7agHH"
      },
      "source": [
        "***Document reader Question Answering Model***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlZlTFXOae_o"
      },
      "source": [
        "class DrQA(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_size, n_extra_features, hidden_size, n_layers, dropout, pad_index):\n",
        "        super(DrQA, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.n_extra_features = n_extra_features\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.pad_index = pad_index\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_size, padding_idx=pad_index)\n",
        "        self.align_question_embedding_layer = AlignQuestionEmbeddingLayer(hidden_size=embedding_size)\n",
        "        self.ctx_stacked_bi_lstm_layer = StackedBiLSTMsLayer(embedding_size=embedding_size * 2 + n_extra_features,\n",
        "                                                             hidden_size=hidden_size, n_layers=n_layers, dropout=dropout)\n",
        "        self.qst_encoding_layer = QuestionEncodingLayer(embedding_size=embedding_size, hidden_size=hidden_size, dropout=dropout, n_layers=n_layers)\n",
        "        self.bilinear_attention_layer_start = BiLinearAttentionLayer(ctx_size=hidden_size * n_layers * 2, qst_size=hidden_size * n_layers * 2)\n",
        "        self.bilinear_attention_layer_end = BiLinearAttentionLayer(ctx_size=hidden_size * n_layers * 2, qst_size=hidden_size * n_layers * 2)\n",
        "    \n",
        "    def make_ctx_mask(self, ctx_sequences):\n",
        "        \"\"\"\n",
        "        :param LongTensor[batch_size, ctx_len] ctx_sequences\n",
        "        :return IntTensor[batch_size, ctx_len]\n",
        "        \"\"\"\n",
        "        return ctx_sequences != self.pad_index\n",
        "    \n",
        "    def make_qst_mask(self, qst_sequences):\n",
        "        \"\"\"\n",
        "        :param LongTensor[batch_size, qst_len] qst_sequences\n",
        "        :return IntTensor[batch_size, qst_len]\n",
        "        \"\"\"\n",
        "        return qst_sequences != self.pad_index\n",
        "    \n",
        "    @staticmethod\n",
        "    def decode(starts, ends):\n",
        "        \"\"\"\n",
        "        :param IntTensor[batch_size, ctx_len] starts\n",
        "        :param IntTensor[batch_size, ctx_len] ends\n",
        "        :return list(int) start_indexes\n",
        "        :return list(int) end_indexes\n",
        "        :return list(float) pred_probas\n",
        "        \"\"\"\n",
        "        start_indexes, end_indexes, pred_probas = [], [], []\n",
        "        for i in range(starts.size(0)):\n",
        "            probas = torch.ger(starts[i], ends[i]) # [ctx_len, ctx_len]\n",
        "            proba, index = torch.topk(probas.view(-1), k=1)\n",
        "            start_indexes.append(index.tolist()[0] // probas.size(0))\n",
        "            end_indexes.append(index.tolist()[0] % probas.size(1))\n",
        "            pred_probas.append(proba.tolist()[0])\n",
        "        return start_indexes, end_indexes, pred_probas\n",
        "    \n",
        "    def forward(self, ctx_sequences, ctx_lengths, qst_sequences, qst_lengths, em_sequences, pos_sequences, ner_sequences, ntf_sequences):\n",
        "        \"\"\"\n",
        "        :param LongTensor[batch_size, ctx_len] ctx_sequences\n",
        "        :param Tensor[batch_size,] ctx_lengths\n",
        "        :param LongTensor[batch_size, qst_len] qst_sequences\n",
        "        :param Tensor[batch_size,] qst_lengths\n",
        "        :param LongTensor[batch_size, ctx_len] em_sequences\n",
        "        :param LongTensor[batch_size, ctx_len] pos_sequences\n",
        "        :param LongTensor[batch_size, ctx_len] ner_sequences\n",
        "        :param LongTensor[batch_size, ctx_len] ntf_sequences\n",
        "        :return Tensor[batch_size, ctx_len] starts\n",
        "        :return Tensor[batch_size, ctx_len] ends\n",
        "        \"\"\"\n",
        "        ctx_mask = self.make_ctx_mask(ctx_sequences) # [batch_size, ctx_len]\n",
        "        qst_mask = self.make_qst_mask(qst_sequences) # [batch_size, qst_len]\n",
        "        ctx_embedded = self.dropout(self.embedding(ctx_sequences)) # [batch_size, ctx_len, embedding_size]\n",
        "        qst_embedded = self.dropout(self.embedding(qst_sequences)) # [batch_size, ctx_len, embedding_size]\n",
        "        ctx_aligned = self.align_question_embedding_layer(ctx_embed=ctx_embedded, qst_embed=qst_embedded,\n",
        "                                                          qst_mask=qst_mask) # [batch_size, ctx_len, embedding_size]\n",
        "        ctx_inputs = torch.cat([ctx_embedded, em_sequences.unsqueeze(-1), pos_sequences.unsqueeze(-1), ner_sequences.unsqueeze(-1),\n",
        "                                ntf_sequences.unsqueeze(-1), ctx_aligned], dim=-1) # [batch_size, ctx_len, embedding_size * 2 + 4]\n",
        "        ctx_encoded = self.ctx_stacked_bi_lstm_layer(input_embedded=ctx_inputs, sequence_lengths=ctx_lengths)\n",
        "        # ctx_encoded: [batch_size, ctx_len, hidden_size * n_layers * 2]\n",
        "        qst_encoded = self.qst_encoding_layer(qst_embed=qst_embedded, qst_lengths=qst_lengths, qst_mask=qst_mask)\n",
        "        # qst_encoded: [batch_size, hidden_size * n_layers * 2]\n",
        "        starts = self.bilinear_attention_layer_start(ctx_encoded=ctx_encoded, qst_encoded=qst_encoded, ctx_mask=ctx_mask)\n",
        "        ends = self.bilinear_attention_layer_end(ctx_encoded=ctx_encoded, qst_encoded=qst_encoded, ctx_mask=ctx_mask)\n",
        "        return starts, ends"
      ],
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x575iXlz3w4m"
      },
      "source": [
        "***Training routines***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31k5BZf43uV4"
      },
      "source": [
        "class AverageMeter:\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.value = 0.\n",
        "        self.sum = 0.\n",
        "        self.count = 0\n",
        "        self.average = 0.\n",
        "        \n",
        "    def reset(self):\n",
        "        self.value = 0.\n",
        "        self.sum = 0.\n",
        "        self.count = 0\n",
        "        self.average = 0.\n",
        "        \n",
        "    def update(self, value, n=1):\n",
        "        self.value = value\n",
        "        self.sum += value * n\n",
        "        self.count += n\n",
        "        self.average = self.sum / self.count"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSmh2GmU4KXH"
      },
      "source": [
        "def normalize(answer: str):\n",
        "    \"\"\"Performs a series of cleaning steps on the ground truth and predicted answer.\"\"\"\n",
        "    def remove_articles(text):\n",
        "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
        "\n",
        "    def white_space_fix(text):\n",
        "        return ' '.join(text.split())\n",
        "\n",
        "    def remove_punc(text):\n",
        "        return ''.join(ch for ch in text if ch not in set(string.punctuation))\n",
        "\n",
        "    def lower(text):\n",
        "        return text.lower()\n",
        "\n",
        "    return white_space_fix(remove_articles(remove_punc(lower(answer))))"
      ],
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hi2JHYTX6F6A"
      },
      "source": [
        "def get_scores(prediction: str, ground_truth: str):\n",
        "    prediction, ground_truth = normalize(prediction), normalize(ground_truth)\n",
        "    em_score = prediction == ground_truth\n",
        "\n",
        "    prediction_tokens, ground_truth_tokens = prediction.split(), ground_truth.split()\n",
        "    common = collections.Counter(prediction_tokens) & collections.Counter(ground_truth_tokens)\n",
        "    num_same = sum(common.values())\n",
        "    if num_same == 0:\n",
        "        f1_score = 0\n",
        "    else:\n",
        "        precision = 1.0 * num_same / len(prediction_tokens)\n",
        "        recall = 1.0 * num_same / len(ground_truth_tokens)\n",
        "        f1_score = (2 * precision * recall) / (precision + recall)\n",
        "\n",
        "    return em_score, f1_score"
      ],
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tv9kxaI34_Oo"
      },
      "source": [
        "def max_metrics_over_ground_truths(prediction: str, ground_truths: list):\n",
        "    scores = [get_scores(prediction, ground_truth) for ground_truth in ground_truths]\n",
        "    em_score = max(scores, key=lambda score: score[0])[0]\n",
        "    f1_score = max(scores, key=lambda score: score[1])[1]\n",
        "    return em_score, f1_score"
      ],
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmxMG01B5JEx"
      },
      "source": [
        "def metrics(predictions: dict, qas=valid_qas):\n",
        "    ground_truths = collections.defaultdict(lambda: [])\n",
        "    for qa in qas:\n",
        "        if qa['id'] in predictions:\n",
        "            ground_truths[qa['id']].append(qa['answer'].text)\n",
        "\n",
        "    em_scores, f1_scores, total = [], [], 0\n",
        "    for id in predictions:\n",
        "        em_score, f1_score = max_metrics_over_ground_truths(predictions[id], ground_truths[id])\n",
        "        em_scores.append(em_score); f1_scores.append(f1_score)\n",
        "        total += 1\n",
        "\n",
        "    em_score = 100.0 * sum(em_scores) / total\n",
        "    f1_score = 100.0 * sum(f1_scores) / total\n",
        "    return em_score, f1_score"
      ],
      "execution_count": 244,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHUdYB6f-NRJ"
      },
      "source": [
        "class Trainer:\n",
        "    \n",
        "    def __init__(self, model, optimizer, criterion, id_field, text_field):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.criterion = criterion\n",
        "        self.id_field = id_field\n",
        "        self.text_field = text_field\n",
        "        \n",
        "    def train_step(self, loader, epoch, grad_clip):\n",
        "        loss_tracker = AverageMeter()\n",
        "        self.model.train()\n",
        "        progress_bar = tqdm.tqdm(enumerate(loader), total=len(loader))\n",
        "        for i, batch in progress_bar:\n",
        "            self.optimizer.zero_grad()\n",
        "            starts, ends = self.model(*batch.ctx, *batch.qst, batch.em, batch.pos, batch.ner, batch.ntf) # [batch_size, ctx_len]\n",
        "            loss = self.criterion(starts, batch.trg[:, 0]) + self.criterion(ends, batch.trg[:, 1])\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(self.model.parameters(), grad_clip)\n",
        "            self.optimizer.step()\n",
        "            loss_tracker.update(loss.item())\n",
        "            progress_bar.set_description(f'Epoch: {epoch+1:02d} -     loss: {loss_tracker.average:.3f}')\n",
        "        return loss_tracker.average\n",
        "    \n",
        "    def validate(self, loader, epoch):\n",
        "        loss_tracker, predictions = AverageMeter(), {}\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            progress_bar = tqdm.tqdm(enumerate(loader), total=len(loader))\n",
        "            for i, batch in progress_bar:\n",
        "                starts, ends = self.model(*batch.ctx, *batch.qst, batch.em, batch.pos, batch.ner, batch.ntf) # [batch_size, ctx_len]\n",
        "                loss = self.criterion(starts, batch.trg[:, 0]) + self.criterion(ends, batch.trg[:, 1])\n",
        "                start_indexes, end_indexes, _ = DrQA.decode(starts=F.softmax(starts, dim=-1), ends=F.softmax(ends, dim=-1))\n",
        "                for i in range(starts.size(0)):\n",
        "                    id = self.id_field.itos(batch.id[i].item())\n",
        "                    prediction = batch.ctx[0][i][start_indexes[i]:end_indexes[i]+1]\n",
        "                    predictions[id] = ' '.join([self.text_field.itos(indice.item()) for indice in prediction])\n",
        "                loss_tracker.update(loss.item())\n",
        "                progress_bar.set_description(f'Epoch: {epoch+1:02d} - val_loss: {loss_tracker.average:.3f}')\n",
        "        return loss_tracker.average, predictions\n",
        "    \n",
        "    def train(self, train_loader, valid_loader, n_epochs, grad_clip):\n",
        "        history, best_loss = {'loss': [], 'val_loss': [], 'em': [], 'f1': []}, float('inf')\n",
        "        for epoch in range(n_epochs):\n",
        "            loss = self.train_step(train_loader, epoch, grad_clip)\n",
        "            val_loss, predictions = self.validate(valid_loader, epoch)\n",
        "            em_score, f1_score = metrics(predictions)\n",
        "            history['loss'].append(loss); history['val_loss'].append(val_loss)\n",
        "            history['em'].append(em_score); history['f1'].append(f1_score)\n",
        "            if best_loss > val_loss:\n",
        "                best_loss = val_loss\n",
        "                torch.save(self.model.state_dict(), './checkpoints/DrQA.pth')\n",
        "            time.sleep(1)\n",
        "            print(f'\\nEM={em_score:.3f}% - F1={f1_score:.3f}%')\n",
        "        return history"
      ],
      "execution_count": 250,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFzM-vWUAov9"
      },
      "source": [
        "***Train the model***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YCmJQLhAlqo"
      },
      "source": [
        "N_LAYERS = 3\n",
        "EMBED_SIZE = 300\n",
        "HIDDEN_SIZE = 256\n",
        "DROPOUT = 0.25\n",
        "N_EPOCHS = 5\n",
        "LR = 1e-3\n",
        "GRAD_CLIP = 1.0"
      ],
      "execution_count": 251,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ersGVmFxBwAV",
        "outputId": "82811505-826b-4309-b120-ab6905930bd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "drqa = DrQA(vocab_size=len(TEXT),\n",
        "            embedding_size=EMBED_SIZE,\n",
        "            n_extra_features=4,\n",
        "            hidden_size=HIDDEN_SIZE,\n",
        "            n_layers=N_LAYERS,\n",
        "            dropout=DROPOUT,\n",
        "            pad_index=TEXT.stoi(PAD_TOKEN))\n",
        "drqa.to(DEVICE)\n",
        "optimizer = optim.RMSprop(params=drqa.parameters(), lr=LR)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=TEXT.stoi(PAD_TOKEN))\n",
        "print(f'Number of parameters of the model: {sum(p.numel() for p in drqa.parameters() if p.requires_grad):,}')\n",
        "print(drqa)\n",
        "trainer = Trainer(model=drqa, optimizer=optimizer, criterion=criterion, id_field=ID, text_field=TEXT)"
      ],
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of parameters of the model: 41,017,285\n",
            "DrQA(\n",
            "  (dropout): Dropout(p=0.25, inplace=False)\n",
            "  (embedding): Embedding(26885, 300, padding_idx=1318)\n",
            "  (align_question_embedding_layer): AlignQuestionEmbeddingLayer(\n",
            "    (linear): Linear(in_features=300, out_features=300, bias=True)\n",
            "  )\n",
            "  (ctx_stacked_bi_lstm_layer): StackedBiLSTMsLayer(\n",
            "    (dropout): Dropout(p=0.25, inplace=False)\n",
            "    (lstms): ModuleList(\n",
            "      (0): LSTM(604, 256, num_layers=3, batch_first=True, bidirectional=True)\n",
            "      (1): LSTM(512, 256, num_layers=3, batch_first=True, bidirectional=True)\n",
            "      (2): LSTM(512, 256, num_layers=3, batch_first=True, bidirectional=True)\n",
            "    )\n",
            "  )\n",
            "  (qst_encoding_layer): QuestionEncodingLayer(\n",
            "    (stacked_bilstms_layer): StackedBiLSTMsLayer(\n",
            "      (dropout): Dropout(p=0.25, inplace=False)\n",
            "      (lstms): ModuleList(\n",
            "        (0): LSTM(300, 256, num_layers=3, batch_first=True, bidirectional=True)\n",
            "        (1): LSTM(512, 256, num_layers=3, batch_first=True, bidirectional=True)\n",
            "        (2): LSTM(512, 256, num_layers=3, batch_first=True, bidirectional=True)\n",
            "      )\n",
            "    )\n",
            "    (linear): Linear(in_features=300, out_features=1, bias=True)\n",
            "  )\n",
            "  (bilinear_attention_layer_start): BiLinearAttentionLayer(\n",
            "    (linear): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "  )\n",
            "  (bilinear_attention_layer_end): BiLinearAttentionLayer(\n",
            "    (linear): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giP1Ov5_DTGr",
        "outputId": "3131cc87-b9a6-4235-f681-aa26e6feb9c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!mkdir -p ./checkpoints\n",
        "history = trainer.train(train_loader=train_dataloader, valid_loader=valid_dataloader, n_epochs=N_EPOCHS, grad_clip=GRAD_CLIP)"
      ],
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 -     loss: 6.798: 100%|██████████| 1354/1354 [11:49<00:00,  1.91it/s]\n",
            "Epoch: 01 - val_loss: 4.883: 100%|██████████| 536/536 [01:53<00:00,  4.74it/s]\n",
            "  0%|          | 0/1354 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "EM=24.379% - F1=36.267%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 02 -     loss: 4.452: 100%|██████████| 1354/1354 [11:50<00:00,  1.90it/s]\n",
            "Epoch: 02 - val_loss: 4.583: 100%|██████████| 536/536 [01:52<00:00,  4.77it/s]\n",
            "  0%|          | 0/1354 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "EM=25.968% - F1=38.437%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 03 -     loss: 3.999: 100%|██████████| 1354/1354 [11:52<00:00,  1.90it/s]\n",
            "Epoch: 03 - val_loss: 4.256: 100%|██████████| 536/536 [01:53<00:00,  4.73it/s]\n",
            "  0%|          | 0/1354 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "EM=30.403% - F1=43.905%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 04 -     loss: 3.700: 100%|██████████| 1354/1354 [11:51<00:00,  1.90it/s]\n",
            "Epoch: 04 - val_loss: 4.047: 100%|██████████| 536/536 [01:51<00:00,  4.80it/s]\n",
            "  0%|          | 0/1354 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "EM=31.069% - F1=44.442%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 05 -     loss: 3.487: 100%|██████████| 1354/1354 [11:48<00:00,  1.91it/s]\n",
            "Epoch: 05 - val_loss: 4.088: 100%|██████████| 536/536 [01:50<00:00,  4.83it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "EM=32.401% - F1=45.959%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8C-bSJpY-qZM",
        "outputId": "5d1d9884-a176-4d92-f1b0-70df6907f896",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "_, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "axes[0].plot(history['loss'], label='train')\n",
        "axes[0].plot(history['val_loss'], label='valid')\n",
        "axes[0].set_title('Loss history')\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('Loss')\n",
        "axes[0].grid(True)\n",
        "axes[0].legend()\n",
        "\n",
        "axes[1].plot(history['em'], label='valid')\n",
        "axes[1].set_title('Exact match history')\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].set_ylabel('Exact match (%)')\n",
        "axes[1].grid(True)\n",
        "axes[1].legend()\n",
        "\n",
        "axes[2].plot(history['f1'], label='valid')\n",
        "axes[2].set_title('F1 history')\n",
        "axes[2].set_xlabel('Epoch')\n",
        "axes[2].set_ylabel('F1 (%)')\n",
        "axes[2].grid(True)\n",
        "axes[2].legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3gAAAFNCAYAAABSRs15AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXxU5dn/8c+VhYQ1EAIJEGQRZAkiIAJuFFELKu4LWpdWW60+7rW2tk9tbR/bp8uvttrWWrX2aSugFESsVXAj4sIiOwkgKktIICQQtkASsly/P2bAiCwBMjnJzPf9es3LmTPnzHxvYu7MNec+923ujoiIiIiIiDR9cUEHEBERERERkfqhAk9ERERERCRKqMATERERERGJEirwREREREREooQKPBERERERkSihAk9ERERERCRKqMCTRsHM/s/MHj3M86Vm1rMhM4mIHAsz625mbmYJddxf/Z+IHJL6CDlaKvDkC8xsnZmdF3SOA7l7K3dfc7h9zGyUmeU3VCYR+Vy47ygLf9DYd/tjBN+vQX/fzewbZvZ+Q71fber/RJqmQ/SLncPPPW1mH5tZjZl943jeR32EHKhO3y6KxAIzS3D3qqBziDRhF7v7W0GHkKOn/k8kYg7VLy4FXgR+1cB5jon6iKZFZ/CkTswsycx+b2Ybw7ffm1lS+Lk0M3vVzLabWYmZvWdmceHnvm9mBWa2K/xN1bmHeZt2Zvaf8L7zzOzEWu/vZtYrfP9CM1sR3q/AzL5rZi2B14HOtb8lO0LuUWaWH85YCPzNzHLM7OJa75toZlvMbHD9/6uKxAYz+7OZTa31+Fdm9raFtAv3H8Vmti18P7PWvqlm9rfw7+82M3v5UL/vB3nf/zOzJ83s9fA+H5hZRrgf2GZmq2r/bpvZQ2b2WbhvWWFml4e39wOeAk4Pv8728PbmZvZbM1tvZjvM7H0za14rwvVmlhfuQ/77CP9M6v9EYoi7/8nd3wbK63iI+gipMxV4Ulf/DYwABgGnAMOAH4WfewDIBzoA6cAPATezPsBdwGnu3hoYA6w7zHtcC/wUaAd8Cvz8EPv9Ffh2+DUHAO+4+27gAmBjeKhCK3ffeITcABlAKtANuA34B3BDrecvBDa5++LD5BaRw3sAONlCwxzPBr4JfN3dndDfob8R+h08ASgDag/t/CfQAsgCOgK/O8zv+8FcQ+h3Pg2oAOYAi8KPpwCP1dr3M+BsIIVQX/S8mXVy95XA7cCc8Hu1De///4BTgTMI9SPfA2pqvd5ZQB/gXODH4ULxUNT/icjhqI+QOlOBJ3V1PfAzdy9y92JCncyN4ecqgU5AN3evdPf3wh/cqoEkoL+ZJbr7Onf/7DDvMc3d54eHAEwg1OEcTGX4Ndu4+zZ3X3SMuSH0Yewn7l7h7mXA88CFZtYm/PyNhD5gisiRvWyhM/n7brcCuPseQr9LjxH6Hbvb3fPDz21196nuvsfddxH60PIVADPrROhDye3h3/VKd3/3KDNNc/eF7l4OTAPK3f0f7l5NaHjU/m+e3f1f7r7R3Wvc/UXgE0IfeL7EQqMUbgHudfcCd6929w/dvaLWbj919zJ3X0poONYpR8ip/k8k+tTuF18+jtdRHyF1pgJP6qozsL7W4/XhbQC/IfRt0htmtsbMHgJw90+B+4BHgCIze+Fgw6hqKax1fw/Q6hD7XUnoW6P1ZvaumZ1+jLkBisMf/Ahn3gh8AFxpZm0JfbiccJjXF5HPXebubWvdntn3hLvPA9YABkzet93MWpjZX8LDHHcCs4G2ZhYPdAVK3H3bcWTaXOt+2UEe7+9nzOwmM1uy78MYoW+/0w7xumlAMqGzfodS1z7taPZV/yfStNTuFy87jtdRHyF1pgJP6mojoVP0+5wQ3oa773L3B9y9J3AJ8B0LX2vn7hPd/azwsU49XEzs7h+5+6WEhmu9zOcfFv1och/mmL8TGoJwNaEhWQXHm1kk1pnZnYTO6G8kNJRxnwcIDWMc7u5tgJH7DgE2AKnhDxIHOtjv7vHk6wY8Q2hYefvwMMyccI6Dvd8WQtfOnEgDUv8nIoejPkJABZ4cXKKZJde6JQCTgB+ZWQczSwN+TOhUPWY2zsx6mZkBOwgNzawxsz5mNjp8wW45oW/Law7+lnVjZs3M7HozS3H3SmBnrdfcDLQ3s5Rahxwy92G8DAwB7iU03lxEjoOZnQQ8SuhDwY3A98xs3/Ci1oT6hu1mlgr8ZN9x7r6J0MQAT1poMpZEM9tXAB7s9/14tCT0YaY4nPlmQmfw9tkMZJpZs3C2GuA54LHwZAXxZnb6vgkKIkH9n0j0CP8+JxP6Emnf567j+lyuPkL2UYEnB/MaoQ9c+26PEPpwtgBYBiwnNEnBvkU3ewNvAaWEJjB40t1nEfq2/peEvukuJPRt0g/qId+NwLrwcK7bCY0hx91XEeqs1oSHWHU+Qu6DCo8znwr0AF6qh7wiseLf9sX1nqaFvyB6HviVuy91908ITcT0z3Ax9HugOaF+Yi4w44DXvJHQNSWrgCJCw74P9ft+zNx9BfBbQn3YZuBkQkOR9nkHyAUKzWxLeNt3CfUrHwElhEYoRPrvqvo/kejwBqHPWGcAT4fvjzzsEXWjPkKw0FwYIlKbmf0YOMndbzjiziIiUUT9n4gcjvqIxk8LnYscIDxM7Jt8cSYpEZGop/5PRA5HfUTToCGaIrWEp3XfALzu7rODziMi0lDU/4nI4aiPaDo0RFNERERERCRK6AyeiIiIiIhIlFCBJyIiIiIiEiWa3CQraWlp3r179zrtu3v3blq2bBnZQAFS+5o2te9zCxcu3OLuHSIcKeLUP31O7Wva1L7PRUP/pL7pc2pf06b2fe5wfVOTK/C6d+/OggUL6rRvdnY2o0aNimygAKl9TZva9zkzWx/ZNA1D/dPn1L6mTe37XDT0T+qbPqf2NW1q3+cO1zdpiKaIiIiIiEiUUIEnIiIiIiISJVTgiYiIiIiIRIkmdw2eSLSprKwkPz+f8vLyoKPUq5SUFFauXPmFbcnJyWRmZpKYmBhQqoZ3qJ/vwf59mrpY/PmKNFXqm0Silwo8kYDl5+fTunVrunfvjpkFHafe7Nq1i9atW+9/7O5s3bqV/Px8evToEWCyhnWon++B/z5NXaz+fEWaKvVNItFLQzRFAlZeXk779u2jqrg7GDOjffv2UXem8kj08xWR42Fm8Wa22MxeDT82M/u5ma02s5Vmds+xvK76JpHopTN4Io1AtP+B3SdW2nmgWGl3rLRTpIHdC6wE2oQffwPoCvR19xoz63isLxwrv7Ox0k6RfXQGTyTGbd++nSeffPKoj7vwwgvZvn17BBJJkFq1agXAxo0bueqqqw66z6hRo+q8ppaIHDszywQuAp6ttfkO4GfuXgPg7kVBZGto6ptE6k4FnkiMO1SBV1VVddjjXnvtNdq2bRupWBKwzp07M2XKlKBjiMS63wPfA2pqbTsRGG9mC8zsdTPrHUy0YKhvEjmyqB2imb9tDzPWVjJypBMXp1PzIofy0EMP8dlnnzFo0CASExNJTk6mXbt2rFq1itWrV3PZZZexYcMGysvLuffee7ntttsA6N69OwsWLKC0tJQLLriAs846iw8//JAuXbowffr0gFsl+zz00EN07dqVO++8E4BHHnmEhIQEZs2axbZt26isrOTRRx/l0ksv/cJx69atY9y4ceTk5FBWVsbNN9/M0qVL6du3L2VlZUE0ReS4VVXX8LcP1pFZ5UFHOSIzGwcUuftCMxtV66kkoNzdh5rZFcBzwNkHOf424DaA9PR0srOzv/B8SkoKu3bt+tL7VldXH3R7ffvJT35Cly5d9v9N+cUvfkFCQgLvvfce27dvp7KykocffpiLLrpo/zG7du1i/fr1XHPNNcybN4+ysjLuuOMOcnJyOOmkkygtLWX37t0HzV9eXk52djalpaVf+reIJmpf0/Xptmq27iqDemhf1BZ4C9Zt44WP93L1hu2c2q1d0HFEGq1f/vKX5OTksGTJErKzs7nooovIycnZP9vYc889R2pqKmVlZZx22mlceeWVtG/f/guv8cknnzBp0iSeeeYZrrnmGqZOnfqlgkGCMX78eO677779Bd7kyZOZOXMm99xzD23atGHLli2MGDGCSy655JDXqfz5z3+mRYsWrFy5kmXLljFkyJCGbIJIvSjYXsZ9Lyzmo3XbuDmrGRcEHejIzgQuMbMLgWSgjZk9D+QDL4X3mQb87WAHu/vTwNMAQ4cO9VGjRn3h+ZUrVx50tsyGmkXzxhtv5L777uOBBx4AYPr06cycOZMHH3zwC33T+PHj9/dNrVu3plWrVsTFxdG6dWueeeYZUlJS+Pjjj/f3TS1btjxo/uTkZAYPHkx2djYH/ltEE7Wv6dlbVcPjb6/mz/M/o2vreL5341eO+7rRqC3wzunbkXiDmbmFKvCkyfjpv3NZsXFnvb5m/85t+MnFWXXef9iwYV+YSvqJJ55g2rRpAGzYsIFPPvnkSwVejx49GDRoEACnnnoq69atO/7gUaj2z7e6upr4+Pjjfs0j/XwHDx5MUVERGzdupLi4mHbt2pGRkcH999/P7NmziYuLo6CggM2bN5ORkXHQ15g9ezb33BOaqG/gwIEMHDjwuHOLNKSZuYV8b8oyqqpr+P34QbTd8UnQkY7I3X8A/AAgfAbvu+5+g5n9EjgHWAt8BVh9vO+lvkkkGKs37+L+F5eQu3EnV52aybntSuplUqCoLfBSmifSv308M3ML+cEFfTWDkkgdtWzZcv/97Oxs3nrrLebMmUOLFi0YNWrUQaeaTkpK2n8/Pj5eQ/gamauvvpopU6ZQWFjI+PHjmTBhAsXFxSxcuJDExES6d++uKcQlKpVXVvO/r63k73PWM6BLG/5w3RB6pLUkO7vxF3iH8UtggpndD5QC3wo4zzFT3ySxqqbGee6Dtfx65se0SkrgLzeeypisjHobfhq1BR7Aqenx/F/uHlYV7qJfpzZHPkAkYEdzpq2+tG7d+pDXW+zYsYN27drRokULVq1axdy5cxs4XXSp/fNtyMWEx48fz6233sqWLVt49913mTx5Mh07diQxMZFZs2axfv36wx4/cuRIJk6cyOjRo8nJyWHZsmUNklvkeHxaVMrdkxazctNOvnlWD743tg9JCcd/ZioI7p4NZIfvbyc0s2a9Ud8k0nDyt+3hu/9aytw1JZzXryP/e8VAOrROOvKBRyGqC7whHRP4+4q9zMgpVIEncgjt27fnzDPPZMCAATRv3pz09PT9z40dO5annnqKfv360adPH0aMGBFgUjlWWVlZ7Nq1iy5dutCpUyeuv/56Lr74Yk4++WSGDh1K3759D3v8HXfcwc0330y/fv3o168fp556agMlFzl67s6Uhfn8eHouyYlxPPeNoYzum37kA6XBqW+SWOLuTF1UwE9fyaXGnV9fOZCrh2ZGZJRhVBd4bZKM07qlMjO3kPvPPynoOCKN1sSJEw+6PSkpiddff/2gz+27zi4tLY2cnJz927/73e8CNMgsbFJ3y5cv338/LS2NOXPmHHS/0tJSIDRL6r6fa/PmzXnhhRciH1LkOJVWVPGjact5eclGRvRM5ffjB5ORkhx0LDkM9U0SC7aWVvDDacuZmbuZYd1T+e01p9A1tUXE3i+qCzyAMQMy+J9XV7B2y256pLU88gEiIiLS5CzP38HdkxaRV7KH75x/Enee04t4LZMkIgF7e+Vmvj91OTvLKvnBBX351tk9I943Rf1C52OyQsMyZuYWBpxERERE6pu78+x7a7jizx9QUVXDC7edzj3n9lZxJyKBKq2o4qGpy/jm3xeQ1qoZ0+86k29/5cQG6Zui/gxeZrsWnNwlhZm5hdz+lRODjiMiIiL1ZGtpBQ9OWcY7q4o4v386v75yIO1aNgs6lojEuI/WlfCdyUvI31bG7V85kfvP792gkzxFfYEHMHZABr+Z+TGFO8o1Fl9EvsDMkoHZQBKhPnGKu//EzCYAQ4FKYD7wbXevPJb3cPeYWKrF3YOOIDFkzmdbue/FxWzbXclPL8niptO7xcTvWX1S3yRSvyqqqnnszdU8PXsNme2aM/nbp3Na99QGzxH1QzTh82Gab6zQME0R+ZIKYLS7nwIMAsaa2QhgAtAXOBlozjGuNZWcnMzWrVuj/gOGu7N161aSk/UlmkRWVXUNj73xMV97di4tmyUw7c4z+PoZ3WOiUKlP6ptE6teqwp1c+scP+Mu7a7j2tK68fu/IQIo7iJEzeL06tubEDi2ZkVPITad3DzqOiDQiHvp0Uxp+mBi+ubu/tm8fM5sPZB7L62dmZpKfn09xcfEXtpeXl0fdB47k5GQyM4/pn0mkTjZuL+PeFxbz0bptXDkkk59dmkXLpJj4KFPv1DeJ1I/qmtB1wL99YzVtmify168P5dx+wS7NEjO94tgBGTz17hpKdu8lVePzRY5Lq1atKC0tZePGjdxzzz1MmTLlS/tceOGF/O53v2Po0KEBJDw6ZhYPLAR6AX9y93m1nksEbgTuPZbXTkxMpEePHl/anp2dzeDBg48tsEgMeiO3kAenLKOquobfjT+FywfrA/vxUN8kcvw2lOzhgclLmb+uhDFZ6fzi8pNp36p+Fy0/FrFT4GV14k+zPuOtlZu5ZmjXoOOIRIXOnTsftLhraty9GhhkZm2BaWY2wN33Le73JDDb3d872LFmdhtwG0B6ejrZ2dl1es/S0tI679sUqX1NW2Nq395q58WP9/J2XhXd2sRxx9Ak2u34lOzsT4/5NRtT+0Sk6XF3Ji/YwM/+vYI4M3579SlcMaRLoxkqHjMF3oAubejStjlv5BaqwBM5wEMPPUTXrl258847AXjkkUdISEhg1qxZbNu2jcrKSh599FEuvfTSLxy3bt06xo0bR05ODmVlZdx8880sXbqUvn37UlZWFkRTjou7bzezWcBYIMfMfgJ0AL59mGOeBp4GGDp0qI8aNapO75WdnU1d922K1L6mrbG077PiUu6auJiVm/Zwy5k9+P4FfeplJrrG0j4RaXqKd1Xwg5eW8dbKIkb0TOX/XX0Kme0it2j5sYiZAs/MGJOVwfPz1lNaUUUrjdkX2W/8+PHcd999+wu8yZMnM3PmTO655x7atGnDli1bGDFiBJdccskhv53685//TIsWLVi5ciXLli1jyJAhDdmEY2ZmHYDKcHHXHDgf+JWZfQsYA5zr7jWBhhSJMe7O1EUF/Hh6DkkJcY3imhYRkZm5hfzwpeXsqqjiRxf145YzexDXCNfcjKkqZ0xWOs99sJbsj4sYN7Bz0HFEvuz1h6Bwef2+ZsbJcMEvD7vL4MGDKSoqYuPGjRQXF9OuXTsyMjK4//77mT17NnFxcRQUFLB582YyMjIO+hqzZ8/mnnvuAWDgwIEMGDCgftsROZ2Av4evw4sDJrv7q2ZWBawH5oSL2pfc/WcB5hSJCaUVVTz8cg7TFhcwvEcqj187WEsciUigdpVX8tN/r2DKwnyyOrdh0vhBnJTeOuhYhxRTBd7Q7qm0b9mMGTmFKvBEDnD11VczZcoUCgsLGT9+PBMmTKC4uJiFCxeSmJhI9+7dKS8vDzpmvXP3ZcCXZhRw95jqH0Uag+X5O7h70iLySvZw/3kncdfoXsQ3wm/HRSR2zF2zlQcmL2XTjjLuOqcX95zbm2YJjXuluZj6ABMfZ3w1K51XlmykvLKa5MSGW1FepE6OcKYtksaPH8+tt97Kli1bePfdd5k8eTIdO3YkMTGRWbNmsX79+sMeP3LkSCZOnMjo0aPJyckhJyfnsPuLiOzj7jz3wTp++fpK0lolMenWEQzv2T7oWCISw8orq/ntGx/z7Ptr6Zbagn/dfgandmsXdKw6iWiBF56R7llgAODALe4+p9bzo4DpwNrwpogPgRqTlcGk+Rv48LMtjO6r8fwi+2RlZbFr1y66dOlCp06duP7667n44os5+eSTGTp0KH379j3s8XfccQc333wz/fr1o1+/fgwaNKiBkotIU1ayey8P/mspb68q4rx+6fzmqoG003JGIhKgnIIdfGfyElZvLuX64Sfw3xf1o0WzpnNeLNJJHwdmuPtVZtYMONgUM++5+7gI59jvjBPTaJ2UwIycQhV4IgdYvvzz6//S0tKYM2fOQfcrLQ2tC969e/f9Z+qaN2/OCy+8sH+fXbt20bp14x2fLiLBm/PZVu57cTHbdlfyyMX9+foZ3RvNNOMiEnuqa5yn3v2M37+1mnYtmvG3m0/jnD4dg4511CJW4JlZCjAS+AaAu+8F9kbq/eqqWUIc5/bryJsrNlNVXUNCfOMeQysiIhJtqqpreOKdT/nDO5/Qo31L/vr10xjQJSXoWCISw9Zt2c0D/1rKwvXbuOjkTjx62YAmO5ogkmfwegDFwN/M7BRgIXCvu+8+YL/TzWwpsBH4rrvnRjATEBqm+fKSjcxfV8IZJ6ZF+u1EREQkbOP2Mu57YQnz15Vw5ZBMfnZpFi21dJGIBMTdmTg/j5//ZyUJccbj1w7iklM6N+nRBJHsUROAIcDd7j7PzB4HHgIerrXPIqCbu5ea2YXAy0DvA1/IzG4DbgNIT08nOzu7TgFKS0sPum9clZMYB3+duZC9/ZOOqlGNyaHaFy1ipX0pKSns2rUr6Dj1rrq6+qDtKi8vj+qfq4gc2psrNvPglKXsrarhsWtO4YohmUFHEpEYVrSznO9PXcasj4s5q1cav7l6IJ1Smgcd67hFssDLB/LdfV748RRCBd5+7r6z1v3XzOxJM0tz9y0H7Pc08DTA0KFDfdSoUXUKkJ2dzaH2PWfjApbl72DkyK80ygUK6+Jw7YsGsdK+lStX0qpVqyb9TdHBHOwaPHcnOTmZwYO/tCqBiESx8spqfvn6Kv7vw3VkdW7DH64bTM8OrYKOJSIx7LXlm/jvacvZs7eaRy7uz02nd2+yNcGBIlbguXuhmW0wsz7u/jFwLrCi9j5mlgFsdnc3s2GEFhneGqlMtY0dkMEbKzazrGAHg7q2bYi3FDmo5ORktm7dSvv27aOuyKvN3dm6dSvJyVqwWCSWfFZcyt0TF7Ni005uObMH37+gD0kJWqZIRIKxo6ySR17JZdriAgZmpvDYNYPo1TG6vnCK9KD3u4EJ4Rk01wA3m9ntAO7+FHAVcIeZVQFlwLXu7hHOBMC5fdNJiDNm5BSqwJNAZWZmkp+fT3FxcdBR6lV5efmXirnk5GQyMzUkSyRWTF2Yz8PTc0hKiOPZm4ZyXn/NXi0iwfng0y08+K+lbN5Vwb3n9uau0b1IjMIJFyNa4Ln7EmDoAZufqvX8H4E/RjLDoaS0SOT0E9szI2cT3x/bJ6rPnEjjlpiYSI8ePYKOUe+ys7M1FFMkRpVWVPHwyzlMW1zAsB6pPH7toKi4rkVEmqbyymp+NWMVf/tgHT3TWjL1jjOi+gRPTE9bNSYrgx+9nMPqzaX0ydB6XSIiIscrp2AHd01cRF7JHu47rzd3j+5NfJRc1yIiTc/y/B3cP3kJnxaV8vXTu/HQBf1o3iy6h4lH3znJo/DV/umYwYycwqCjiIiINGnuznPvr+XyJz+gvLKGSbeO4L7zTlJxJyKBqKqu4Ym3P+HyJz+gtLyKf35zGD+9dEDUF3cQ42fwOrZJ5tQT2jEjt5B7z/vS6gwiIiJSByW79/Lgv5by9qoizuvXkd9cdUqTXSBYRJq+NcWlfGfyUpZs2M6lgzrzs0sGkNIiMehYDSamCzwIzab56H9Wkrd1Dye0bxF0HBERkSZl7pqt3PvCYrbtruSRi/vz9TO667p2EQmEu/P83PX8/LWVJCXE84frBnPxKZ2DjtXgYnqIJoSuwwOYmathmiIiInVVVV3D795czdeemUvLZgm89F9n8I0ze6i4E5FAFO4o56bn5vPw9FyG9WjPG/ePjMniDnQGj66pLcjq3IYZuYXcOrJn0HFEREQavU07yrj3hSXMX1vClUMy+dmlWbRMivmPFCISkH8v3ciPXs5hb1UN/3PZAG4YfkJMf9mk3pjQWbzH3lxN0c5yOrbRIswiIiKH8uaKzTw4ZSl7q2p47JpTuGKI1rYUkWBs37OXH0/P5ZWlGxnUtS2/Gz+IHmktg44VuJgfogmh6/AAZq7YHHASERGRxqmiqppHXsnl1n8soEvb5rx691kq7kQkMLNXFzPm97N5bfkmHjj/JKbcfrqKuzCdwQN6d2xFz7SWzMwp5MYR3YKOIyIi0qisKS7l7kmLyd24k1vO7MH3L+hDUkL0TzUuIo1P2d5q/vf1lfxjznp6dWzFszedxsmZKUHHalRU4AFmxpgBGTwzew3b9+ylbQtN7SwiIgIwdWE+D0/PISkhjmdvGsp5/dODjiQiMWrN9mp+9sR7rNmym1vO7MH3xvYhOVFfNh1IBV7Y2KwM/pz9GW+vLOLKUzXkREREYltpRRU/fjmHlxYXMKxHKo9fO4hOKc2DjiUiMWZDyR7mrS3hw8+28PLicjLaJDPxW8M5o1da0NEaLRV4YQMzU+iUksyM3EIVeCIiEtPW7ajmp394n/Vbd3Pfeb25e3Rv4uNid0Y6EWkY7s7aLbuZv7aEeWtLmL+2hILtZQCkNE9kZJcEHv/mSFKax86i5cdCBV6YmTEmK4NJ8/PYXVGl6Z5FYoSZJQOzgSRCfeIUd/+Jmd0F3AecCHRw9y0BxhRpEHv2VjFhbh6/mltOWutkJt06guE92wcdS0SiVE2N82lxKfPWbN1f0BXtqgAgrVUzhvVI5baRPRnWI5U+6a2ZPftdFXd1oCqmljFZGfzfh+t4d3UxF57cKeg4ItIwKoDR7l5qZonA+2b2OvAB8CqQHWQ4kUirqXHmrt3KS4sKeH35JnbvrWZQh3j+dvvZtGupa9JFpP5U1zgrN+0Mn6HbykfrtlGyey8AGW2SOf3E9gzrkcrwHu05sUPLmF7L7niowKvltO7tSG3ZjJm5hSrwRGKEuztQGn6YGL65uy8G9MdFotanRaW8tCiflxcXsHFHOa2TEhg3sDNXDOnCnvXLVNyJyHGrrK4hd+NO5q3Zyvy1JcxfV8Ku8ioAuqY255w+HRneM5XhPVI5IbWF/ubWExV4tSTEx3F+v3ReW76JiqpqTdOYkHYAACAASURBVAEtEiPMLB5YCPQC/uTu8wKOJBIRJbv38u+lG3lpUT5L83cQH2eM7J3GDy7sx/n90/fPRpedpw9ZInL0KqqqWZa/g/lrS5i7ZisL129jz95qAHqmtWTcwE77z9B1bqtJmyJFBd4Bxg7I4MUFG/jws62c06dj0HFEpAG4ezUwyMzaAtPMbIC759TlWDO7DbgNID09nezs7Dq9Z2lpaZ33bYrUvsajssZZUlTNhxurWFZcTbXDCa3juK5vM4Z3iqdt0h7Ytpq5H6zef0xTat+xiPb2iTSUsr3VLN6wjXlrQkMuF+dtp6KqBoA+6a25ckgmw3umMqx7Kh3bJAecNnaowDvAGb3a0yopgZk5hSrwRGKMu283s1nAWKBOBZ67Pw08DTB06FAfNWpUnd4rOzubuu7bFKl9wXJ3FuVt56VF+by6bBM7yirp2DqJb57djcsHd6FfpzaHPb6xt+94RXv7RCKltKKKheu3MX/tVuatKWFp/nYqqx0z6N+pDdcP78bwnqmc1j2VVA3zDowKvAMkJcRzTt+OvLFiMz+/3DUttEiUM7MOQGW4uGsOnA/8KuBYIsdkQ8kepi0u4KVF+azbuofkxDjGZmVwxZBMzuyVpr9pTVB4CPkCoMDdx9Xa/gRwi7u3CiycRL0dZZUsWBdasmDemq3kbNxJdU3o8/HJXVK45cweDO+ZyqndUjW7ZSOiAu8gxmZl8O+lG/loXQkjND20SLTrBPw9/CEqDpjs7q+a2T3A94AMYJmZvebu3woyqMjB7Cyv5LVlm3hpcQHz15ZgBiN6tOfOc3pxwcmdaKVlf5q6e4GVwP7TrmY2FGgXWCKJWiW794bOzq0tYd6aElYW7sQdmsXHcUrXFO74yokM75nKkBPaaUmxRkw/mYMY1acDzRLimJlbqAJPJMq5+zJg8EG2PwE80fCJRI6sqrqG9z7ZwtRF+by5YjMVVTX07NCSB8f04bLBXeiiyQuigpllAhcBPwe+E94WD/wG+BpweXDpJBoU7SwPFXPhIZefFIUmlU5OjGPICe2499zeDO/RnsEntN0/CZM0firwDqJlUgIje3dgZk4hPx7XX1O2iohI4NydFZt28tKiAqYv2ciW0gratUjk2tO6csWQTAZmpujvVfT5PaGRBK1rbbsLeMXdN+nnLUerYHtZaFHxNaElC9Zu2Q1Ay2bxnNo9lcsGd2FEz1RO7tKWZglxAaeVY6UC7xDGDsjgrZWbWV6wg4GZbYOOIyIiMWrzznKmLyngpUUFrCrcRWK8cW7fdK4Y0oVRfTrqQ1iUMrNxQJG7LzSzUeFtnYGrgVF1OF4z/B5ELLXP3Sna43y8rZqPS2pYVVLN1nIHoEUCnNQunvF9mtEnNY5ureOIj9sD7GHX2nw+XBtcGw4nln5+x0MF3iGc168j8XHGjJxCFXgiItKg9uyt4o3czUxdlM8Hn26hxmHICW159LIBjBvYibYtNDtdDDgTuMTMLgSSCV2DlwtUAJ+Gz961MLNP3b3XgQdrht+Di+b2uTuT/jOL7ck9mLe2hPlrt7J5ZwUAqS2bMezEtPCi4u3pk9G6SU66FM0/P6i/9qnAO4S2LZoxomcqM3IKeXBMHw17ERGRiKqpceau3cpLiwp4ffkmdu+tJrNdc+46pxeXD8mkR1rLoCNKA3L3HwA/AAifwftu7Vk0w9tLD1bcSWz6xWsreeb9MiCHjq2TGN6zPcN7pDK8Ryq9OrbSZ9kYogLvMMZmZfDw9Fw+LSqld3rrIx8gIiJylD4tKuWlRfm8vLiAjTvKaZWUwLiBnbliSBdO655KXBP8ll1EGtaOskr+OXc9QzrG89hNZ9OtfQsVdDFMBd5hfDVc4M3MLVSBJyIi9aZk917+vXQjLy3KZ2n+DuLjjJG903jown58tX+6ZquTL3D3bCD7INu1Bp4A8PLiAsora7jkxGS662x/zFOBdxjpbZIZckJbZuQWctfo3kHHERGRJqyiqppZq4qYuqiAWauKqKpx+ndqw48u6sclgzrTsXVy0BFFpAlydybNz2NAlzZ0T6kOOo40AhEt8MysLfAsMABw4BZ3n1PreQMeBy4E9gDfcPdFkcx0tMYOyOAXr61iQ8keuqa2CDqOiIg0Ie7OorztvLQon1eXbWJHWSUdWydxy1k9uHxwF/p1anPkFxEROYxFedtZVbiLX1x+MpStCTqONAKRPoP3ODDD3a8ys2bAgRXSBUDv8G048OfwfxuNMVmhAm9mbiHfOrtn0HFERKQJ2FCyh2mLC3hpUT7rtu4hOTGOsVkZXDEkkzN7pTXJ2etEpHGaOC+Pls3iuWRQZxbMUYEnESzwzCwFGAl8A8Dd9wJ7D9jtUuAf7u7AXDNra2ad3H1TpHIdrW7tW9I3o7UKPBEROayd5ZW8vnwTUxcVMH9tCQCn92zPnef04oKTO9EqSVdFiEj92rGnkleXbeSKIZnqY2S/SP6f0AMoBv5mZqcAC4F73X13rX26ABtqPc4Pb2s0BR6Ehmk+/vYnFO+qoEPrpKDjiIhII1FVXcN7n2xh6qJ83lyxmYqqGnp2aMmDY/pw6aDOZLbT0H4RiZxpi/OpqKrh+uEnBB1FGpFIFngJwBDgbnefZ2aPAw8BDx/tC5nZbcBtAOnp6XVe4b2+VoNvX1aDO/zp5dmM6pp43K9XX+qrfY2V2te0RXv7JHa5O+t3VvM/r65g+pKNbCmtoF2LRK49rStXDMlkYGaKpicXkYhzdybOz2NgZgoDuqQEHUcakUgWePlAvrvPCz+eQqjAq60A6FrrcWZ42xe4+9PA0wBDhw71uq7wXl+rwbs7f12VzZrKljwyathxv159qa/2NVZqX9MW7e2T2FRRVc0Nz87jo3XlJMav49y+6VwxpAuj+nSkWUJc0PFEJIYsXL+N1ZtL+eUVJwcdRRqZiBV47l5oZhvMrI+7fwycC6w4YLdXgLvM7AVCk6vsaEzX3+1jZowZkMFf31vLjrJKUpo3nrN4IiLScF5fXshH67ZxRe9EHr52FO1aNgs6kojEqInz82iVlMDFp3QOOoo0MpH+uvFuYIKZLQMGAb8ws9vN7Pbw868Ba4BPgWeA/4pwnmM2JiuDqhrnnVWbg44iIiIBeX7uerq3b8G4nokq7kQkMDv2VPKfZZu4dFBnWmpyFTlARP+PcPclwNADNj9V63kH7oxkhvoyKLMt6W2SmJFTyOWDM4OOIyIiDWxV4U4WrN/Gf1/Yj7iavKDjiEgMm7ooNLnK1zS5ihyELhioo7g4Y0xWBu+uLqZsb3XQcUREpIFNmJtHs4Q4rjpVX/KJSHD2Ta5ySte2ZHXW5CryZSrwjsLYrAzKK2t4d3Vx0FFERKQB7a6oYtriAsYN7KShmSISqAXrt/FpUSlfG9b1yDtLTFKBdxSG9UilbYtEZuYWBh1FREQa0MtLCiitqOKGEd2CjiIiMW7ivDxaa3IVOQwVeEchIT6O8/ul89bKzeytqgk6joiINAB35/m5efTv1IbBXdsGHUdEYti23Xv5z/JNXDa4Cy2aaXIVOTgVeEdpTFYGu8qrmLNma9BRRESkASzK287KTTu5YUQ3LWAuIoGauiifvVU1XDdMk6vIoanAO0pn9U6jRbN4ZuRomKaISCyYMHc9rZISuHSQhkOJSHDcnUnz8xjUtS39O7cJOo40YirwjlJyYjzn9O3Imys2U13jQccRkeNkZslmNt/MlppZrpn9NLy9h5nNM7NPzexFM9PMGjFo2+69vLp8E5cP7qK1pkQkUPPXlvBZ8W4tjSBHpALvGIzNymBLaQWL8rYFHUVEjl8FMNrdTwEGAWPNbATwK+B37t4L2AZ8M8CMEpApC0PDoTS5iogEbeL8PFonJ3DxQI0mkMNTgXcMzunbkWbxcRqmKRIFPKQ0/DAxfHNgNDAlvP3vwGUBxJMA1dQ4E+at57Tu7eiT0TroOCISw7bt3svrywu5fHAXmjeLDzqONHIab3IMWiUlcHbvNGbkFPKji/rponuRJs7M4oGFQC/gT8BnwHZ3rwrvkg90OcSxtwG3AaSnp5OdnV2n9ywtLa3zvk1RNLQvZ0s167aWM6ZL9ZfaEg3tOxy1T6Rxmboon73VNRqeKXWiAu8YjcnK4O1VReRu3MmALilBxxGR4+Du1cAgM2sLTAP6HsWxTwNPAwwdOtRHjRpVp+Oys7Op675NUTS0b9I/F9C+ZQ3fueYckhK++I15NLTvcNQ+kcbD3Zk4P48hJ7Slb4YmV5Ej0xDNY3Re/3TiDA3TFIki7r4dmAWcDrQ1s31fgmUCBYEFkwZXuKOct1YWcfXQrl8q7kREGtLcNSWsKd7N14brWmCpGxV4xyi1ZTOG92jPzFwVeCJNmZl1CJ+5w8yaA+cDKwkVeleFd/s6MD2YhBKESfPzqHHna1prSkQCNik8ucpFJ3cKOoo0ESrwjsPYARl8UlTKp0WlR95ZRBqrTsAsM1sGfAS86e6vAt8HvmNmnwLtgb8GmFEaUGV1DS98lMfI3h04oX2LoOOISAwr2b2XGTmFXDkkU5OrSJ2pwDsOX81KB9BZPJEmzN2Xuftgdx/o7gPc/Wfh7WvcfZi793L3q929Iuis0jDeXlnE5p0VWhpBRAI3ZeEGTa4iR00F3nHolNKcU7q2VYEnIhJFJsxbT+eUZEb37Rh0FBGJYe7OpPkbGNqtHSela6kWqTsVeMdpbFYGy/J3ULC9LOgoIiJynNZu2c17n2zhumEnEB+nJXBEJDhz1mxl7ZbdXKdrgeUoqcA7TmP2DdPUbJoiIk3exHnrSYgzxg/rGnQUEYlxE+flkdI8kYsGanIVOToq8I5Tzw6t6JPeWsM0RUSauPLKav61MJ8xWRl0bJ0cdBwRiWFbSiuYmVvIFUO6kJyoyVXk6Gih83owZkAGf3znE7aUVpDWKinoOCIxx8ySgXHA2UBnoAzIAf7j7rlBZpOm4z/LNrF9TyXXazIDEQnYlIX5VFZrqRY5NjqDVw/GZmVQ4/DWis1BRxGJOWb2U+ADQouTzwP+AkwGqoBfmtmbZjYwwIjSRDw/bz09O7Tk9BPbBx1FRGJYTY3zwvw8Tuvejt6aXEWOgc7g1YN+nVrTNbU5M3ILuVbftIg0tPnu/pNDPPeYmXUE9Isph5W7cQeL87bz8Lj+mGlyFREJzpw1W1m3dQ/3ntc76CjSROkMXj0wM8ZmZfDBp1vYWV4ZdByRmOLu/zlwm5klm1mb8PNF7r6g4ZNJUzJhXh7JiXFcNSQz6CgiEuP2Ta5ywQBNriLHRgVePRk7IIPKamfWqqKgo4jENDP7FvAyMNXM/jfoPNL47Sqv5OXFBVw8sDMpLRKDjiMiMax4V2hylSuHZGpyFTlmKvDqyeCu7ejQOkmzaYo0MDO75IBN57n7WHc/H7gwiEzStLy8uIA9e6u5YUS3oKOISIybsjCfqhrna8O1VIscOxV49SQuzhiTlc6sVcWUV1YHHUcklpxsZtPNbFD48TIze9bMngE0g6Yclrvz/Nw8Tu6Swild2wYdR0RiWE2NM2l+HsN6pNKroyZXkWOnAq8ejc3qRFllNbNXFwcdRSRmuPvPgW8D/xUu6p4DfgX8wd2/Fmg4afQWrN/Gx5t3aWkEEQncB59tIa9kj/ojOW4q8OrR8J6ppDRPZIaGaYo0tN3AfcAfgaeB64DVgSaSJuH5uetpnZzAJYM6Bx1FRGLcpPl5tGuRyJisjKCjSBMX0QLPzNaZ2XIzW2JmX5rFzsxGmdmO8PNLzOzHkcwTaYnxcZzbryNvrdhMZXVN0HFEYoKZPQpMBV4FznH3S4AlwGtmdlOg4aRR21pawevLQ5MZtGimVYNEJDhFu8p5I3ezJleRetEQZ/DOcfdB7j70EM+/F35+kLv/rAHyRNTYrAx2llcxd83WoKOIxIpx7v5V4FzgJgB3fwX4KtAuyGDSuP1rYT57q2s0HEpEAvevBaHJVa5TfyT1QEM069nIkzrQPDFes2mKNJwcM3sa+Afw7r6N7l7l7o8HF0sas5oaZ+K8PIb3SKV3uiYzEJHg1NQ4L3yUx4ieqZzYoVXQcSQKRLrAc+ANM1toZrcdYp/TzWypmb1uZlkRzhNxyYnxnNO3AzNzN1NT40HHEYl67n4D8Afg5+5+f9B5pGmY/UkxeSV7tDSCiATu/U+3sKGkjOuG6eyd1I9IX3RwlrsXmFlH4E0zW+Xus2s9vwjo5u6lZnYhocWJex/4IuHi8DaA9PR0srOz6/TmpaWldd63Pp1gVby2q4K/Tn+H3u0iN446qPY1FLWvaWuo9pnZWe7+/mGebwOc4O45EQ8jTcbzc/NIa9VMkxlIo2dm8cACoMDdx5nZBGAoUAnMB77t7pVBZpTjM3FeHqktmzF2gPojqR8RLfDcvSD83yIzmwYMA2bXen5nrfuvmdmTZpbm7lsOeJ2nCc2Mx9ChQ33UqFF1ev/s7Gzqum99GlJeyV9z36SoWSduHdU/Yu8TVPsaitrXtDVg+640s18DM4CFQDGQDPQCzgG6AQ80RBBpGgq2l/HOqs3c/pUTaZagKxWk0bsXWAm0CT+eANwQvj8R+Bbw5wByST0o2lnOmys3882zepCUoMlVpH5E7C+bmbU0s9b77hOa8CDngH0yzMzC94eF8zT52UnaJCdyZq80ZuQW4q5hmiKRFB6WOQ7YBFwN/A/wHUKjAf7i7iPd/aMAI0oj88L8PBw0HEoaPTPLBC4Cnt23zd1f8zBCZ/Ayg8onx2/ygg1U1zjXntY16CgSRSJ5Bi8dmBau3xKAie4+w8xuB3D3p4CrgDvMrAooA671KKmIxmZl8NBLy1m5aRf9O7c58gEicszcvQR4JnwTOaTK6hpe+GgD5/TpSNfUFkHHETmS3wPfA740E5CZJQI3EjrDJ01QTY0zaf4GTu/Znp6aXEXqUcQKPHdfA5xykO1P1br/R0ILE0ed8/qnEzdtOTNyC1XgiTRiZtaV0Ayc6YQmhnra3R83s1OAp4BWwDrg+trDyqVpenPFZop3VXDDCJ29k8bNzMYBRe6+0MxGHWSXJ4HZ7v7eIY5vUvMXNJTG1L5lxVUUbK/gkm419ZapMbUvEtS+utHKrhGS1iqJ07qnMjOnkO+cf1LQcUTk0KqAB9x9UXhY+UIze5PQkKjvuvu7ZnYL8CDwcJBB5fg9P3c9Xdo25ysndQw6isiRnAlcEp6ELhloY2bPu/sNZvYToAPw7UMd3NTmL2gojal9E/+xgPYtt3H/1aPr7XrgxtS+SFD76kZXl0fQ2AEZfLx5F2uKS4OOIiKH4O6b3H1R+P4uQpMZdAFO4vNJod4ErgwmodSXz4pL+fCzrXxt+AnEx1nQcUQOy91/4O6Z7t4duBZ4J1zcfQsYA1zn7jWBhpRjtnlnOW+vKuKqUzM12ZPUO/0fFUFfDU+/PTN3c8BJRGKDmZ1hZl8zs5v23Y7y+O7AYGAekAtcGn7qakBXwDdxE+bmkRhvjNdkBtK0PUVoSPkcM1tiZj8OOpAcvckfhSZX0WRPEgkaohlBXdo2Z2BmCjNyC7lj1IlBxxGJamb2T+BEYAlQHd7shK6vq8vxrYCpwH3uvjM8LPMJM3sYeAXYe4jjdJ3LQTS29lVUOy/M28OQDvHkLJhz3K/X2NpX39S+xsXds4Hs8H19dmviqmucFz7awJm92tM9rWXQcSQKqZOIsDFZGfxm5sds2lFGp5TmQccRiWZDgf7HMhNveDa6qcAEd38JwN1XEVreBTM7idBU5V+i61wOrrG1b/KCDeypWsb9l5zGiJ7tj/v1Glv76pvaJxI5s1cXU7C9jB9e2C/oKBKlNEQzwsYOCA3TfEPDNEUiLQfIONqDwmtx/hVY6e6P1dreMfzfOOBHhIZFSRM1Ye56endsxfAeqUFHEZEYN3F+HmmtmnF+//Sgo0iUUoEXYSd2aEXvjq2YkVMYdBSRqGRm/zazV4A0YIWZzTSzV/bd6vASZxJaS2p0+HqWJeFZ664zs9XAKmAj8LeINUIiann+Dpbm7+D64ScQXptVRCQQhTvKeWdVEVed2lWTq0jEaIhmAxg7IIM/zfqUkt17SW3ZLOg4ItHm/x3Pwe7+PnCoT/2PH89rS+MwYd56mifGc8WpmUFHkRhlZkOBs4HOQBmhEQdvuvu2QINJg3tx/+QqmuxJIkdfHTSAMVkZ1Di8tULDNEXqm7u/6+7vAnnAvFqP5wPrg00nQdtZXsn0JRu5dFBn2iQnBh1HYoyZ3Wxmi4AfAM2Bj4Ei4CzgLTP7u5lpGsUYUV3jvPhRHmf3TqNbe02uIpGjM3gNIKtzG7q0bc6M3EKu0fTcIpHyL+CMWo+rw9tOCyaONAYvLcynrLKaG0Z0CzqKxKYWwJnuXnawJ81sENCb0BdUEuXeXV3Exh3l/Ghc/6CjSJTTGbwGYGaMHZDB+59sobSiKug4ItEqwd33L2UQvq8x0THM3Xl+Xh6ndG3LgC4pQceRGOTufzpUcRd+fom7v92QmSQ4E+flkdYqSZOrSMSpwGsgYwdksLe6hlmrioKOIhKtis3skn0PzOxSYEuAeSRg89aW8GlRKdcP1wg4aRzM7GIzyzazuWb2X0HnkYazcXsZ76wq4pqhmSTG6+O3RJb+D2sgQ05oR1qrJGbkajZNkQi5HfihmeWZWR7wfcILkEtsen7uetokJ3DxwM5BR5EYFR6CWduNwDmEhpPf0fCJJCgvfrSBGofrhukLJ4m8Ol2DZ2YtgTJ3rwkv+NsXeN3dKyOaLorExxnn909n+pICyiurSU6MDzqSSLSpcfcRZtYKwN1LzaxH0KEkGMW7KpiZW8iNI7rTvJn6WwnMHeG1NB9290JgA6F1NWsILb8iMaCquobJCzZwdu80uqa2CDqOxIC6nsGbDSSbWRfgDULfQP1fpEJFq7EDMtizt5r3P9GoMZEImAqhws7dS8PbpgSYRwI0ecEGKqud60fo23IJjrt/G/gj8Bcz+zHwY2AOsBy45HDHSvTI/riYTTvKNVxcGkxdZ9E0d99jZt8EnnT3X5vZkkgGi0an92xP6+QEZuQWcp4usBWpF2bWF8gCUszsilpPtQGSg0klQaqucSbOy+OME9tzYodWQceRGOfuS4FLzexiYDrwD3f/R8CxpAFNnJ9Hh9ZJnNtPn/2kYdT1DJ6Z2enA9cB/wts05uUoNUuI47x+6by1cjNV1TVBxxGJFn2AcUBb4OJatyHArQHmkoC8u7qIgu1lWhpBAmdmt5vZh2b2IdASGAu0NbOZZjYy4HjSAAq2l5H9sSZXkYZV1zN49xFapHOau+eaWU9gVuRiRa8xWRlMW1zA/LUlnNErLeg4Ik2eu08HppvZ6e4+J+g8Erzn54a+LddU5NII/Je7DzSzJOBDd38BeMLM/gk8TOgSGIliL360AQeuPU3DM6Xh1KnAc/d3gXcBwhcLb3H3eyIZLFp95aQOJCfGMSO3UAWeSP1abGZ3EhquuX9oprvfElwkaWgbSvYw6+Mi7jqnl74tl8agwMx+SGjB81X7Nrr7NuA7gaWSBlFVXcOLH+UxsncHTa4iDapOf/3MbKKZtQnPppkDrDCzByMbLTo1bxbPV07qwMzcQmpqPOg4ItHkn0AGMIbQF1KZwK5AE0mDmzQ/D0NTkUujcSmhCVXeB24KOIs0sHdWFbF5ZwVf0+Qq0sDq+vVmf3ffCVwGvA70IDSTphyDsQMy2LyzgiX524OOIhJNern7w8Bud/87cBEwPOBM0oD2VoWmIh/dN53ObZsHHUcEoLO7/9vdZ7h79YFPWkhmEMEk8ibNz6Nj6yRG9+0YdBSJMXUt8BLNLJFQgfdKeP07nX46RqP7ppMQZ8zUouci9WnfupzbzWwAkALor2oMmZFbyJbSvdygpRGk8fiNmU01s5vMLMvMOprZCWY22sz+B/gA6Bd0SKl/+dv2kL26mPGnddVwcWlwdf0/7i/AOkIzQM02s27AzkiFinYpzRM5o1caM3MKcVedLFJPnjazdoQmLngFWAH8OthI0pAmzF3PCaktGNm7Q9BRRABw96sJ9Ul9gD8B7xFaKuFbwMfAaHd/M7iEEikvfrQBgPGndQ04icSiuk6y8gTwRK1N683snMhEig1jszL44bTlfLx5F30z2gQdR6TJc/dnw3ffBXoGmUUa3iebdzFvbQkPXdCXuDgLOo7Ifu6+AvjvoHNIw6msruHFjzYw6qQOZLbT5CrS8Oo6yUqKmT1mZgvCt98SOpsnx+j8/umYwYwcDdMUqQ9m1tbM7gn3VU/suwWdSxrGhHl5NIuP4+pTdTmTiATrnVVFFO2q0GRPEpi6DtF8jtBsdNeEbzuBv0UqVCzo0DqJod3aqcATqT+vAd0JzVi3sNZNotyevVVMXZjPBSdn0L5VUtBxRCTGTZyXR0abZE2uIoGp60LnJ7r7lbUe/9TMlkQiUCwZk5XBo/9Zyfqt/7+9+w6Pskr/P/6+U0hooSahJKEX6SUUQSCgIqJiV0Bs64q6rq5t3dUt7q76+26xl3UXy9oAFbuoKAIBUUjovSOEUCM9IAlJzu+PGdbIBggwyTPl87qu52LmmWdm7kPgZO4559znAE3qaUBU5DTFO+e0r1QE+njhFvYXFDGqdxOvQxGRCLdp10FmrMnjjkGtiFFxFfFIef/l/WBmZx25Y2Z9gR8qJqTIcV77BgCqpikSGG+Y2c1m1tDM6h45vA5KKpZzjjezNtImuSbpTep4HY5IuZlZW69jkMB7a45vL04VVxEvlTfBuxV43sw2mNkG4DnglgqLKkKk1q1Gh8YJmqYpEhiFwD+AWfw4PXOupxFJhVuUu5elm/cxqncaZiquIiHlS68DkMA6XFzCO3NzyWiTRGPtxSkeKm8VzUVAZzNL8N/fZ2Z3AYuP9zx/MrgfKAaKnHPpRz1uwNPAUOAgcINzbv7JNiKUDWnfgMe+XM32fYdIToj3OhyRUHYvjzy/cwAAIABJREFUvs3Ov/c6EKk8Y2dvpFqVaC7p2tjrUET+x3EKPRlQuzJjkYo3ZcV28vYXMFLFVcRjJzU52Dm3zzl3ZP+78q51Geic63J0cud3PtDKf4wGXjiZeMLBkA6+aZpfapqmyOlai++LopNiZqlmNs3MlpvZMjP7lf98FzObbWYL/dWDewY8Yjktew8e5pPFW7ika2Nqxsd6HY5IWW4ElvLTwk9HZhcUehiXVICxWTk0rBVPRhvtxSneKm+RlbIEYi7MxcDrzrfb92x/mfOGzrmtAXjtkNAyqSbNE6szadk2rj2zqdfhiISyA8BCM5sGFBw56Zy78wTPKwLudc7NN7OawDwzm4xvk/Q/O+c+N7Oh/vsZFRO6nIp35+dy6HAJo3qpuIoErTnAUufct0c/YGZ/qvxwpKJs2nWQr9d8z6/OVnEV8d7pJHiunNd8aWYO+LdzbsxRjzcGNpW6n+s/FzEJHvimaf57xnp2HyikTvUqXocjEqo+9B8nxf+F0lb/7f1mtgJfP+SABP9ltYAtAYpTAsA5x9isjXRNq027RgknfoKIN64ADpX1gHOuWSXHIhVofHYOUQbDe6q4injvuAmeme2n7ETOgPKsHj3LObfZzJKAyWa20jk342SDNLPR+KZwkpycTGZmZrmel5+fX+5rvZRYUExxieP5D6dzVuPyTzMKlfadKrUvtFV2+5xzr53ua5hZU6ArkAXcBXxhZo/hm87e53RfXwJn1rqdrM87wONXdvY6FJHjqeGc2+V1EFKxjhRXGdQ2iYa1VFxFvHfcBM85V/N0Xtw5t9n/5w4z+wDoCZRO8DYDpb/qSPGfO/p1xgBjANLT011GRka53j8zM5PyXuulAc7x4vKpbCiqxe8zylqqWLZQad+pUvtCW6i1z8xqAO8Bd/kLST0C3O2ce8/MrgJeBs4p43lh/QXUqaro9j234BDVY6HmnjVkZq6tsPc5Fv38Qlsltu9DoBuAmb131J7CEiYmL9/O9/kFjOyl4ioSHE5niuZxmVl1IMo/5ak6MBj4y1GXfQz80szeAnoBeyNp/d0RZsZ5HRowNiuHAwVFVI+rsB+LiJTBzGLxJXdjnXPv+09fD/zKf3sC8FJZzw33L6BOVUW2b8e+Qyz8cio39m3G4LPbVch7nIh+fqGtEttXul5B88p4Q6l847NzaFQrngGtk7wORQQ4ySqaJykZmGlmi4Bs4FPn3CQzu9XMbvVf8xmwHl/1uxeBX1RgPEFtSPsGFBaVkLkqz+tQREKSmV1ZnnNlXGP4RudWOOeeKPXQFmCA//YgYE0g4pTT9/acTRSVOEaquIoEP3eM2xImNu48wNdrvufqHmlER2kvTgkOFTZU5JxbD/zP4gjn3L9K3XbA7RUVQyhJb1qXetWrMGnZNi7o1NDrcERC0QP4RtpOdO5ofYFrgSVmttB/7kHgZuBpM4vBVyRhdABjlVNUXOIYn51Dv1b1aVa/utfhiJxIZzPbh792gf82/vvOOacKQSFufPYmoqOMq3uouIoED80FDBLRUca57ZKZuHgrBUXFxMVEex2SSEgws/OBoUDjozYVTsC3BcJxOedmcuxtX7qffoQSSFNX7mDL3kP88aL2XocickLOOf0yD2OFRSW8O28Tg9om0aBWvNfhiPyXNuoIIud1aEB+QRHfrt3pdSgioWQLvk2DD/HTjYQ/Bs7zMC6pAG/O3khyQhznnKG1LiLiLV9xlUJG9lRxFQku4TuCt3sjTb8bC11aQO3QGDbv06IeNeNimLR0GwPb6sOLSHk45xYBi/yVeg8454oBzCwaiPM0OAmonJ0HmbEmjzsHaSNhEfHeuOyNNK5dlf6tE70OReQnwvc35IaZNNk4AZ7qCGOvhJWfQfEJZ2t5Ki4mmkFnJDF5xXaKiku8Dkck1HzJT/fnrAp85VEsUgHGZm8kyowR+rZcRDy24fsDfLN2J8N7pKq4igSd8E3wul7D7N5joP99sHUxvDUCnuoAUx+FPZu8ju6YhrRvwK4DhczZsNvrUERCTbxzLv/IHf/tah7GIwFUUFTMhLm5nHOG1rqIiPfGZ+cQHWVcpeIqEoTCN8EDCuKTYNDv4e5lMHwcJHeAGf8oNar3adCN6g1ok0hcTBRfLNvmdSgioeaAmXU7csfMugM/eBiPBNDnS7ax60Aho3prawQR8VZBUTET5uVydtskkhP0hZMEn/Bdg1dadAy0vcB37MmB+W/AgjfgrZFQsyF0vRa6XRcUa/WqVYmhf+tEvli2jYcuaodviy4RKYe7gAlmtgVfVcwGwNXehiSBMjZrI03rVaNvi/pehyIiEe7LZdvZdaCQkb00XVyCU1iP4JWpdhoM+h3ctdQ3qtegY9CN6g1p34Ctew+xOHevp3GIhBLn3BygLXAbcCtwhnNunrdRSSCs3LaPORt2c02vJkRprYuIeGxcVo6vuEorFVeR4BQZI3hlKdeo3rW+hLCSnX1GEjFRxqRl2+icWrvS318khLUB2gHxQDczwzn3uscxyWkaOzuHKjFRXNE9xetQRCqdvyLwXGCzc+5CM2sGvAXUw7clzLXOuUIvY4wk6/PymbV+J/cNbq0vnCRoRd4IXlmOOarXyZNRvdrVqnBmi3pMWroN51ylva9IKDOzh4Bn/cdA4O/AME+DktN2oKCIDxZs5sKODalTvYrX4Yh44VfAilL3/wY86ZxrCewGbvIkqgj11pxNxEQZV6V7v6xH5FiU4JV2ZFTvmglw12Lo/2vYtsQ3qvffCpw5lRLK4PYN+O77A6zZkX/ii0UE4ArgbGCbc+5GoDNQy9uQ5HR9uHAz+QVFXKPiKhKBzCwFuAB4yX/fgEHAu/5LXgMu8Sa6yFNQVMy783I554xkklRcRYKYErxjOd6o3ptXVPio3nntkjGDSUtVTVOknH5wzpUARWaWAOwA9BVrCHPO8ebsHM5omEC3NE1Xl4j0FHA/cGRz3HrAHufckQ8guUBjLwKLRJOWblNxFQkJkbsGr7xOuFZvlL8CZ2D/syclxNMtrQ5fLNvGnWe3Cuhri4SpuWZWG3gR37qUfGCWtyHJ6Zifs4cVW/fx6KUdVFFYIo6ZXQjscM7NM7OMU3j+aGA0QHJyMpmZmeV6Xn5+frmvDUWn074Xsn8gsapRtHkpmVuCs0/Szy+0Bap9SvBOxpFRvQG/gTVfwLxXYcZjvqPlOZB+I7Q6z5cUBsCQ9g149LMVbNp1kNS62q9Z5Hicc7/w3/yXmU0CEpxzi72MSU7P2KyN1IiL4ZIuGqCQiNQXGGZmQ/EVjkoAngZqm1mMfxQvBdhc1pOdc2OAMQDp6ekuIyOjXG+amZlJea8NRafavnV5+aycNJ1fn9eGQQNbBj6wANHPL7QFqn2aonkqylqrt31pqbV6jwRkrd557RsAaNNzkXIws/8WGnDObQCW+QuvSAjafaCQiYu3cmnXxlSP03eREnmccw8451Kcc02B4cBU59w1wDR8a44Brgc+8ijEiDI+K4eYKOPKdFXzleCnBO90lblW77Ef1+qtmHjKa/XS6lWjXcMErcMTKZ+zzewzM2toZu2B2UBNr4OSU/PuvFwKi0q4prfWuogc5TfAPWa2Ft+avJc9jifsHTpczLvzcxncPpmkmiquIsFPX4sGyrHW6r19DdRo4NtT7xTW6p3XvgFPTVnNjn2HVLFJ5DiccyPN7GpgCXAAGOmc+8bjsOQUlJQ4xmZtJL1JHdo2SPA6HBHPOecygUz/7fVATy/jiTRfLNvGnoOHGdFTXzhJaNAIXkX4yajeeGjYqYxRvcPleqkhHRrgHHy5fHsFBy0S2sysFb79ot4DNgLXmpkWr4agb9Z9z4adBxmlrRFEJAiMzcohrW41+rao73UoIuWiBK8iRcdA26H+tXpLYMD9vrV6b18DT/rX6u3eeNyXaJ1cg2b1q2sdnsiJfQL8wTl3CzAAWAPM8TYkORVvzt5I3epVOL9jA69DEZEIt3bHfrK/28WInmlERQVn5UyRoynBqyy1U2Hgg/87qvd0Z3jz8mOO6pkZ57VvwKx1O9l7sHyjfiIRqqdzbgqA83kcuNTjmOQkbdt7iK9W7ODK9BTiYqK9DkdEIty4rE3ERqu4ioQWJXiVrcxRvWXHHdUb0qEBRSWOKSs1TVPkaGZ2P4Bzbp+ZXXnUwzdUfkRyOsZn51DiHNf01PRMEfHWocPFvDc/l8HtGlC/RpzX4YiUmxI8L5VzVK9T41o0rBWvapoiZRte6vYDRz02pDIDkdNTVFzCW3Ny6N8qkbR6Wj4pIt76fOlW9v5wmJG9VFxFQouqaAaDI6N6bYfCnk2+6pvzX/9vBc6orqO4qkVv/rU4j4OFRVSroh+bSCl2jNtl3Zcg9tWKHWzfV8Ajl2j0TkS8Ny4rh6b1qnFm83pehyJyUpQpBJsjo3r974c1X8K8V+Hrx7kL6GqdWDk1j27njoDoWK8jFQkW7hi3y7r/P8wsFXgdSPZfP8Y597SZvQ208V9WG9jjnOsSgHjlGMZmbaRhrXgGtkn0OhQRiXBrtu9nzobd/Pb8tiquIiFHCV6wOmpUz817nTO+fonk2XfA0keh6yjiC1t7HaVIMOhsZvvwjdZV9d/Gf788m0cWAfc65+abWU1gnplNds5dfeQCM3sc2BvowOVH331/gK/XfM8957YmJlqrB0TEW+Oyc4iNNq7oruIqEnqU4IWC2qlEnf07ntw1hANLJ/F0g4VEff04vQD2fgy9b4MmfcH0DZNEHufcaZVadM5tBbb6b+83sxVAY2A5gJkZcBUw6DRDleMYl7WRmChjeI9Ur0MRkQh36HAx783L5bz2Kq4ioUlfk4aQwR1T+KSgCzN6PA93LSEn7XLY+C28egH8qx8sGAuHD3kdpkjIMrOmQFcgq9TpfsB259waL2KKBIcOFzNhXi6D2yeTlFCeQVcRkYrz6eKt7DtUpOIqErI0ghdC+rSoT424GL5Yto2MNp34rvm1NLn2OVj8Dsx+AT76BXz1EKTfBOk/g5rJXocsEjLMrAbwHnCXc25fqYdGAOOP87zRwGiA5ORkMjMzy/V++fn55b42FJ1M+77ZfJg9Bw/TIX5PyPyd6OcX2sK9fXJ6xmfn0Kx+dRVXkZBV4QmemUUDc4HNzrkLj3rsBuAfwGb/qeeccy9VdEyhKj42mow2iXy5bDuPXOKvHRFbFbpfD92ug/WZvkRv+l9h5hPQ4XLodSs0Ul0IkeMxs1h8yd1Y59z7pc7HAJcB3Y/1XOfcGGAMQHp6usvIyCjXe2ZmZlLea0PRybTvmX9+Q/PEWG67bAAWIlPN9fMLbeHePjl1q7fvZ+7G3Tw4tG3I9EciR6uMEbxfASuAhGM8/rZz7peVEEdYGNKhARMXb2Xuhl0/fcAMWgz0Hd+vhex/+6ZsLhrvW5/X+zZoMxSiTmu5kkjY8a+xexlY4Zx74qiHzwFWOudyKz+yyLB8yz7m5+zhDxe204cpEfHcuKwcqkRHcUV3rQeW0FWha/DMLAW4ANCoXIBktEmiSkwUXyzbfuyL6reEof+Ae5bD4Ed8e+u9PQqe6QLfPgeHVAxQpJS+wLXAIDNb6D+G+h8bznGmZ8rpezNrI3ExUVzerbHXoYhIhPuhsJj35ucypEMD6lav4nU4IqesoousPAXcD5Qc55rLzWyxmb3r349KjqNGXAz9W9Xni2XbcO4EW3xVrQ197oA7F8BVb0BCCnz5O3iiHXx2P+xcVzlBiwQx59xM55w55zo557r4j8/8j93gnPuX1zGGq/2HDvPhgs1c1LkRtavpw5SIeOvTJVvZf6iIET1VXEVCW4VN0TSzC4Edzrl5ZpZxjMs+AcY75wrM7BbgNcooRa4iBj/VJPowX+0pZMV2h5W7fQnQ/DfUSFxHSu4nJM15Gcsew8566eSmXMSe2p2CbpuFcP35HaH2SaT7cMFmDhYWM6p3E69DERFhXNZGmidWp3fzul6HInJaKnINXl9gmH+qUzyQYGZvOudGHbnAObez1PUvAX8v64VUxOCnOh8o5NXlX7F8Xyy/GJ5xks/OAG6C/dth7svUn/My9Rf9EZLa+QqydLrKV7glCITrz+8ItU8imXOON2fn0KFxAp1TankdjohEuJXbfOuBf3/BGVoPLCGvwqZoOucecM6lOOea4lvHMrV0cgdgZg1L3R2GrxiLnECd6lXo1awuc7cXUVJygmmax1IzGQY+CHcvg4ufB4uCT+70Td+c8jDs2xrYoEVESpm7cTertu9nVK8m+jAlIp47Ulzl8m4pXocictoqfaNzM/uLmQ3z373TzJaZ2SLgTuCGyo4nVF3cpRHbDjiu+Ne3LNtyGkVTYuOh6yi4dSZcPxHSzoSvH4enOsB7P4fN8wIXtIiI35uzN1IzPoZhXRp5HYqIRLgfCov5YP5mzu/YgDoqriJhoFI2OnfOZQKZ/tt/LHX+AeCByogh3FyVnsqa1av4YP1BLnp2Jted2ZR7BrcmIT721F7QDJr18x271kP2izD/DVgyAVJ7+aZvnjEMoivln4yIhLGd+QV8vmQbI3ulUa2K+hQR8dYni7ewv6CIkSquImGi0kfwJDDMjLMaxzL13gyu6dWE12ZtYNBj03l/fu6Jq2ueSN3mMOT/fNssDPkr5G+Hd2+EpzvDzKfg4K4Tv4aIyDFMmJdLYXEJI3vpw5SIeG9cVg4tEqvTs5mKq0h4UIIX4mpVi+XhSzrw8e1n0bhOVe55ZxFXj5nNqm37T//F4xN8G6TfMR+Gj4e6zeCrh+DJ9jDxHshbffrvISIRpaTEMS4rh57N6tI6uabX4YhIhFu+ZR8LN+1hRM80rQeWsKEEL0x0TKnFB7f14f8u68jq7fsZ+szXPDJxOfkFRaf/4lHR0HYo3DDRt1av/WWw4E14vge8eTms/QpOd9RQRCLCjDV55Ow6qK0RRCQojM/OoUpMFFd0V3EVCR9K8MJIVJQxomca0+7N4Kr0FF6a+R1nP57JJ4u2nP60zSMadIRLnvdV3xz4O9i2xJfkPd8T5rwMhQcC8z4iEpbenJ1D/RpVGNK+gdehiEiEO1hYxIcLNnNBx4bUrqbiKhI+lOCFoTrVq/B/l3Xig1/0IbFmHHeMX8Col7NYuyM/cG9SIxEG3A93LYFL/+3bO+/Te3zbLEx+CPbmBu69RCQsbN7zA1NXbueq9FSqxOjXj4h465NF/uIqWg8sYUa/YcNY17Q6fHT7WTx8cXuW5O7l/Kdn8LdJKzlYGIBpm0fExEHn4TB6Otw4CZr1h2+fgac6wYQbYFO2pm+KCABvZefggBGqVCciQWBc9iZaJtUgvUkdr0MRCSgleGEuOsq49symTL0vg4u7NOaFzHWc8/h0Ji3dGrhpm+DbZqHJmXD1G3DnQjjzF7B2Krx8Lrx0NiyeAEWFgXs/EQkph4tLeGvOJga2SSK1bjWvwxGRCLdsy14WbdrDSBVXkTCkBC9C1K8Rx2NXdmbCrWeSUDWWW9+czw3/mcN331fAmrk6TWDwI75tFoY+Bof2wvs/h6c7wYzH4MDOwL+niAS1ycu3k7e/gFG9NXonIt4bl5VDXEwUl3dTcRUJP0rwIkyPpnWZeMdZ/PHCdszbuJvznpzBE1+u4tDh4sC/WVwN6Hkz3D4HRk6AxLYw9WF4sh18fAdsXx749xSRoPTm7I00rl2VAa2TvA5FRCLcgYIiPlq4hQs6NaRWtVivwxEJOCV4ESgmOoqfndWMqfcO4PyODXhm6lrOfXI6U1Zsr5g3jIqC1oPhug/htlnQ6WpY/A68cCa8fjGs/gJKSirmvUXEc+vy8vl23U5G9kojOkpToUTEW58s2kJ+QREjtR5YwpQSvAiWlBDP08O7Mu7mXsTFRHPTa3P5+Wtz2LTrYMW9aXI7GPYM3L0czv4j5K2CcVfBc+mQNQYKAljpU0SCwtjZOcRGG1elp3odiogI47JzaJ1cg+4qriJhSgme0KdFfT67sx8PnN+Wb9ft5JwnpvPslDUUFFXAtM0jqteDfvf6tlm4/GWoWhs+/7Vvm4Uvfge7N1bce4tIpfmhsJh3523ivPYNSKwZ53U4IhLhNuwtZnHuXhVXkbCmBE8AqBITxS0DWjDl3gGcc0Yyj09ezXlPzmD66ryKfePoWOh4Bdw8FW76ClqeDbNfgGe60GHJIzDvNe2pJxLCPlm8hX2HihjVu4nXoYiIkLmpiLiYKC5VcRUJYzFeByDBpWGtqjx/TTeuXp3HQx8v4/pXsjm/QwP+cGE7GtWuWrFvntoDUv/jS+iyX6TmnNfhkzt9jyW2hRZn+xLAJn18G6uLSNAbO3sjrZJq0KtZXa9DEZEIl19QxOytRVzYOYVaVVVcRcKXEjwpU//WiUy6qx8vff0dz05dQ+aqPO48uxU3ndWMKjEVPPBbKwXO/TOzYjLIaJcM66bA2q9gzosw+3mIiYemZ/2Y8NVv7duHT0SCypLcvSzK3cufLmqnqVAi4rl3527iUDGM7KXiKhLelODJMcXFRHP7wJYM69yIhycu52+TVvLe/Fz+Mqw9fVrWr/gAzHxFWZLbQZ87oPAAbPjGn/BNgS8egC+AWqnQYhC0PAeaD4D4WhUfm4ic0NisjVSNjdZUKBHx3JfLtvHoZytoXSeKbmm1vQ5HpEIpwZMTSq1bjTHXpTN15Xb+9PFyRr6UxUWdG/H7C84gOSG+8gKpUt233ULrwb77uzf+mOwtfR/mvwYWDak9/aN7g6BhV982DSJSqQ4edny0cAvDOjfSVCgR8dSkpVv55bgFdGhci5tbF2pGgYQ9JXhSboPaJtOnRX1eyFzHC9PXMXXFdu4+tzXX92lKbLQHSVSdJpD+M99RfBhy5/imcq6dAtMe8R3V6kHzgb6pnC3OhprJlR+nBDUzSwVeB5IBB4xxzj3tf+wO4HagGPjUOXe/Z4GGmG+2FPHD4WIVVxERT322ZCt3jF9Ap5RavPaznsyf/Y3XIYlUOCV4clLiY6O5+9zWXNatMX/6eBmPfLqCCXNzefiSDvT0sohCdKyv+EqTPr799fLzYP00X8K3biosfdd3XXJHX7LX8mxI7Q0xVbyLWYJFEXCvc26+mdUE5pnZZHwJ38VAZ+dcgZkleRplCHHOMS3nMJ1TatExRVOmRcQbnyzawl1vL6RLam1evbEHNeM1m0AigxI8OSVN6lXnlRt6MHn5dv78yXKu+vcsLuvWmAfOPyM49rqqkQidrvIdJSWwfYl/dG8qzHoOvnkKqtSApv1+TPjqNvc6avGAc24rsNV/e7+ZrQAaAzcDf3XOFfgf2+FdlKEl67tdbDnguOt8jd6JiDc+WriZu99eSPcmdfjPjT2pEaePvBI59K9dTpmZMbh9A/q1SuS5aWsYM2M9k5dv577BbbimVxoxXkzbLEtUFDTs7Dv63QuH9sGGr3+czrn6c991dZr5CrW0PNuX+MXV8DZuqXRm1hToCmQB/wD6mdmjwCHgPufcHO+iCx1vzt5ItRi4qFMjr0MRkQj0wYJc7n1nEelN6/KfG3pQXcmdRBj9i5fTVrVKNL8+ry2XdUvhoY+W8dDHy3h7ziYeubQD3dLqeB3e/4pPgLYX+A7nYNf6H5O9hWN92zFExUJa7x8TvuQO2oohzJlZDeA94C7n3D4ziwHqAr2BHsA7ZtbcOeeOet5oYDRAcnIymZmZ5Xq//Pz8cl8bSqbmHObT5YVkNHJkffu11+FUmHD9+R2h9kmoem9eLve9u4jezerx8g3pVKuij7oSefSvXgKmRWIN3ripJ58t2cbDE5dz2T+/5er0VH5zflvqVg/StW5mUK+F7+h1CxQVQM6sH6dzfvWQ76iR/OO+e80HQvV6XkcuAWRmsfiSu7HOuff9p3OB9/0JXbaZlQD1gbzSz3XOjQHGAKSnp7uMjIxyvWdmZiblvTYUlJQ4/vbFSl5fvp6z2yZxVUp+WLXvaOH28zua2uc9M4sHZgBx+D6vveuce8jMzsY3wyAKyAducM6t9S7S4PHO3E385r3F9GlRj5eu60HVKtFehyTiCSV4ElBmxgWdGjKgTSLPTFnDKzO/Y9Kybdw/pA3De6QRHRXko2AxcdA8w3cMBvZt8RVpWTsFVn0Gi8YBBo26+tfunQON0yFa/5VClfnqZb8MrHDOPVHqoQ+BgcA0M2sNVAG+9yDEoHfocDH3TVjExMVbuaZXGn8e1p6ZX8/wOiyRUFcADHLO5fu/hJppZp8DLwAXO+dWmNkvgN8DN3gYZ1B4e04Ov31/CWe1rM+L16UTH6vkTiKXPpVKhagRF8ODQ8/giu4p/OHDpfzug6W8M2cTD1/SgU4pIbTBaEIj6DrKd5QUw5YFP07n/PpxmPEPiKvl22D9yFYMtVO9jtobzvk2oy/YBwX7qbF/PZDhdVTl0Re4FlhiZgv95x4EXgFeMbOlQCFw/dHTMwX2HCxk9OvzyN6wi9+e35Zb+jfXHlMiAeDvb/L9d2P9h/MfCf7ztYAtlR9dcBmXlcODHyyhf+tExlzbXcmdRDwleFKhWifX5K3Rvfl40RYe+XQFFz//DSN7pvHr89pQu1qQTts8lqhoSEn3HRm/hR92w/pMX7K3dgqs+Nh3Xf02P1bmbNIXYqt6GvYJOQeF+VCwv9Sxz1eM5uhzBUedK31N4X5wJf992c4x1eGin3nYsPJxzs0EjpWRjKrMWELNpl0Huf4/2eTu+oFnRnRlWGcVVREJJDOLBuYBLYHnnXNZZvZz4DMz+wHYh2+dcMR6Y/ZG/vDhUga2SeSFUUruREAJnlQCM+PiLo0Z2DaJpyav4bVZG/h86TZ+e35bruiWQlSwT9s8lqp1oP2lvsM5yFv54+jenJdh9j8hJt6X5B0Z3UtsE7hiLSUlcPjAUQnX3qOSsjISs7ISN8oxMBVbDeJqQlyC/8+aUC/Rdz++1Dn/NStWb6RTYFoqQWhx7h5+9uocCotKeOOmnvRqrnWpIoF9KylBAAAaYElEQVTmnCsGuphZbeADM+sA3A0M9Sd7vwaeAH5+9HMjoQDUVxsP8+aKQjonRjOyyQFmf3Piwk6h1L5TofaFtkC1TwmeVJqE+Fj+eFE7ruiewh8/Wsr97y7m7Tmb+MvF7WnfKMQ3QzaDpDN8R587oPAgbPzGP7r3FXzxoO+6hBRoOQhankP8D4cgb5U/4SprtGx/gBKz6j9NvuIToGbyTxO1nyRuCT+9Nq4mVKl50usMd+3MPOm/RgkNXy3fzh3jF1CvRhXeGt2blkk1vQ5JJKw55/aY2TTgfKCzcy7L/9DbwKRjPCesC0C9+s13vLliOeeckczz13QlLqZ8I3eh0r5TpfaFtkC1r8ITPP/0grnAZufchUc9Fge8DnQHdgJXO+c2VHRM4q12jRJ455YzeW9+Ln/9fCUXPTuT685syj2DW5MQH+t1eIFRpRq0Otd3AOzJ+THZW/YhzH/dN6cm6zivcSQxKz069t/E7OjkrCbE1/rfc6eQmIkczxuzNvDQx8to36gWL9+QTlLNeK9DEglLZpYIHPYnd1WBc4G/AbXMrLVzbrX/3Aov4/TCyzO/4+GJyxncLpnnRnajSkyQ7LsrEiQq45Pfr/B1PgllPHYTsNs519LMhuPruK6uhJjEY1FRxpXpqQxu14DHvlzFa7M2MHHxVn53QVsu6dI4/Io01E6D9Bt9R/FhyJ3Dqm8m0qZT96OStSMjZjWUmElQObINwr+n+7ZBeHZkV+0vJVKxGgKv+b8ojwLecc5NNLObgff8W7fsBoJ/sXMAvThjPY9+toIh7Rvw7MiuxEYruRM5WoX+djazFOAC4FHgnjIuuRj4k//2u8BzZmaqVBc5alWL5eFLOnBVeiq//2gpd7+9iLeyfdU2w1Z0LDTpw9bvCmnTIcPraEROqPQ2CKN6p/Gni9oTow9VIhXKObcY6FrG+Q+ADyo/Iu/9a/o6/vr5Si7o2JCnhndRcidyDBX9P+Mp4H6g5BiPNwY2ATjnioC9gFbqR6COKbX44LY+/N9lHVm1fT9Dn/6asSsK2LTroNehiUS0PQcLufblLCYu3spvz2/Lwxd3UHInIpXu+Wlr+evnK7mwU0OeVnInclwVNoJnZhcCO5xz88ws4zRfK+wrQZ2KcGxfQ+Dh3rFMWO34auNhvvr7NNrXi2ZAagxdk6KJCdWKm2UIx59faeHevkigbRBEJBg8O2UNj09ezcVdGvH4lZ31JZPICVTkFM2+wDAzGwrEAwlm9qZzrvS+UpuBVCDXzGLwbdi58+gXCvdKUKcqnNt30WB4f9JUNsWk8vacHJ5feIj6NeK4Mj2FET3SSKtXzesQT1s4//wg/NsX7hZt2sNNr83hcLHTNggi4pmnvlrNU1+t4dKujXnsys5Eh9EXvSIVpcISPOfcA8ADAP4RvPuOSu4APgauB2YBVwBTtf5OjqgbH8VlGa345aCWzFidx7jsHMbMWM8Lmevo16o+I3qmcc4ZyaqeJRJgP90GoYe2QRCRSuec48mv1vDMlDVc3i2Fv1/RScmdSDlVegk0M/sLMNc59zHwMvCGma0FdgHDKzseCX7RUcbAtkkMbJvEtr2HmDB3E2/N2cQvxs6nfo0qXNE9leE9Umlav7rXoYqEPG2DICJec87x+JereW7aWq7snsJfL1dyJ3IyKiXBc85lApn+238sdf4QcGVlxCDhoUGteO44uxW/GNiSGWvyGJ+Vw4tfr+df09fRt2U9RvZswrntNKoncrJKShx/m7SSf8/QNggi4h3nHH//YhUvZK5jeI9U/t+lHYlScidyUvTbW0JSdJQxsE0SA9sksX2fb1RvfPYmbh83n3rVq3BFegrDe6TRTKN6IiekbRBEJBg45/jr574vmkb2SuORizsouRM5BUrwJOQlJ8Tzy0GtuC2jJTPXfs/4rBxe+vo7/j19PX1a1GNEzzQGt08mLiba61BFgs6eg4Xc/Ppc5mzYzW/Pb8st/Ztjpg9UIlK5nHM8+ukKXpr5HaN6p/GXYUruRE6VEjwJG9FRxoDWiQxonciOfYeYMC+X8dk53DF+AXWrV+GK7ikM75FK88QaXocqEhRKb4Pw7IiuXKRtEETEA845Hp64gle++Y7rz2zCn4a11xdNIqdBCZ6EpaSEeG4f2JLbBrTwjepl5/DKzO8YM2M9Zzavx4heaZynUT2JYKW3QXjz573o2ayu1yGJSARyzvHnT5bz6rcbuLFvU/54YTsldyKnSQmehLWoKKN/60T6t05kx/5DvDsvl7eyN3Hn+AXUqRbrG9XrmUYLjepJBJm8fDt3/ncbhJ60TNK/fxGpfM45Hvp4Ga/P2shNZzXj9xecoeROJACU4EnESKoZzy8yWnJr/xZ8s843qvefbzbw4tff0atZXUb2SuO89g2Ij9WonoSvI9sgdGhci5ev70FizTivQxKRCFRS4vjDR0sZm5XD6P7NeeD8tkruRAJECZ5EnKgoo1+rRPq1SiRvfwHv+tfq/eqthdSuFsvl3VIY0TNNoxoSVrQNgogEi5ISx+8+XML47E3cOqAFvxnSRsmdSADpt7tEtMSacdyW0YJb+jdn1vqdjMvO4fVZG3h55nf0bFaXkT3TGNJBo3oS2rQNgogEi5ISxwPvL+HtuZu4fWAL7hus5E4k0JTgieAb1evbsj59W9bn+/wC/1q9HO56eyG1P4nlsq4pjOiZSqvkml6HKnJSSm+D8MD5bRmtbRBExCPFJY7fvLeYd+flcuegltx9bmv1RyIVQAmeyFHq14jj1gEtGN2vObP9o3pvzN7AK998R4+mdRjRM42hHRtqVE+CXs7Og9zwqrZBEBHvFZc4fj1hEe8v2Mxd57TirnNaex2SSNhSgidyDFFRRp+W9enTsj478wt4b34u47M3cc87i/jzJ8u5rFtjRvRMo7VG9SQIaRsEEQkWRcUl3DdhER8u3MI957bmzrNbeR2SSFhTgidSDvVqxDG6fwtu7udbqzc+exNjZ/uqcKY38Y3qXdBJo3qhyMxSgdeBZMABY5xzT5vZn4CbgTz/pQ865z7zJsqTo20QRCRYFBWXcPc7i/hk0RZ+fV4bbh/Y0uuQRMKeEjyRk2Bm9GlRnz4tfKN678/fzPjsHO6dsIg/f7KMy/wVONs00KheCCkC7nXOzTezmsA8M5vsf+xJ59xjHsZ20l6ftYE/aRsEEQkCh4tLuOvthXy6eCu/GdKW2zJaeB2SSERQgidyiurViOPm/s35eb9mZH23i/HZOYzLyuHVbzfQLa02I3s14YKODalaRaN6wcw5txXY6r+938xWAI29jerkaRsEEQkmh4tLuHP8Aj5fuo0Hh7ZldH8ldyKVRb/9RU6TmdG7eT16N6/HQxcV8v78XMZl53DfkVG9ro0Z0SuNtg0SvA5VTsDMmgJdgSygL/BLM7sOmItvlG93Gc8ZDYwGSE5OJjMzs1zvlZ+fX+5rT6Sw2PHSkgKytxUzKDWGkWn5ZH87MyCvfaoC2b5gpPaFtnBvn9cKi0q4Y/x8vli2nd9fcAY/79fc65BEIooSPJEAqlu9Cj/v15ybzmpGtn9Ub/ycTbw2ayNd02ozomcaF3ZqqJGVIGRmNYD3gLucc/vM7AXgYXzr8h4GHgd+dvTznHNjgDEA6enpLiMjo1zvl5mZSXmvPZ7/boOw7WBQbYMQqPYFK7UvtIV7+7xUWFTC7ePmM3n5dv54YTt+dlYzr0MSiTj6lClSAcyMXs3r0at5PR46UMj7CzYzLmsj97+7mIc/Wc4lXRvTwopxzgXFh/FIZ2ax+JK7sc659wGcc9tLPf4iMNGj8I5J2yCISDApKCrm9rHz+WrFDv50UTtu6KvkTsQLSvBEKlid6lW46axm/KxvU+Zs2M347BzenruJwqIS/rl0CgNaJ5LRJomzWtWnVtVYr8ONOObLsF8GVjjnnih1vqF/fR7ApcBSL+I7Fm2DICLB5NDhYn4xdj5TV+7g4Yvbc+2ZTb0OSSRiKcETqSRmRs9mdenZrC4PXdSOZ9+fzraounyxbBsT5uUSHWV0S6tNRpskBrROpH2jBI3uVY6+wLXAEjNb6D/3IDDCzLrgm6K5AbjFm/D+1+Tl27lj/HwSa8bx1g3aBkFEvHXocDG3vDGP6avzePTSDlzTq4nXIYlENCV4Ih6oXa0K/VJiycjoRlFxCQs37SFzVR7TV+fxjy9W8Y8vVpFYM47+rRLJaJNI/1aJ1Kqm0b2K4JybCZSVSQflnnfaBkFEgsmhw8Xc/Ppcvl7zPf93WUdG9EzzOiSRiKcET8RjMdFRpDetS3rTutx3Xhvy9hcwY3UemavzmLJyO+/NzyXKoGtaHTL80znbN0ogKkqje5Gk9DYI55yRxDMjtA2CiHjrh0JfcvfNuu/5++WduKpHqtchiQhK8ESCTmLNOC7vnsLl3VMoLnEs3LSH6at2MH11Hk98tZrHJ6+mfo0q9G+VyAD/6F6d6lW8Dlsq0KHDxdw7YRGfLt7Ktb2b8Kdh7YlWgi8iHjpYWMTPX5vLrPU7+ccVnbmie4rXIYmInxI8kSAWHWV0b1KH7k3qcM/gNnyfX8DXa/LIXJXHtFU7eH/BZqIMOqfWJqN1EhltEunYuJZG98LI7gOFjH5jLnM27A6qbRBEJHIdLCziZ6/OIfu7XTx+ZWcu66bkTiSYKMETCSH1a8RxadcULu3qG91bnPvj2r2npqzmya9WU7d6Ffq3qk9GmyT6t06krkb3Qpa2QRCRYHOgoIgb/zOHuRt38eTVXbi4S2OvQxKRoyjBEwlR0VFG17Q6dE2rw93ntmbXgcL/ju7NWJ3Hhwu3YAadUmr71+4l0imltqb2hQhtgyAiwSa/oIgbXslmwaY9PDW8K8P0pZNIUFKCJxIm6lavwsVdGnNxl8aUlDiWbN7rH93bwbNT1/D0lDXUqRZLvyOVOVsnUr+GKjAGI22DICLBZv+hw1z/SjaLcvfyzPCuXNCpodchicgxKMETCUNRUUbn1Np0Tq3Nr85pxe4DhXy99nsyV+1gxuo8Pl7kG93r2LgWGa19xVq6pNbR6F4QOLINQsfGtXhJ2yCISBDY50/uluTu5bkRXTm/o5I7kWCmBE8kAtSpXoVhnRsxrHMjSkocy7bsI9NfmfO5aWt5ZupaalWNpZ9/7d6A1olKLCpZSYnjr5NWMkbbIIhIENn7w2GueyWbZZv38tzIbgzp0MDrkETkBPTpQSTCREUZHVNq0TGlFnec3Yq9Bw/z9dq8/xZrmbh4KwAdGieQ0TqJAW0S6Zpam5joKI8jD1/aBkFEgtHeg4e59pUsVmzdxz+v6cbg9kruREJBhSV4ZhYPzADi/O/zrnPuoaOuuQH4B7DZf+o559xLFRWTiPyvWtViubBTIy7s5BvdW751H9NX5zF9VR4vTF/Hc9PWkhAfQz//vnsZrRNJSoj3OuywUXobhAeHtuXmftoGQUS8t+dgIaNezmL1tnxeuKY757RL9jokESmnihzBKwAGOefyzSwWmGlmnzvnZh913dvOuV9WYBwiUk5RUUaHxrXo0LgWtw9syd4fDvONf+1e5qo8Pl3iG91r1zCBjDaJZLRJomtabWI1undKcnYe5Ib/ZJO7+weeG9mVCzupIp2IeG/3gUKueSmLtTvy+fe13RnYNsnrkETkJFRYguecc0C+/26s/3AV9X4iEni1qsYytGNDhnZsiHOOFVv3k7l6B9NX5TFmxnr+mbmOmvExnNWyPhltEhnQOokGtTS6Vx7r9xRz7z+/oahE2yCISPDYX+gY+VIW6/LyGXNddzLaKLkTCTUVugbPzKKBeUBL4HnnXFYZl11uZv2B1cDdzrlNZbzOaGA0QHJyMpmZmeV6//z8/HJfG4rUvtAWqu1rB7RrAwebV2X5zmIWf1/M7DXb+XzpNgBSa0bRsX40LasXUjJtGlGabvg/Ji/fzl+zD5Fcuyqv3tiTFonaBkFEvLczv4C/Zf9A3iHjpevS6d860euQROQUVGiC55wrBrqYWW3gAzPr4JxbWuqST4DxzrkCM7sFeA0YVMbrjAHGAKSnp7uMjIxyvX9mZiblvTYUqX2hLRzaN9T/p3OOVdv3+wq1rMrjyw27mBZlLBkxQMVZjrLnYCH3vL2QxjWjeOe2vqpWKiJB47EvV7PjoOOVG3tyVqv6XocjIqeoUqpoOuf2mNk0YAiwtNT5naUuewn4e2XEIyKBZWa0bZBA2wYJ3DqgBfkFRbzz+XQld2WoXa0Kr93Uk7zVC5XciUhQ+f0FZ9AyaoeSO5EQV2Gfvsws0T9yh5lVBc4FVh51TemdMocBKyoqHhGpPDXiYmheO9rrMIJWt7Q6xMVo6qqIBJfqcTG0UN8tEvIq8uv1hsA0M1sMzAEmO+cmmtlfzGyY/5o7zWyZmS0C7gRuqMB4REREREKCmcWbWbaZLfJ/Vvqz/7yZ2aNmttrMVpjZnV7HKiLBpSKraC4GupZx/o+lbj8APFBRMYiIiIiEqDK3mwLOAFKBts65EjNTmUsR+YlKWYMnIiIiIuV3nO2mbgNGOudK/Nft8CZCEQlWqoAgIiIiEoTMLNrMFgI78C11yQJaAFeb2Vwz+9zMWnkbpYgEG43giYiIiAShsrabAuKAQ865dDO7DHgF6Hf0c7WHcNnUvtCm9pWPEjwRiWhmlgq8DiTjm/40xjn3dKnH7wUeAxKdc997E6WIRLKjtpvKBd73P/QB8J9jPEd7CJdB7Qttal/5aIqmiES6IuBe51w7oDdwu5m1g/8mf4OBHA/jE5EIdJztpj4EBvovGwCs9iZCEQlWGsETkYjmnNsKbPXf3m9mK4DGwHLgSeB+4CPvIhSRCNUQeM3MovF9If+Of7upmcBYM7sbXxGWn3sZpIgEHyV4IiJ+ZtYU3/YuWWZ2MbDZObfITJuSi0jlOs52U3uACyo/IhEJFUrwREQAM6sBvAfchW/a5oP4pmee6HkqZFAGtS+0qX0iIqHLfNushA4zywM2lvPy+kA4F0VQ+0Kb2vejJs65xIoM5nj8mwhPBL5wzj1hZh2BKcBB/yUpwBagp3Nu23FeR/3Tj9S+0Kb2/cjT/ikQ1Df9hNoX2tS+Hx2zbwq5BO9kmNlc51y613FUFLUvtKl9wcF88y9fA3Y55+46xjUbgPRAVtEMlb+fU6X2hTa1L3KF+9+N2hfa1L7yURVNEYl0fYFrgUFmttB/DPU6KBEREZFToTV4IhLRnHMzgeNWUXHONa2caEREREROT7iP4I3xOoAKpvaFNrUvsoX734/aF9rUvsgV7n83al9oU/vKIazX4ImIiIiIiESScB/BExERERERiRhhm+CZ2RAzW2Vma83st17HE0hm9oqZ7TCzpV7HUhHMLNXMppnZcjNbZma/8jqmQDKzeDPLNrNF/vb92euYAs3Mos1sgZlN9DqWYBPOfROEd/+kvik8qH86tnDun8K5bwL1T+EgkH1TWCZ4ZhYNPA+cD7QDRphZO2+jCqhXgSFeB1GBioB7nXPtgN7A7WH28ysABjnnOgNdgCFm1tvjmALtV8AKr4MINhHQN0F490/qm8KD+qcyRED/9Crh2zeB+qdwELC+KSwTPKAnsNY5t945Vwi8BVzscUwB45ybAezyOo6K4pzb6pyb77+9H98/9sbeRhU4zifffzfWf4TNYlgzSwEuAF7yOpYgFNZ9E4R3/6S+KfSpfzqusO6fwrlvAvVPoS7QfVO4JniNgU2l7ucSRv/II4mZNQW6AlneRhJY/mH4hcAOYLJzLpza9xRwP1DidSBBSH1TmFDfFLLUPx2b+qcwof4pJAW0bwrXBE/CgJnVAN4D7nLO7fM6nkByzhU757oAKUBPM+vgdUyBYGYXAjucc/O8jkWkoqhvCk3qnyQSqH8KPRXRN4VrgrcZSC11P8V/TkKEmcXi66DGOufe9zqeiuKc2wNMI3zWBfQFhpnZBnzTewaZ2ZvehhRU1DeFOPVNIU390/Gpfwpx6p9CVsD7pnBN8OYArcysmZlVAYYDH3sck5STmRnwMrDCOfeE1/EEmpklmllt/+2qwLnASm+jCgzn3APOuRTnXFN8/++mOudGeRxWMFHfFMLUN4U29U8npP4phKl/Cl0V0TeFZYLnnCsCfgl8gW+R6TvOuWXeRhU4ZjYemAW0MbNcM7vJ65gCrC9wLb5vMBb6j6FeBxVADYFpZrYY3y/Uyc45leuOAOHeN0HY90/qmyRshXv/FOZ9E6h/klLMubApQCMiIiIiIhLRwnIET0REREREJBIpwRMREREREQkTSvBERERERETChBI8ERERERGRMKEET0REREREJEwowZMKZ2bFpUr2LjSz3wbwtZua2dJAvZ6IRBb1TyISjNQ3yemI8ToAiQg/OOe6eB2EiEgZ1D+JSDBS3ySnTCN44hkz22BmfzezJWaWbWYt/eebmtlUM1tsZlPMLM1/PtnMPjCzRf6jj/+los3sRTNbZmZfmllVzxolImFB/ZOIBCP1TVIeSvCkMlQ9aprB1aUe2+uc6wg8BzzlP/cs8JpzrhMwFnjGf/4ZYLpzrjPQDVjmP98KeN451x7YA1xewe0RkfCh/klEgpH6Jjll5pzzOgYJc2aW75yrUcb5DcAg59x6M4sFtjnn6pnZ90BD59xh//mtzrn6ZpYHpDjnCkq9RlNgsnOulf/+b4BY59wjFd8yEQl16p9EJBipb5LToRE88Zo7xu2TUVDqdjFaWyoigaH+SUSCkfomOS4leOK1q0v9Oct/+1tguP/2NcDX/ttTgNsAzCzazGpVVpAiEpHUP4lIMFLfJMelbF0qQ1UzW1jq/iTn3JFyv3XMbDG+b5JG+M/dAfzHzH4N5AE3+s//ChhjZjfh+7bpNmBrhUcvIuFM/ZOIBCP1TXLKtAZPPOOfR57unPve61hEREpT/yQiwUh9k5SHpmiKiIiIiIiECY3giYiIiIiIhAmN4ImIiIiIiIQJJXgiIiIiIiJhQgmeiIiIiIhImFCCJyIiIiIiEiaU4ImIiIiIiIQJJXgiIiIiIiJh4v8DHOnVL8bGOisAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1080x360 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_99dtAVn5CL"
      },
      "source": [
        "***Inference***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gk9dSwSR_OM9",
        "outputId": "700b8c99-9861-4690-8429-fd0d268635cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "drqa.load_state_dict(torch.load('./checkpoints/DrQA.pth'))\n",
        "drqa.to(DEVICE)"
      ],
      "execution_count": 290,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DrQA(\n",
              "  (dropout): Dropout(p=0.25, inplace=False)\n",
              "  (embedding): Embedding(26885, 300, padding_idx=1318)\n",
              "  (align_question_embedding_layer): AlignQuestionEmbeddingLayer(\n",
              "    (linear): Linear(in_features=300, out_features=300, bias=True)\n",
              "  )\n",
              "  (ctx_stacked_bi_lstm_layer): StackedBiLSTMsLayer(\n",
              "    (dropout): Dropout(p=0.25, inplace=False)\n",
              "    (lstms): ModuleList(\n",
              "      (0): LSTM(604, 256, num_layers=3, batch_first=True, bidirectional=True)\n",
              "      (1): LSTM(512, 256, num_layers=3, batch_first=True, bidirectional=True)\n",
              "      (2): LSTM(512, 256, num_layers=3, batch_first=True, bidirectional=True)\n",
              "    )\n",
              "  )\n",
              "  (qst_encoding_layer): QuestionEncodingLayer(\n",
              "    (stacked_bilstms_layer): StackedBiLSTMsLayer(\n",
              "      (dropout): Dropout(p=0.25, inplace=False)\n",
              "      (lstms): ModuleList(\n",
              "        (0): LSTM(300, 256, num_layers=3, batch_first=True, bidirectional=True)\n",
              "        (1): LSTM(512, 256, num_layers=3, batch_first=True, bidirectional=True)\n",
              "        (2): LSTM(512, 256, num_layers=3, batch_first=True, bidirectional=True)\n",
              "      )\n",
              "    )\n",
              "    (linear): Linear(in_features=300, out_features=1, bias=True)\n",
              "  )\n",
              "  (bilinear_attention_layer_start): BiLinearAttentionLayer(\n",
              "    (linear): Linear(in_features=1536, out_features=1536, bias=True)\n",
              "  )\n",
              "  (bilinear_attention_layer_end): BiLinearAttentionLayer(\n",
              "    (linear): Linear(in_features=1536, out_features=1536, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 290
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1CVgakLDtsU"
      },
      "source": [
        "def inference(model: nn.Module, context: spacy.tokens.doc.Doc, question: spacy.tokens.doc.Doc,\n",
        "              text_vocab: Vocab, pos_vocab: Vocab, ner_vocab: Vocab, device: torch.device):\n",
        "    # Build extra features\n",
        "    question = [token.text.lower() for token in question]\n",
        "    counts = collections.Counter(map(lambda token: token.text.lower(), context))\n",
        "    freqs = {index: counts[token.text.lower()] for index, token in enumerate(context)}\n",
        "    freqs_norm = sum(freqs.values())\n",
        "    em, pos, ner, ntf = zip(\n",
        "        *map(lambda index: [\n",
        "            context[index].text.lower() in question, context[index].tag_,\n",
        "            context[index].ent_type_ or 'None',\n",
        "            freqs[index] / freqs_norm\n",
        "        ], range(len(context)))\n",
        "    )\n",
        "\n",
        "    # Build tensors\n",
        "    ctx = torch.LongTensor([*map(lambda word: text_vocab.stoi(word), context)]).unsqueeze(0).to(device)\n",
        "    qst = torch.LongTensor([*map(lambda word: text_vocab.stoi(word), question)]).unsqueeze(0).to(device)\n",
        "    len_ctx = torch.LongTensor([len(context)]).to(device)\n",
        "    len_qst = torch.LongTensor([len(question)]).to(device)\n",
        "    em = torch.LongTensor(em).unsqueeze(0).to(device)\n",
        "    pos = torch.LongTensor([*map(lambda x: pos_vocab.stoi(x), pos)]).unsqueeze(0).to(device)\n",
        "    ner = torch.LongTensor([*map(lambda x: ner_vocab.stoi(x), ner)]).unsqueeze(0).to(device)\n",
        "    ntf = torch.LongTensor(ntf).unsqueeze(0).to(device)\n",
        "\n",
        "    # Prediction\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Feed the model\n",
        "        start, end = model(ctx_sequences=ctx, ctx_lengths=len_ctx, qst_sequences=qst, qst_lengths=len_qst,\n",
        "                           em_sequences=em, pos_sequences=pos, ner_sequences=ner, ntf_sequences=ntf)\n",
        "    \n",
        "        # Decode the result indexes\n",
        "        start_index, end_index, proba = model.__class__.decode(starts=F.softmax(start, dim=-1), ends=F.softmax(end, dim=-1))\n",
        "\n",
        "        # Extract the answer\n",
        "        answer = context[start_index[0]:end_index[0] + 1]\n",
        "\n",
        "    return answer, proba[0]"
      ],
      "execution_count": 320,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dI-ME2Q1-WzB",
        "outputId": "c389a9a7-2ae7-489d-8a3f-e8ef528c5f22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for index in np.random.choice(len(valid_qas), size=25, replace=False):\n",
        "    id = valid_qas[index]['id']\n",
        "    context = valid_qas[index]['context']\n",
        "    question = valid_qas[index]['question']\n",
        "\n",
        "    answers = []\n",
        "    for qa in valid_qas:\n",
        "        if id == qa['id']:\n",
        "            answers.append(qa['answer'])\n",
        "\n",
        "    prediction, proba = inference(model=drqa, context=context, question=question,\n",
        "                                  text_vocab=TEXT, pos_vocab=POS, ner_vocab=NER, device=DEVICE)\n",
        "    \n",
        "    html = f'<p><span><b>Context:</b> {context.text}</span><br />'\n",
        "    html += f'<span><b>Question:</b> {question.text}</span><br />'\n",
        "    html += f'<span style=\"color:blue\"><b>Answers:</b><br /><ul>'\n",
        "    for answer in answers:\n",
        "        html += f'<li style=\"color:blue\">{answer.text}</li>'\n",
        "    html += '</ul></span><br />'\n",
        "    html += f'<span style=\"color:green\"><b>Prediction:</b> {prediction}</span><br />'\n",
        "    html += f'<span style=\"color:green\"><b>Probability:</b> {proba * 100:.3f}%</span><br />'\n",
        "    display(HTML(html))\n",
        "    print('='*100)"
      ],
      "execution_count": 334,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span><b>Context:</b> Sociologist Jake Rosenfield of the University of Washington asserts that the decline of organized labor in the United States has played a more significant role in expanding the income gap than technological changes and globalization, which were also experienced by other industrialized nations that didn't experience steep surges in inequality. He points out that nations with high rates of unionization, particularly in Scandinavia, have very low levels of inequality, and concludes \"the historical pattern is clear; the cross-national pattern is clear: high inequality goes hand-in-hand with weak labor movements and vice-versa.\"</span><br /><span><b>Question:</b> What has had a negative impact on the labor markets in the US?</span><br /><span style=\"color:blue\"><b>Answers:</b><br /><ul><li style=\"color:blue\">decline of organized labor</li><li style=\"color:blue\">decline of organized labor</li><li style=\"color:blue\">decline of organized labor</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> a more significant role</span><br /><span style=\"color:green\"><b>Probability:</b> 7.157%</span><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span><b>Context:</b> In the 1930s, radio in the United States was dominated by three companies: the Columbia Broadcasting System (CBS), the Mutual Broadcasting System and the National Broadcasting Company (NBC). The last was owned by electronics manufacturer Radio Corporation of America (RCA), which owned two radio networks that each ran different varieties of programming, NBC Blue and NBC Red. The NBC Blue Network was created in 1927 for the primary purpose of testing new programs on markets of lesser importance than those served by NBC Red, which served the major cities, and to test drama series.</span><br /><span><b>Question:</b> What two radio networks did RCA own?</span><br /><span style=\"color:blue\"><b>Answers:</b><br /><ul><li style=\"color:blue\">NBC Blue and NBC Red</li><li style=\"color:blue\">NBC Blue and NBC Red</li><li style=\"color:blue\">NBC Blue and NBC Red</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> varieties of programming, NBC Blue and NBC Red</span><br /><span style=\"color:green\"><b>Probability:</b> 14.868%</span><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span><b>Context:</b> In Europe, the North American theater of the Seven Years' War usually is not given a separate name. The entire international conflict is known as the Seven Years' War. \"Seven Years\" refers to events in Europe, from the official declaration of war in 1756 to the signing of the peace treaty in 1763. These dates do not correspond with the fighting on mainland North America, where the fighting between the two colonial powers was largely concluded in six years, from the Battle of Jumonville Glen in 1754 to the capture of Montreal in 1760.</span><br /><span><b>Question:</b> What time framd does the Seven Years War cover?</span><br /><span style=\"color:blue\"><b>Answers:</b><br /><ul><li style=\"color:blue\">declaration of war in 1756 to the signing of the peace treaty in 1763</li><li style=\"color:blue\">1756 to the signing of the peace treaty in 1763</li><li style=\"color:blue\">1756 to the signing of the peace treaty in 1763</li><li style=\"color:blue\">1756 to the signing of the peace treaty in 1763</li><li style=\"color:blue\">the official declaration of war in 1756 to the signing of the peace treaty in 1763</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> international conflict</span><br /><span style=\"color:green\"><b>Probability:</b> 10.799%</span><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span><b>Context:</b> The Rhine was not known to Herodotus and first enters the historical period in the 1st century BC in Roman-era geography. At that time, it formed the boundary between Gaul and Germania. The Upper Rhine had been part of the areal of the late Hallstatt culture since the 6th century BC, and by the 1st century BC, the areal of the La Tène culture covered almost its entire length, forming a contact zone with the Jastorf culture, i.e. the locus of early Celtic-Germanic cultural contact. In Roman geography, the Rhine formed the boundary between Gallia and Germania by definition; e.g. Maurus Servius Honoratus, Commentary on the Aeneid of Vergil (8.727) (Rhenus) fluvius Galliae, qui Germanos a Gallia dividit \"(The Rhine is a) river of Gaul, which divides the Germanic people from Gaul.\"</span><br /><span><b>Question:</b> Who first wrote about the Rhine's discovery and border?</span><br /><span style=\"color:blue\"><b>Answers:</b><br /><ul><li style=\"color:blue\">Maurus Servius Honoratus</li><li style=\"color:blue\">Maurus Servius Honoratus</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> Rhine</span><br /><span style=\"color:green\"><b>Probability:</b> 3.995%</span><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span><b>Context:</b> In the 1530s and 1540s, printed images of Luther that emphasized his monumental size were crucial to the spread of Protestantism. In contrast to images of frail Catholic saints, Luther was presented as a stout man with a \"double chin, strong mouth, piercing deep-set eyes, fleshy face, and squat neck.\" He was shown to be physically imposing, an equal in stature to the secular German princes with whom he would join forces to spread Lutheranism. His large body also let the viewer know that he did not shun earthly pleasures like drinking—behavior that was a stark contrast to the ascetic life of the medieval religious orders. Famous images from this period include the woodcuts by Hans Brosamer (1530) and Lucas Cranach the Elder and Lucas Cranach the Younger (1546).</span><br /><span><b>Question:</b> In contrast how were Catholic saints portrayed?</span><br /><span style=\"color:blue\"><b>Answers:</b><br /><ul><li style=\"color:blue\">frail Catholic saints</li><li style=\"color:blue\">frail</li><li style=\"color:blue\">frail</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> frail Catholic</span><br /><span style=\"color:green\"><b>Probability:</b> 6.758%</span><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span><b>Context:</b> But bounding the computation time above by some concrete function f(n) often yields complexity classes that depend on the chosen machine model. For instance, the language {xx | x is any binary string} can be solved in linear time on a multi-tape Turing machine, but necessarily requires quadratic time in the model of single-tape Turing machines. If we allow polynomial variations in running time, Cobham-Edmonds thesis states that \"the time complexities in any two reasonable and general models of computation are polynomially related\" (Goldreich 2008, Chapter 1.2). This forms the basis for the complexity class P, which is the set of decision problems solvable by a deterministic Turing machine within polynomial time. The corresponding set of function problems is FP.</span><br /><span><b>Question:</b> A multi-tape Turing machine requires what type of time for a solution?</span><br /><span style=\"color:blue\"><b>Answers:</b><br /><ul><li style=\"color:blue\">linear time</li><li style=\"color:blue\">linear</li><li style=\"color:blue\">linear</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> quadratic</span><br /><span style=\"color:green\"><b>Probability:</b> 37.375%</span><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span><b>Context:</b> On October 6, 1973, Syria and Egypt, with support from other Arab nations, launched a surprise attack on Israel, on Yom Kippur. This renewal of hostilities in the Arab–Israeli conflict released the underlying economic pressure on oil prices. At the time, Iran was the world's second-largest oil exporter and a close US ally. Weeks later, the Shah of Iran said in an interview: \"Of course [the price of oil] is going to rise... Certainly! And how!... You've [Western nations] increased the price of the wheat you sell us by 300 percent, and the same for sugar and cement... You buy our crude oil and sell it back to us, refined as petrochemicals, at a hundred times the price you've paid us... It's only fair that, from now on, you should pay more for oil. Let's say ten times more.\"</span><br /><span><b>Question:</b> When did Syria and Egypt launch a surprise attack on Israel?</span><br /><span style=\"color:blue\"><b>Answers:</b><br /><ul><li style=\"color:blue\">On October 6, 1973</li><li style=\"color:blue\">October 6, 1973</li><li style=\"color:blue\">October 6, 1973</li><li style=\"color:blue\">October 6, 1973</li><li style=\"color:blue\">October 6, 1973</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> Yom Kippur</span><br /><span style=\"color:green\"><b>Probability:</b> 43.345%</span><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span><b>Context:</b> When the Committee for Non-Violent Action sponsored a protest in August 1957, at the Camp Mercury nuclear test site near Las Vegas, Nevada, 13 of the protesters attempted to enter the test site knowing that they faced arrest. At a pre-arranged announced time, one at a time they stepped across the \"line\" and were immediately arrested. They were put on a bus and taken to the Nye County seat of Tonopah, Nevada, and arraigned for trial before the local Justice of the Peace, that afternoon. A well known civil rights attorney, Francis Heisler, had volunteered to defend the arrested persons, advising them to plead \"nolo contendere\", as an alternative to pleading either guilty or not-guilty. The arrested persons were found \"guilty,\" nevertheless, and given suspended sentences, conditional on their not reentering the test site grounds.[citation needed]</span><br /><span><b>Question:</b> What was the result of the disobedience protesting the nuclear site?</span><br /><span style=\"color:blue\"><b>Answers:</b><br /><ul><li style=\"color:blue\">arrested</li><li style=\"color:blue\">arrest</li><li style=\"color:blue\">were immediately arrested</li><li style=\"color:blue\">one at a time they stepped across the \"line\" and were immediately arrested</li><li style=\"color:blue\">put on a bus and taken to the Nye County seat of Tonopah, Nevada, and arraigned for trial before the local Justice of the Peace</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> they faced arrest</span><br /><span style=\"color:green\"><b>Probability:</b> 15.469%</span><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span><b>Context:</b> Perhaps the most significant difference between primary school and secondary school teaching is the relationship between teachers and children. In primary schools each class has a teacher who stays with them for most of the week and will teach them the whole curriculum. In secondary schools they will be taught by different subject specialists each session during the week and may have ten or more different teachers. The relationship between children and their teachers tends to be closer in the primary school where they act as form tutor, specialist teacher and surrogate parent during the course of the day.</span><br /><span><b>Question:</b> What does a teacher teach in primary school?</span><br /><span style=\"color:blue\"><b>Answers:</b><br /><ul><li style=\"color:blue\">the whole curriculum</li><li style=\"color:blue\">whole curriculum</li><li style=\"color:blue\">whole curriculum</li><li style=\"color:blue\">the whole curriculum</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> class has a teacher who stays with them for most of the week and will teach them the whole curriculum</span><br /><span style=\"color:green\"><b>Probability:</b> 3.132%</span><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span><b>Context:</b> The service started on 1 September 1993 based on the idea from the then chief executive officer, Sam Chisholm and Rupert Murdoch, of converting the company business strategy to an entirely fee-based concept. The new package included four channels formerly available free-to-air, broadcasting on Astra's satellites, as well as introducing new channels. The service continued until the closure of BSkyB's analogue service on 27 September 2001, due to the launch and expansion of the Sky Digital platform. Some of the channels did broadcast either in the clear or soft encrypted (whereby a Videocrypt decoder was required to decode, without a subscription card) prior to their addition to the Sky Multichannels package. Within two months of the launch, BSkyB gained 400,000 new subscribers, with the majority taking at least one premium channel as well, which helped BSkyB reach 3.5 million households by mid-1994. Michael Grade criticized the operations in front of the Select Committee on National Heritage, mainly for the lack of original programming on many of the new channels.</span><br /><span><b>Question:</b> Who was the chief executive officer when the service began?</span><br /><span style=\"color:blue\"><b>Answers:</b><br /><ul><li style=\"color:blue\">Sam Chisholm</li><li style=\"color:blue\">Sam Chisholm</li><li style=\"color:blue\">Sam Chisholm and Rupert Murdoch</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> Sam Chisholm</span><br /><span style=\"color:green\"><b>Probability:</b> 23.854%</span><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span><b>Context:</b> Southern California consists of a heavily developed urban environment, home to some of the largest urban areas in the state, along with vast areas that have been left undeveloped. It is the third most populated megalopolis in the United States, after the Great Lakes Megalopolis and the Northeastern megalopolis. Much of southern California is famous for its large, spread-out, suburban communities and use of automobiles and highways. The dominant areas are Los Angeles, Orange County, San Diego, and Riverside-San Bernardino, each of which is the center of its respective metropolitan area, composed of numerous smaller cities and communities. The urban area is also host to an international metropolitan region in the form of San Diego–Tijuana, created by the urban area spilling over into Baja California.</span><br /><span><b>Question:</b> Where does southern California's megalopolis standard in terms of population nationwide?</span><br /><span style=\"color:blue\"><b>Answers:</b><br /><ul><li style=\"color:blue\">third</li><li style=\"color:blue\">third</li><li style=\"color:blue\">third</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> automobiles and highways</span><br /><span style=\"color:green\"><b>Probability:</b> 3.980%</span><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span><b>Context:</b> Not all cells in a multicellular plant contain chloroplasts. All green parts of a plant contain chloroplasts—the chloroplasts, or more specifically, the chlorophyll in them are what make the photosynthetic parts of a plant green. The plant cells which contain chloroplasts are usually parenchyma cells, though chloroplasts can also be found in collenchyma tissue. A plant cell which contains chloroplasts is known as a chlorenchyma cell. A typical chlorenchyma cell of a land plant contains about 10 to 100 chloroplasts.</span><br /><span><b>Question:</b> What plant cells have chloroplasts in them?</span><br /><span style=\"color:blue\"><b>Answers:</b><br /><ul><li style=\"color:blue\">parenchyma cells</li><li style=\"color:blue\">photosynthetic</li><li style=\"color:blue\">parenchyma cells</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> parenchyma</span><br /><span style=\"color:green\"><b>Probability:</b> 11.670%</span><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span><b>Context:</b> The early United States expressed its opposition to Imperialism, at least in a form distinct from its own Manifest Destiny, through policies such as the Monroe Doctrine. However, beginning in the late 19th and early 20th century, policies such as Theodore Roosevelt’s interventionism in Central America and Woodrow Wilson’s mission to \"make the world safe for democracy\" changed all this. They were often backed by military force, but were more often affected from behind the scenes. This is consistent with the general notion of hegemony and imperium of historical empires. In 1898, Americans who opposed imperialism created the Anti-Imperialist League to oppose the US annexation of the Philippines and Cuba. One year later, a war erupted in the Philippines causing business, labor and government leaders in the US to condemn America's occupation in the Philippines as they also denounced them for causing the deaths of many Filipinos. American foreign policy was denounced as a \"racket\" by Smedley Butler, an American general. He said, \"Looking back on it, I might have given Al Capone a few hints. The best he could do was to operate his racket in three districts. I operated on three continents\".</span><br /><span><b>Question:</b> What did Smedley Butler call US foreign Policy?</span><br /><span style=\"color:blue\"><b>Answers:</b><br /><ul><li style=\"color:blue\">a \"racket\"</li><li style=\"color:blue\">racket</li><li style=\"color:blue\">racket</li><li style=\"color:blue\">a \"racket\"</li><li style=\"color:blue\">racket</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> racket</span><br /><span style=\"color:green\"><b>Probability:</b> 62.818%</span><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span><b>Context:</b> On September 3, 1958, the Disneyland anthology series was retitled Walt Disney Presents as it became disassociated with the theme park of the same name. The movement in westerns, which ABC is credited for having started, represented a fifth of all primetime series on American television in January 1959, at which point detective shows were beginning to rise in popularity as well. ABC requested additional productions from Disney. In late 1958, Desilu Productions pitched its detective series The Untouchables to CBS; after that network rejected the show because of its use of violence, Desilu then presented it to ABC, which agreed to pick up the show, and debuted The Untouchables in April 1959. The series went on to quickly become \"immensely popular\".</span><br /><span><b>Question:</b> What was the Disneyland anthology series retitled in 1958?</span><br /><span style=\"color:blue\"><b>Answers:</b><br /><ul><li style=\"color:blue\">Walt Disney Presents</li><li style=\"color:blue\">Walt Disney Presents</li><li style=\"color:blue\">Walt Disney Presents</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> retitled Walt Disney Presents</span><br /><span style=\"color:green\"><b>Probability:</b> 27.446%</span><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span><b>Context:</b> Newton's Second Law asserts the direct proportionality of acceleration to force and the inverse proportionality of acceleration to mass. Accelerations can be defined through kinematic measurements. However, while kinematics are well-described through reference frame analysis in advanced physics, there are still deep questions that remain as to what is the proper definition of mass. General relativity offers an equivalence between space-time and mass, but lacking a coherent theory of quantum gravity, it is unclear as to how or whether this connection is relevant on microscales. With some justification, Newton's second law can be taken as a quantitative definition of mass by writing the law as an equality; the relative units of force and mass then are fixed.</span><br /><span><b>Question:</b> In Newton's second law, what are the units of mass and force in relation to microscales?</span><br /><span style=\"color:blue\"><b>Answers:</b><br /><ul><li style=\"color:blue\">fixed</li><li style=\"color:blue\">an equality</li><li style=\"color:blue\">fixed</li><li style=\"color:blue\">fixed</li><li style=\"color:blue\">unclear</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> fixed</span><br /><span style=\"color:green\"><b>Probability:</b> 58.532%</span><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span><b>Context:</b> Islamist movements such as the Muslim Brotherhood, \"are well known for providing shelters, educational assistance, free or low cost medical clinics, housing assistance to students from out of town, student advisory groups, facilitation of inexpensive mass marriage ceremonies to avoid prohibitively costly dowry demands, legal assistance, sports facilities, and women's groups.\" All this compares very favourably against incompetent, inefficient, or neglectful governments whose commitment to social justice is limited to rhetoric.</span><br /><span><b>Question:</b> What type of movement is the Muslim Brotherhood?</span><br /><span style=\"color:blue\"><b>Answers:</b><br /><ul><li style=\"color:blue\">Islamist</li><li style=\"color:blue\">Islamist</li><li style=\"color:blue\">Islamist</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> Islamist</span><br /><span style=\"color:green\"><b>Probability:</b> 7.557%</span><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span><b>Context:</b> Warsaw lies in east-central Poland about 300 km (190 mi) from the Carpathian Mountains and about 260 km (160 mi) from the Baltic Sea, 523 km (325 mi) east of Berlin, Germany. The city straddles the Vistula River. It is located in the heartland of the Masovian Plain, and its average elevation is 100 metres (330 ft) above sea level. The highest point on the left side of the city lies at a height of 115.7 metres (379.6 ft) (\"Redutowa\" bus depot, district of Wola), on the right side – 122.1 metres (400.6 ft) (\"Groszówka\" estate, district of Wesoła, by the eastern border). The lowest point lies at a height 75.6 metres (248.0 ft) (at the right bank of the Vistula, by the eastern border of Warsaw). There are some hills (mostly artificial) located within the confines of the city – e.g. Warsaw Uprising Hill (121 metres (397.0 ft)), Szczęśliwice hill (138 metres (452.8 ft) – the highest point of Warsaw in general).</span><br /><span><b>Question:</b> Where is the lowest point of Warsaw located?</span><br /><span style=\"color:blue\"><b>Answers:</b><br /><ul><li style=\"color:blue\">at the right bank of the Vistula</li><li style=\"color:blue\">at the right bank of the Vistula, by the eastern border of Warsaw</li><li style=\"color:blue\">by the eastern border</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> a height 75.6 metres (248.0 ft) (at the right bank of the Vistula</span><br /><span style=\"color:green\"><b>Probability:</b> 8.007%</span><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span><b>Context:</b> Ludwig Krapf recorded the name as both Kenia and Kegnia believed by most to be a corruption of the Kamba version. Others say that this was—on the contrary—a very precise notation of a correct African pronunciation /ˈkɛnjə/. An 1882 map drawn by Joseph Thompsons, a Scottish geologist and naturalist, indicated Mt. Kenya as Mt. Kenia, 1862. Controversy over the actual meaning of the word Kenya notwithstanding, it is clear that the mountain's name became widely accepted, pars pro toto, as the name of the country.</span><br /><span><b>Question:</b> What do some believe about this pronunciation?</span><br /><span style=\"color:blue\"><b>Answers:</b><br /><ul><li style=\"color:blue\">a very precise notation of a correct African pronunciation</li><li style=\"color:blue\">precise</li><li style=\"color:blue\">precise</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> An 1882 map</span><br /><span style=\"color:green\"><b>Probability:</b> 0.981%</span><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span><b>Context:</b> As interesting examples of expositions the most notable are: the world's first Museum of Posters boasting one of the largest collections of art posters in the world, Museum of Hunting and Riding and the Railway Museum. From among Warsaw's 60 museums, the most prestigious ones are National Museum with a collection of works whose origin ranges in time from antiquity till the present epoch as well as one of the best collections of paintings in the country including some paintings from Adolf Hitler's private collection, and Museum of the Polish Army whose set portrays the history of arms.</span><br /><span><b>Question:</b> How many museums are in Warsaw?</span><br /><span style=\"color:blue\"><b>Answers:</b><br /><ul><li style=\"color:blue\">60</li><li style=\"color:blue\">60</li><li style=\"color:blue\">60</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> 60</span><br /><span style=\"color:green\"><b>Probability:</b> 85.434%</span><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span><b>Context:</b> Sculptors both British and Europeans who were based in Britain and whose work is in the collection include Nicholas Stone, Caius Gabriel Cibber, Grinling Gibbons, John Michael Rysbrack, Louis-François Roubiliac, Peter Scheemakers, Sir Henry Cheere, Agostino Carlini, Thomas Banks, Joseph Nollekens, Joseph Wilton, John Flaxman, Sir Francis Chantrey, John Gibson, Edward Hodges Baily, Lord Leighton, Alfred Stevens, Thomas Brock, Alfred Gilbert, George Frampton, and Eric Gill. A sample of some of these sculptors' work is on display in the British Galleries.</span><br /><span><b>Question:</b> Which British sculptor whose work include the Queen Victoria memorial in front of Buckingham Palace is included in the V&A collection?</span><br /><span style=\"color:blue\"><b>Answers:</b><br /><ul><li style=\"color:blue\">Thomas Brock</li><li style=\"color:blue\">Thomas Brock</li><li style=\"color:blue\">Thomas Brock</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> Nicholas Stone</span><br /><span style=\"color:green\"><b>Probability:</b> 4.196%</span><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span><b>Context:</b> One of the first Norman mercenaries to serve as a Byzantine general was Hervé in the 1050s. By then however, there were already Norman mercenaries serving as far away as Trebizond and Georgia. They were based at Malatya and Edessa, under the Byzantine duke of Antioch, Isaac Komnenos. In the 1060s, Robert Crispin led the Normans of Edessa against the Turks. Roussel de Bailleul even tried to carve out an independent state in Asia Minor with support from the local population, but he was stopped by the Byzantine general Alexius Komnenos.</span><br /><span><b>Question:</b> When did Robert Crispin go up against the Turks?</span><br /><span style=\"color:blue\"><b>Answers:</b><br /><ul><li style=\"color:blue\">1060s</li><li style=\"color:blue\">In the 1060s</li><li style=\"color:blue\">In the 1060s</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> Edessa</span><br /><span style=\"color:green\"><b>Probability:</b> 29.392%</span><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span><b>Context:</b> Courts have distinguished between two types of civil disobedience: \"Indirect civil disobedience involves violating a law which is not, itself, the object of protest, whereas direct civil disobedience involves protesting the existence of a particular law by breaking that law.\" During the Vietnam War, courts typically refused to excuse the perpetrators of illegal protests from punishment on the basis of their challenging the legality of the Vietnam War; the courts ruled it was a political question. The necessity defense has sometimes been used as a shadow defense by civil disobedients to deny guilt without denouncing their politically motivated acts, and to present their political beliefs in the courtroom. However, court cases such as U.S. v. Schoon have greatly curtailed the availability of the political necessity defense. Likewise, when Carter Wentworth was charged for his role in the Clamshell Alliance's 1977 illegal occupation of the Seabrook Station Nuclear Power Plant, the judge instructed the jury to disregard his competing harms defense, and he was found guilty. Fully Informed Jury Association activists have sometimes handed out educational leaflets inside courthouses despite admonitions not to; according to FIJA, many of them have escaped prosecution because \"prosecutors have reasoned (correctly) that if they arrest fully informed jury leafleters, the leaflets will have to be given to the leafleter's own jury as evidence.\"</span><br /><span><b>Question:</b> Why are people who distribute leaflets inside courthouses not been arrested?</span><br /><span style=\"color:blue\"><b>Answers:</b><br /><ul><li style=\"color:blue\">the leaflets will have to be given to the leafleter's own jury as evidence</li><li style=\"color:blue\">if they arrest fully informed jury leafleters, the leaflets will have to be given to the leafleter's own jury as evidence</li><li style=\"color:blue\">the leaflets will have to be given to the leafleter's own jury as evidence</li><li style=\"color:blue\">the leaflets will have to be given to the leafleter's own jury as evidence</li><li style=\"color:blue\">the leaflets will have to be given to the leafleter's own jury as evidence</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> according to FIJA, many of them have escaped prosecution because \"prosecutors have reasoned (correctly) that if they arrest fully informed jury leafleters, the leaflets will have to be given to the leafleter's own jury as evidence</span><br /><span style=\"color:green\"><b>Probability:</b> 3.031%</span><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span><b>Context:</b> The shape of the Rhine delta is determined by two bifurcations: first, at Millingen aan de Rijn, the Rhine splits into Waal and Pannerdens Kanaal, which changes its name to Nederrijn at Angeren, and second near Arnhem, the IJssel branches off from the Nederrijn. This creates three main flows, two of which change names rather often. The largest and southern main branch begins as Waal and continues as Boven Merwede (\"Upper Merwede\"), Beneden Merwede (\"Lower Merwede\"), Noord River (\"North River\"), Nieuwe Maas (\"New Meuse\"), Het Scheur (\"the Rip\") and Nieuwe Waterweg (\"New Waterway\"). The middle flow begins as Nederrijn, then changes into Lek, then joins the Noord, thereby forming Nieuwe Maas. The northern flow keeps the name IJssel until it flows into Lake IJsselmeer. Three more flows carry significant amounts of water: the Nieuwe Merwede (\"New Merwede\"), which branches off from the southern branch where it changes from Boven to Beneden Merwede; the Oude Maas (\"Old Meuse\"), which branches off from the southern branch where it changes from Beneden Merwede into Noord, and Dordtse Kil, which branches off from Oude Maas.</span><br /><span><b>Question:</b> What is the English translation of Het Scheur?</span><br /><span style=\"color:blue\"><b>Answers:</b><br /><ul><li style=\"color:blue\">the Rip</li><li style=\"color:blue\">the Rip</li><li style=\"color:blue\">the Rip</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> Rip</span><br /><span style=\"color:green\"><b>Probability:</b> 48.186%</span><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span><b>Context:</b> Since the 2005 revival, the Doctor generally travels with a primary female companion, who occupies a larger narrative role. Steven Moffat described the companion as the main character of the show, as the story begins anew with each companion and she undergoes more change than the Doctor. The primary companions of the Ninth and Tenth Doctors were Rose Tyler (Billie Piper), Martha Jones (Freema Agyeman), and Donna Noble (Catherine Tate) with Mickey Smith (Noel Clarke) and Jack Harkness (John Barrowman) recurring as secondary companion figures. The Eleventh Doctor became the first to travel with a married couple, Amy Pond (Karen Gillan) and Rory Williams (Arthur Darvill), whilst out-of-sync meetings with River Song (Alex Kingston) and Clara Oswald (Jenna Coleman) provided ongoing story arcs. The tenth series will introduce Pearl Mackie as Bill, the Doctor's newest traveling companion.</span><br /><span><b>Question:</b> Since 2005, what is the gender of Doctor Who's primary traveling companion?</span><br /><span style=\"color:blue\"><b>Answers:</b><br /><ul><li style=\"color:blue\">female</li><li style=\"color:blue\">female</li><li style=\"color:blue\">female</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> Steven Moffat</span><br /><span style=\"color:green\"><b>Probability:</b> 6.442%</span><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span><b>Context:</b> As opposed to broadcasts of primetime series, CBS broadcast special episodes of its late night talk shows as its lead-out programs for Super Bowl 50, beginning with a special episode of The Late Show with Stephen Colbert following the game. Following a break for late local programming, CBS also aired a special episode of The Late Late Show with James Corden.</span><br /><span><b>Question:</b> What show aired on CBS after late local programming?</span><br /><span style=\"color:blue\"><b>Answers:</b><br /><ul><li style=\"color:blue\">The Late Late Show with James Corden</li><li style=\"color:blue\">The Late Late Show with James Corden</li><li style=\"color:blue\">Late Late Show with James Corden</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> Following a break</span><br /><span style=\"color:green\"><b>Probability:</b> 6.661%</span><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jXLsXBe_kJD",
        "outputId": "e2299fe2-a5db-4cf8-a262-c8e9861a6aee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        ""
      ],
      "execution_count": 289,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('', [89.63230895996094])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 289
        }
      ]
    }
  ]
}