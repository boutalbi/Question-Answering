{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1 - DrQA, Document reader Question Answering.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM3vTG7kr279RUmGrO4xseo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dksifoua/Question-Answering/blob/master/1%20-%20DrQA%2C%20Document%20reader%20Question%20Answering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMGpLvYNKR78",
        "outputId": "11833491-53a3-494d-ec4f-3388b07b6751",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Nov  1 00:16:14 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.32.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   30C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lP-9tyjdylTg"
      },
      "source": [
        "## Load dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bm6QVw_hzHB7"
      },
      "source": [
        "!pip install tqdm --upgrade >> /dev/null 2>&1\n",
        "!pip install spacy --upgrade >> /dev/null 2>&1\n",
        "!python -m spacy download en >> /dev/null 2>&1"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJQv4DSelwnB"
      },
      "source": [
        "import re\n",
        "import json\n",
        "import time\n",
        "import tqdm\n",
        "import spacy\n",
        "import string\n",
        "import collections\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_sequence, pad_packed_sequence\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 317,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cw16-fZCDHHu",
        "outputId": "9064526b-34a7-4ba0-aae0-fab56468b390",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "SEED = 546\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Device: {DEVICE}')"
      ],
      "execution_count": 318,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xx9pL3Hiyn7c"
      },
      "source": [
        "## Prepare data\n",
        "\n",
        "***Download data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBy3v4Pke7dq",
        "outputId": "4016d958-c705-48e6-e37a-11a86700476d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!rm -rf ./data\n",
        "!mkdir ./data\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json \\\n",
        "    -O ./data/train-v1.1.json\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json \\\n",
        "    -O ./data/dev-v1.1.json"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-01 00:18:50--  https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json\n",
            "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n",
            "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.108.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 30288272 (29M) [application/json]\n",
            "Saving to: ‘./data/train-v1.1.json’\n",
            "\n",
            "./data/train-v1.1.j 100%[===================>]  28.88M  73.3MB/s    in 0.4s    \n",
            "\n",
            "2020-11-01 00:18:52 (73.3 MB/s) - ‘./data/train-v1.1.json’ saved [30288272/30288272]\n",
            "\n",
            "--2020-11-01 00:18:52--  https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json\n",
            "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n",
            "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.108.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4854279 (4.6M) [application/json]\n",
            "Saving to: ‘./data/dev-v1.1.json’\n",
            "\n",
            "./data/dev-v1.1.jso 100%[===================>]   4.63M  20.5MB/s    in 0.2s    \n",
            "\n",
            "2020-11-01 00:18:53 (20.5 MB/s) - ‘./data/dev-v1.1.json’ saved [4854279/4854279]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9H59xUnyvAR"
      },
      "source": [
        "***Load JSON data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbZQjhA5roqo"
      },
      "source": [
        "def load(path):\n",
        "    with open(path, mode='r', encoding='utf-8') as file:\n",
        "        return json.load(file)['data']\n",
        "    raise FileNotFoundError"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqjrkTxHr3rA",
        "outputId": "22ef1aab-1489-4cfe-a6c3-8e55b943c1e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_raw_data = load('./data/train-v1.1.json')\n",
        "valid_raw_data = load('./data/dev-v1.1.json')\n",
        "print(f'Length of raw train data: {len(train_raw_data):,}')\n",
        "print(f'Length of raw valid data: {len(valid_raw_data):,}')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of raw train data: 442\n",
            "Length of raw valid data: 48\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4sypWlVyxx-"
      },
      "source": [
        "***Parse JSON data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-6GE3YxsQsl"
      },
      "source": [
        "def parse(data, nlp=spacy.load('en')):\n",
        "    qas = []\n",
        "    for paragraphs in tqdm.tqdm(data):\n",
        "        for para in paragraphs['paragraphs']:\n",
        "            context = nlp(para['context'], disable=['parser'])\n",
        "            for qa in para['qas']:\n",
        "                id = qa['id']\n",
        "                question = nlp(qa['question'], disable=['parser', 'tagger', 'ner'])\n",
        "                for ans in qa['answers']:\n",
        "                    qas.append({\n",
        "                        'id': id,\n",
        "                        'context': context,\n",
        "                        'question': question,\n",
        "                        'answer': nlp(ans['text'], disable=['parser', 'tagger', 'ner']),\n",
        "                        'answer_start': ans['answer_start'],\n",
        "                    })\n",
        "    return qas"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MeqBr7Ov9ZU",
        "outputId": "6c6c28ef-ea15-42f4-8198-b70e15f10954",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_qas = parse(train_raw_data)\n",
        "valid_qas = parse(valid_raw_data)\n",
        "print()\n",
        "print(f'Length of train qa pairs: {len(train_qas):,}')\n",
        "print(f'Length of valid qa pairs: {len(valid_qas):,}')\n",
        "print('==================== Example ====================')\n",
        "print('Id:', train_qas[0]['id'])\n",
        "print('Context:', train_qas[0]['context'])\n",
        "print('Question:', train_qas[0]['question'])\n",
        "print('Answer starts at:', train_qas[0]['answer_start'])\n",
        "print('Answer:', train_qas[0]['answer'])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 442/442 [04:53<00:00,  1.51it/s]\n",
            "100%|██████████| 48/48 [00:34<00:00,  1.41it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Length of train qa pairs: 87,599\n",
            "Length of valid qa pairs: 34,726\n",
            "==================== Example ====================\n",
            "Id: 5733be284776f41900661182\n",
            "Context: Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\n",
            "Question: To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?\n",
            "Answer starts at: 515\n",
            "Answer: Saint Bernadette Soubirous\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bafKgiFv1GHa"
      },
      "source": [
        "def test_answer_start(qas):\n",
        "    \"\"\"Test answer_start are correct in train set\"\"\"\n",
        "    for qa in tqdm.tqdm(qas):\n",
        "        answer = qa['answer'].text\n",
        "        context = qa['context'].text\n",
        "        answer_start = qa['answer_start']\n",
        "        assert answer == context[answer_start:answer_start + len(answer)]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tTDTQod23-g",
        "outputId": "14edc2f3-3969-4e54-bd18-af6554ae2d2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_answer_start(train_qas)\n",
        "test_answer_start(valid_qas)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 87599/87599 [00:08<00:00, 10567.86it/s]\n",
            "100%|██████████| 34726/34726 [00:03<00:00, 11420.74it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxhCfiNY28zs"
      },
      "source": [
        "***Add targets***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4bpqV3S27SQ"
      },
      "source": [
        "def add_targets(qas):\n",
        "    \"\"\"Add start and end index token\"\"\"\n",
        "    for qa in qas:\n",
        "        context = qa['context']\n",
        "        answer = qa['answer']\n",
        "        ans_start = qa['answer_start']\n",
        "        for i in range(len(context)):\n",
        "            if context[i].idx == ans_start:\n",
        "                ans = context[i:i + len(answer)]\n",
        "                qa['target'] = [ans[0].i, ans[-1].i]\n",
        "                break"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waJedA674CCH",
        "outputId": "76a61f04-1d7d-41d0-f7ea-91e4746686c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "add_targets(train_qas)\n",
        "add_targets(valid_qas)\n",
        "print(f'Length of train qa pairs: {len(train_qas):,}')\n",
        "print(f'Length of valid qa pairs: {len(valid_qas):,}')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of train qa pairs: 87,599\n",
            "Length of valid qa pairs: 34,726\n",
            "CPU times: user 1.52 s, sys: 16 ms, total: 1.53 s\n",
            "Wall time: 1.54 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT65eePm4F9w"
      },
      "source": [
        "def filter_qas(qa):\n",
        "    \"\"\"Remove bad targets\"\"\"\n",
        "    if 'target' in [*qa.keys()]:\n",
        "        start, end = qa['target']\n",
        "        return qa['context'][start:end + 1].text == qa['answer'].text\n",
        "    return False"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_nUlM_n4Mgc",
        "outputId": "0006ad2e-922e-473a-ebb3-eaa0ef9333f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "train_qas = [*filter(filter_qas, train_qas)]\n",
        "valid_qas = [*filter(filter_qas, valid_qas)]\n",
        "print(f'Length of train qa pairs after filtering out bad qa pairs: {len(train_qas):,}')\n",
        "print(f'Length of valid qa pairs after filtering out bad qa pairs: {len(valid_qas):,}')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of train qa pairs after filtering out bad qa pairs: 86,597\n",
            "Length of valid qa pairs after filtering out bad qa pairs: 34,295\n",
            "CPU times: user 1.15 s, sys: 4.99 ms, total: 1.16 s\n",
            "Wall time: 1.16 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKEhn4eI4P5B"
      },
      "source": [
        "def test_targets(qas):\n",
        "    for qa in qas:\n",
        "        if 'target' in [*qa.keys()]:\n",
        "            start, end = qa['target']\n",
        "            assert qa['context'][start:end + 1].text == qa['answer'].text"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O_fmDJl5R7V",
        "outputId": "f5543b24-3aa4-4a6f-95d2-ccf2cc08acff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "test_targets(train_qas)\n",
        "test_targets(valid_qas)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.12 s, sys: 980 µs, total: 1.12 s\n",
            "Wall time: 1.13 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkLppZOP5Vju"
      },
      "source": [
        "***Add features***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8Y038pt5VIc"
      },
      "source": [
        "def add_features(qas):\n",
        "    \"\"\"Add extra features: Exact Match, Part-of-Speech, Name Entity Recognition & Normalized Term Frequency\"\"\"\n",
        "    for qa in tqdm.tqdm(qas):\n",
        "        question = [token.text.lower() for token in qa['question']]\n",
        "        context = qa['context']\n",
        "        counts = collections.Counter(map(lambda token: token.text.lower(), context))\n",
        "        freqs = {index: counts[token.text.lower()] for index, token in enumerate(context)}\n",
        "        freqs_norm = sum(freqs.values())\n",
        "        qa['em'], qa['pos'], qa['ner'], qa['ntf'] = zip(\n",
        "            *map(lambda index: [\n",
        "                context[index].text.lower() in question, context[index].tag_,\n",
        "                context[index].ent_type_ or 'None',\n",
        "                freqs[index] / freqs_norm\n",
        "            ], range(len(context)))\n",
        "        )"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqwcbDgPSmp8",
        "outputId": "0987df46-749c-4d97-e4ed-acc1d8860582",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "add_features(train_qas)\n",
        "add_features(valid_qas)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 86597/86597 [00:51<00:00, 1668.80it/s]\n",
            "100%|██████████| 34295/34295 [00:21<00:00, 1624.91it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8SrKXlfoU5y"
      },
      "source": [
        "***Build vocabularies***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LYjZhu7m6YI"
      },
      "source": [
        "class Vocab:\n",
        "\n",
        "    def __init__(self, pad_token, unk_token):\n",
        "        self.pad_token = pad_token\n",
        "        self.unk_token = unk_token\n",
        "        self.vocab = None\n",
        "        self.word2count = None\n",
        "        self.word2index = None\n",
        "        self.index2word = None\n",
        "    \n",
        "    def build(self, data, min_freq):\n",
        "        \"\"\"\n",
        "        :param List[Union[spacy.tokens.doc.Doc, str, Tuple]] data\n",
        "        :param int min_freq\n",
        "        \"\"\"\n",
        "        words = [self.pad_token, self.unk_token]\n",
        "        type_0 = type(data[0])\n",
        "        if type_0 == spacy.tokens.doc.Doc:\n",
        "            for item in data: # context and question\n",
        "                words += [word.text.lower() for word in item]\n",
        "        elif type_0 == str: # id\n",
        "            words += data\n",
        "        elif type_0 == tuple: # pos and ner\n",
        "            for item in data:\n",
        "                words += [word.lower() for word in item]\n",
        "        self.word2count = collections.Counter(words)\n",
        "        self.vocab = sorted(filter(\n",
        "            lambda word: self.word2count[word] >= min_freq or word == self.pad_token or word == self.unk_token, self.word2count\n",
        "        ))\n",
        "        self.word2index = {word: index for index, word in enumerate(self.vocab)}\n",
        "        self.index2word = {index: word for index, word in enumerate(self.vocab)}\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.vocab)\n",
        "    \n",
        "    def stoi(self, word):\n",
        "        return self.word2index.get(str(word), self.word2index[self.unk_token])\n",
        "\n",
        "    def itos(self, index):\n",
        "        return self.index2word[index]"
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2RP28pUqYoQ",
        "outputId": "4d6da430-4e61-4139-8324-196c2be1aeb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "PAD_TOKEN = '<pad>'\n",
        "UNK_TOKEN = '<unk>'\n",
        "\n",
        "ID = Vocab(pad_token=PAD_TOKEN, unk_token=UNK_TOKEN)\n",
        "POS = Vocab(pad_token=PAD_TOKEN, unk_token=UNK_TOKEN)\n",
        "NER = Vocab(pad_token=PAD_TOKEN, unk_token=UNK_TOKEN)\n",
        "TEXT = Vocab(pad_token=PAD_TOKEN, unk_token=UNK_TOKEN)\n",
        "\n",
        "ids = [*map(lambda qa: qa['id'], train_qas)] + [*map(lambda qa: qa['id'], valid_qas)]\n",
        "pos, ner, contexts, questions = zip(*map(lambda qa: (qa['pos'], qa['ner'], qa['context'], qa['question']), train_qas))\n",
        "\n",
        "ID.build(data=[*set(ids)], min_freq=0)\n",
        "POS.build(data=[*set(pos)], min_freq=0)\n",
        "NER.build(data=[*set(ner)], min_freq=0)\n",
        "TEXT.build(data=[*set(contexts)] + [*set(questions)], min_freq=5)\n",
        "\n",
        "print(f'Length of ID vocabulary: {len(ID):,}')\n",
        "print(f'Length of POS vocabulary: {len(POS):,}')\n",
        "print(f'Length of NER vocabulary: {len(NER):,}')\n",
        "print(f'Length of TEXT vocabulary: {len(TEXT):,}')"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of ID vocabulary: 97,108\n",
            "Length of POS vocabulary: 52\n",
            "Length of NER vocabulary: 21\n",
            "Length of TEXT vocabulary: 26,885\n",
            "CPU times: user 5.61 s, sys: 12.6 ms, total: 5.63 s\n",
            "Wall time: 5.63 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t26xjG9OAikb"
      },
      "source": [
        "***Build datasets***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iotg02zlAflQ"
      },
      "source": [
        "class SQuADV1Dataset(Dataset):\n",
        "\n",
        "    def __init__(self, data, id_vocab, pos_vocab, ner_vocab, text_vocab):\n",
        "        self.data = data\n",
        "        self.id_vocab = id_vocab\n",
        "        self.pos_vocab = pos_vocab\n",
        "        self.ner_vocab = ner_vocab\n",
        "        self.text_vocab = text_vocab\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "        id = torch.LongTensor([self.id_vocab.stoi(item['id'])])\n",
        "        ctx = torch.LongTensor([*map(lambda token: self.text_vocab.stoi(token.text.lower()), item['context'])])\n",
        "        qst = torch.LongTensor([*map(lambda token: self.text_vocab.stoi(token.text.lower()), item['question'])])\n",
        "        trg = torch.LongTensor(item['target'])\n",
        "        em = torch.LongTensor(item['em'])\n",
        "        pos = torch.LongTensor([*map(lambda token: self.pos_vocab.stoi(token.lower()), item['pos'])])\n",
        "        ner = torch.LongTensor([*map(lambda token: self.ner_vocab.stoi(token.lower()), item['ner'])])\n",
        "        ntf = torch.FloatTensor(item['ntf'])\n",
        "        return id, ctx, qst, trg, em, pos, ner, ntf"
      ],
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMgSisEt8ARe",
        "outputId": "3abef599-760f-43ae-f70d-2a4c525c2de4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_dataset = SQuADV1Dataset(data=train_qas, id_vocab=ID, pos_vocab=POS, ner_vocab=NER, text_vocab=TEXT)\n",
        "valid_dataset = SQuADV1Dataset(data=valid_qas, id_vocab=ID, pos_vocab=POS, ner_vocab=NER, text_vocab=TEXT)\n",
        "\n",
        "id, ctx, qst, trg, em, pos, ner, ntf = train_dataset[0]\n",
        "print(f'id shape: {id.shape}')\n",
        "print(f'ctx shape: {ctx.shape}')\n",
        "print(f'qst shape: {qst.shape}')\n",
        "print(f'trg shape: {trg.shape}')\n",
        "print(f'em shape: {em.shape}')\n",
        "print(f'pos shape: {pos.shape}')\n",
        "print(f'ner shape: {ner.shape}')\n",
        "print(f'ntf shape: {ntf.shape}')"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "id shape: torch.Size([1])\n",
            "ctx shape: torch.Size([142])\n",
            "qst shape: torch.Size([14])\n",
            "trg shape: torch.Size([2])\n",
            "em shape: torch.Size([142])\n",
            "pos shape: torch.Size([142])\n",
            "ner shape: torch.Size([142])\n",
            "ntf shape: torch.Size([142])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZQaVaHt_MDc"
      },
      "source": [
        "***Build data loaders***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPKrJOpKTlN1"
      },
      "source": [
        "class DotDict(dict):\n",
        "    __getattr__ = dict.get"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYMYz3-SBYzf"
      },
      "source": [
        "def add_padding(batch, pad_token=PAD_TOKEN, text_vocab=TEXT, pos_vocab=POS, ner_vocab=NER, include_lengths=True, device=DEVICE):\n",
        "    \"\"\"Pad batch of sequence with different lengths\"\"\"\n",
        "    batch_id, batch_ctx, batch_qst, batch_trg, batch_em, batch_pos, batch_ner, batch_ntf = zip(*batch)\n",
        "    if include_lengths:\n",
        "        len_ctx = torch.LongTensor([ctx.size(0) for ctx in batch_ctx]).to(device)\n",
        "        len_qst = torch.LongTensor([qst.size(0) for qst in batch_qst]).to(device)\n",
        "    batch_padded_id = pad_sequence(batch_id, batch_first=True).to(device)\n",
        "    batch_padded_ctx = pad_sequence(batch_ctx, batch_first=True, padding_value=text_vocab.stoi(pad_token)).to(device)\n",
        "    batch_padded_qst = pad_sequence(batch_qst, batch_first=True, padding_value=text_vocab.stoi(pad_token)).to(device)\n",
        "    batch_padded_trg = pad_sequence(batch_trg, batch_first=True).to(device)\n",
        "    batch_padded_em = pad_sequence(batch_em, batch_first=True).to(device)\n",
        "    batch_padded_pos = pad_sequence(batch_pos, batch_first=True, padding_value=pos_vocab.stoi(pad_token)).to(device)\n",
        "    batch_padded_ner = pad_sequence(batch_ner, batch_first=True, padding_value=ner_vocab.stoi(pad_token)).to(device)\n",
        "    batch_padded_ntf = pad_sequence(batch_ntf, batch_first=True).to(device)\n",
        "    return DotDict({\n",
        "        'id': batch_padded_id,\n",
        "        'ctx': (batch_padded_ctx, len_ctx) if include_lengths else batch_padded_ctx,\n",
        "        'qst': (batch_padded_qst, len_qst) if include_lengths else batch_padded_qst,\n",
        "        'trg': batch_padded_trg,\n",
        "        'em': batch_padded_em,\n",
        "        'pos': batch_padded_pos,\n",
        "        'ner': batch_padded_ner,\n",
        "        'ntf': batch_padded_ntf,\n",
        "    })"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zu2ovPqxA7Ix",
        "outputId": "3f94c073-2df0-4d9d-f3ea-6b5f8560d60e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=add_padding)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, collate_fn=add_padding)\n",
        "\n",
        "for batch in train_dataloader:\n",
        "    print('batch.id shape:', batch.id.shape)\n",
        "    print('batch.ctx shape:', batch.ctx[0].shape, batch.ctx[1].shape)\n",
        "    print('batch.qst shape:', batch.qst[0].shape, batch.qst[1].shape)\n",
        "    print('batch.trg shape:', batch.trg.shape)\n",
        "    print('batch.em shape:', batch.em.shape)\n",
        "    print('batch.pos shape:', batch.pos.shape)\n",
        "    print('batch.ner shape:', batch.ner.shape)\n",
        "    print('batch.ntf shape:', batch.ntf.shape)\n",
        "    break"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch.id shape: torch.Size([64, 1])\n",
            "batch.ctx shape: torch.Size([64, 253]) torch.Size([64])\n",
            "batch.qst shape: torch.Size([64, 19]) torch.Size([64])\n",
            "batch.trg shape: torch.Size([64, 2])\n",
            "batch.em shape: torch.Size([64, 253])\n",
            "batch.pos shape: torch.Size([64, 253])\n",
            "batch.ner shape: torch.Size([64, 253])\n",
            "batch.ntf shape: torch.Size([64, 253])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2O79r_CLvGu"
      },
      "source": [
        "***TODO: Download pretrained GloVe embedding***\n",
        "\n",
        "It will take about 16 minutes to download from Colab!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxnYdks-L31E"
      },
      "source": [
        "## Modeling\n",
        "\n",
        "***Stacked Bidirectional LSTM Layer***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoHYvqQQCEGw"
      },
      "source": [
        "class StackedBiLSTMsLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_size, hidden_size, n_layers, dropout):\n",
        "        super(StackedBiLSTMsLayer, self).__init__()\n",
        "        self.embedding_size = embedding_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.lstms = nn.ModuleList([nn.LSTM(embedding_size if i == 0 else hidden_size * 2, hidden_size,\n",
        "                                            batch_first=True, num_layers=n_layers, bidirectional=True)\n",
        "                                    for i in range(n_layers)])\n",
        "    \n",
        "    def apply_lstm(self, layer, inputs, lengths):\n",
        "        \"\"\"\n",
        "        :param nn.LSTM layer\n",
        "        :param FloatTensor[batch_size, seq_len, embedding_size | hidden_size * 2] inputs\n",
        "        :param LongTensor[batch_size, seq_len] lengths\n",
        "        :return FloatTensor[batch_size, seq_len, hidden_size * 2] out_padded\n",
        "        \"\"\"\n",
        "        inputs = self.dropout(inputs)\n",
        "        packed = pack_padded_sequence(inputs, lengths, batch_first=True, enforce_sorted=False)\n",
        "        out_packed, _ = layer(packed)\n",
        "        out_padded, out_lengths = pad_packed_sequence(out_packed, batch_first=True) # [batch_size, seq_len, hidden_size * 2]\n",
        "        return out_padded, out_lengths\n",
        "    \n",
        "    def forward(self, input_embedded, sequence_lengths):\n",
        "        \"\"\"\n",
        "        :param FloatTensor[batch_size, seq_len, embedding_size] input_embedded\n",
        "        :param LongTensor[batch_size, seq_len] sequence_lengths\n",
        "        :return FloatTensor[batch_size, seq_len, hidden_size * n_layers * 2]\n",
        "        \"\"\"\n",
        "        outputs, lens = [input_embedded], sequence_lengths\n",
        "        for lstm in self.lstms:\n",
        "            out, lens = self.apply_lstm(layer=lstm, inputs=outputs[-1], lengths=lens)\n",
        "            outputs.append(out)\n",
        "        return self.dropout(torch.cat(outputs[1:], dim=-1))"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oazq30eW3_T"
      },
      "source": [
        "***Aligned Question Embedding Layer***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATOQC6-pWzq_"
      },
      "source": [
        "class AlignQuestionEmbeddingLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden_size):\n",
        "        super(AlignQuestionEmbeddingLayer, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.linear = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, ctx_embed, qst_embed, qst_mask):\n",
        "        \"\"\"\n",
        "        :param FloatTensor[batch_size, ctx_len, embedding_size] ctx_embed\n",
        "        :param FloatTensor[batch_size, qst_len, embedding_size] qst_embed\n",
        "        :param IntTensor[batch_size, qst_len] qst_mask\n",
        "        :return FloatTensor[batch_size, ctx_len, hidden_size]\n",
        "        \"\"\"\n",
        "        ctx_embed = F.relu(self.linear(ctx_embed)) # [batch_size, ctx_len, hidden_size]\n",
        "        qst_embed = F.relu(self.linear(qst_embed)) # [batch_size, qst_len, hidden_size]\n",
        "        scores = torch.bmm(ctx_embed, qst_embed.transpose(-1, -2)) # [batch_size, ctx_len, qst_len]\n",
        "        scores = scores.masked_fill(qst_mask.unsqueeze(1) == 0, 1e-18)\n",
        "        attention_weights = F.softmax(scores, dim=-1) # [batch_size, ctx_len, qst_len]\n",
        "        return torch.bmm(attention_weights, qst_embed)"
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImX8ayztYjsK"
      },
      "source": [
        "***Question Encoding Layer***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Whil-FgVYhgy"
      },
      "source": [
        "class QuestionEncodingLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_size, hidden_size, dropout, n_layers):\n",
        "        super(QuestionEncodingLayer, self).__init__()\n",
        "        self.embedding_size = embedding_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_layers = n_layers\n",
        "        self.stacked_bilstms_layer = StackedBiLSTMsLayer(embedding_size=embedding_size, hidden_size=hidden_size, n_layers=n_layers, dropout=dropout)\n",
        "        self.linear = nn.Linear(embedding_size, 1)\n",
        "    \n",
        "    def linear_self_attention(self, qst_embed, qst_mask):\n",
        "        \"\"\"\n",
        "        :param FloatTensor[batch_size, qst_len, embedding_size] qst_embed\n",
        "        :param IntTensor[batch_size, qst_len] qst_mask\n",
        "        :return FloatTensor[batch_size, qst_len]\n",
        "        \"\"\"\n",
        "        scores = self.linear(qst_embed).squeeze(-1) # [batch_size, qst_len]\n",
        "        scores = scores.masked_fill(qst_mask == 0, 1e-18)\n",
        "        return F.softmax(scores, dim=-1)\n",
        "\n",
        "    \n",
        "    def forward(self, qst_embed, qst_lengths, qst_mask):\n",
        "        \"\"\"\n",
        "        :param FloatTensor[batch_size, qst_len, embedding_size] qst_embed\n",
        "        :param IntTensor[batch_size, qst_len] qst_lengths\n",
        "        :param IntTensor[batch_size, qst_len] qst_mask\n",
        "        :return FloatTensor[batch_size, hidden_size * n_layers * 2]\n",
        "        \"\"\"\n",
        "        attention_weights = self.linear_self_attention(qst_embed=qst_embed, qst_mask=qst_mask) # [batch_size, qst_len]\n",
        "        lstm_outputs = self.stacked_bilstms_layer(input_embedded=qst_embed, sequence_lengths=qst_lengths)\n",
        "        # lstm_outputs: [batch_size, qst_len, hidden_size * n_layers * 2]\n",
        "        return torch.bmm(attention_weights.unsqueeze(1), lstm_outputs).squeeze(1)"
      ],
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hFIZnmUaFAu"
      },
      "source": [
        "***BiLinear Attention Layer***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZGOH3IhaEZw"
      },
      "source": [
        "class BiLinearAttentionLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, ctx_size, qst_size):\n",
        "        super(BiLinearAttentionLayer, self).__init__()\n",
        "        self.ctx_size = ctx_size\n",
        "        self.qst_size = qst_size\n",
        "        self.linear = nn.Linear(qst_size, ctx_size)\n",
        "    \n",
        "    def forward(self, ctx_encoded, qst_encoded, ctx_mask):\n",
        "        \"\"\"\n",
        "        :param FloatTensor[batch_size, ctx_len, ctx_size] ctx_encoded\n",
        "        :param FloatTensor[batch_size, qst_size] qst_encoded\n",
        "        :param IntTensor[batch_size, ctx_len] ctx_mask\n",
        "        :return FloatTensor[batch_size, ctx_len, hidden_size]\n",
        "        \"\"\"\n",
        "        qst_encoded = self.linear(qst_encoded) # [batch_size, ctx_size]\n",
        "        scores = torch.bmm(ctx_encoded, qst_encoded.unsqueeze(-1)) # [batch_size, ctx_len, 1]\n",
        "        scores = scores.squeeze(-1).masked_fill(ctx_mask == 0, 1e-18) # [batch_size, ctx_len]\n",
        "        return scores"
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzrmk6D7agHH"
      },
      "source": [
        "***Document reader Question Answering Model***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlZlTFXOae_o"
      },
      "source": [
        "class DrQA(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_size, n_extra_features, hidden_size, n_layers, dropout, pad_index):\n",
        "        super(DrQA, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.n_extra_features = n_extra_features\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.pad_index = pad_index\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_size, padding_idx=pad_index)\n",
        "        self.align_question_embedding_layer = AlignQuestionEmbeddingLayer(hidden_size=embedding_size)\n",
        "        self.ctx_stacked_bi_lstm_layer = StackedBiLSTMsLayer(embedding_size=embedding_size * 2 + n_extra_features,\n",
        "                                                             hidden_size=hidden_size, n_layers=n_layers, dropout=dropout)\n",
        "        self.qst_encoding_layer = QuestionEncodingLayer(embedding_size=embedding_size, hidden_size=hidden_size, dropout=dropout, n_layers=n_layers)\n",
        "        self.bilinear_attention_layer_start = BiLinearAttentionLayer(ctx_size=hidden_size * n_layers * 2, qst_size=hidden_size * n_layers * 2)\n",
        "        self.bilinear_attention_layer_end = BiLinearAttentionLayer(ctx_size=hidden_size * n_layers * 2, qst_size=hidden_size * n_layers * 2)\n",
        "    \n",
        "    def make_ctx_mask(self, ctx_sequences):\n",
        "        \"\"\"\n",
        "        :param LongTensor[batch_size, ctx_len] ctx_sequences\n",
        "        :return IntTensor[batch_size, ctx_len]\n",
        "        \"\"\"\n",
        "        return ctx_sequences != self.pad_index\n",
        "    \n",
        "    def make_qst_mask(self, qst_sequences):\n",
        "        \"\"\"\n",
        "        :param LongTensor[batch_size, qst_len] qst_sequences\n",
        "        :return IntTensor[batch_size, qst_len]\n",
        "        \"\"\"\n",
        "        return qst_sequences != self.pad_index\n",
        "    \n",
        "    @staticmethod\n",
        "    def decode(starts, ends):\n",
        "        \"\"\"\n",
        "        :param IntTensor[batch_size, ctx_len] starts\n",
        "        :param IntTensor[batch_size, ctx_len] ends\n",
        "        :return list(int) start_indexes\n",
        "        :return list(int) end_indexes\n",
        "        :return list(float) pred_probas\n",
        "        \"\"\"\n",
        "        start_indexes, end_indexes, pred_probas = [], [], []\n",
        "        for i in range(starts.size(0)):\n",
        "            probas = torch.ger(starts[i], ends[i]) # [ctx_len, ctx_len]\n",
        "            proba, index = torch.topk(probas.view(-1), k=1)\n",
        "            start_indexes.append(index.tolist()[0] // probas.size(0))\n",
        "            end_indexes.append(index.tolist()[0] % probas.size(1))\n",
        "            pred_probas.append(proba.tolist()[0])\n",
        "        return start_indexes, end_indexes, pred_probas\n",
        "    \n",
        "    def forward(self, ctx_sequences, ctx_lengths, qst_sequences, qst_lengths, em_sequences, pos_sequences, ner_sequences, ntf_sequences):\n",
        "        \"\"\"\n",
        "        :param LongTensor[batch_size, ctx_len] ctx_sequences\n",
        "        :param Tensor[batch_size,] ctx_lengths\n",
        "        :param LongTensor[batch_size, qst_len] qst_sequences\n",
        "        :param Tensor[batch_size,] qst_lengths\n",
        "        :param LongTensor[batch_size, ctx_len] em_sequences\n",
        "        :param LongTensor[batch_size, ctx_len] pos_sequences\n",
        "        :param LongTensor[batch_size, ctx_len] ner_sequences\n",
        "        :param LongTensor[batch_size, ctx_len] ntf_sequences\n",
        "        :return Tensor[batch_size, ctx_len] starts\n",
        "        :return Tensor[batch_size, ctx_len] ends\n",
        "        \"\"\"\n",
        "        ctx_mask = self.make_ctx_mask(ctx_sequences) # [batch_size, ctx_len]\n",
        "        qst_mask = self.make_qst_mask(qst_sequences) # [batch_size, qst_len]\n",
        "        ctx_embedded = self.dropout(self.embedding(ctx_sequences)) # [batch_size, ctx_len, embedding_size]\n",
        "        qst_embedded = self.dropout(self.embedding(qst_sequences)) # [batch_size, ctx_len, embedding_size]\n",
        "        ctx_aligned = self.align_question_embedding_layer(ctx_embed=ctx_embedded, qst_embed=qst_embedded,\n",
        "                                                          qst_mask=qst_mask) # [batch_size, ctx_len, embedding_size]\n",
        "        ctx_inputs = torch.cat([ctx_embedded, em_sequences.unsqueeze(-1), pos_sequences.unsqueeze(-1), ner_sequences.unsqueeze(-1),\n",
        "                                ntf_sequences.unsqueeze(-1), ctx_aligned], dim=-1) # [batch_size, ctx_len, embedding_size * 2 + 4]\n",
        "        ctx_encoded = self.ctx_stacked_bi_lstm_layer(input_embedded=ctx_inputs, sequence_lengths=ctx_lengths)\n",
        "        # ctx_encoded: [batch_size, ctx_len, hidden_size * n_layers * 2]\n",
        "        qst_encoded = self.qst_encoding_layer(qst_embed=qst_embedded, qst_lengths=qst_lengths, qst_mask=qst_mask)\n",
        "        # qst_encoded: [batch_size, hidden_size * n_layers * 2]\n",
        "        starts = self.bilinear_attention_layer_start(ctx_encoded=ctx_encoded, qst_encoded=qst_encoded, ctx_mask=ctx_mask)\n",
        "        ends = self.bilinear_attention_layer_end(ctx_encoded=ctx_encoded, qst_encoded=qst_encoded, ctx_mask=ctx_mask)\n",
        "        return starts, ends"
      ],
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x575iXlz3w4m"
      },
      "source": [
        "***Training routines***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31k5BZf43uV4"
      },
      "source": [
        "class AverageMeter:\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.value = 0.\n",
        "        self.sum = 0.\n",
        "        self.count = 0\n",
        "        self.average = 0.\n",
        "        \n",
        "    def reset(self):\n",
        "        self.value = 0.\n",
        "        self.sum = 0.\n",
        "        self.count = 0\n",
        "        self.average = 0.\n",
        "        \n",
        "    def update(self, value, n=1):\n",
        "        self.value = value\n",
        "        self.sum += value * n\n",
        "        self.count += n\n",
        "        self.average = self.sum / self.count"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSmh2GmU4KXH"
      },
      "source": [
        "def normalize(answer: str):\n",
        "    \"\"\"Performs a series of cleaning steps on the ground truth and predicted answer.\"\"\"\n",
        "    def remove_articles(text):\n",
        "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
        "\n",
        "    def white_space_fix(text):\n",
        "        return ' '.join(text.split())\n",
        "\n",
        "    def remove_punc(text):\n",
        "        return ''.join(ch for ch in text if ch not in set(string.punctuation))\n",
        "\n",
        "    def lower(text):\n",
        "        return text.lower()\n",
        "\n",
        "    return white_space_fix(remove_articles(remove_punc(lower(answer))))"
      ],
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hi2JHYTX6F6A"
      },
      "source": [
        "def get_scores(prediction: str, ground_truth: str):\n",
        "    prediction, ground_truth = normalize(prediction), normalize(ground_truth)\n",
        "    em_score = prediction == ground_truth\n",
        "\n",
        "    prediction_tokens, ground_truth_tokens = prediction.split(), ground_truth.split()\n",
        "    common = collections.Counter(prediction_tokens) & collections.Counter(ground_truth_tokens)\n",
        "    num_same = sum(common.values())\n",
        "    if num_same == 0:\n",
        "        f1_score = 0\n",
        "    else:\n",
        "        precision = 1.0 * num_same / len(prediction_tokens)\n",
        "        recall = 1.0 * num_same / len(ground_truth_tokens)\n",
        "        f1_score = (2 * precision * recall) / (precision + recall)\n",
        "\n",
        "    return em_score, f1_score"
      ],
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tv9kxaI34_Oo"
      },
      "source": [
        "def max_metrics_over_ground_truths(prediction: str, ground_truths: list):\n",
        "    scores = [get_scores(prediction, ground_truth) for ground_truth in ground_truths]\n",
        "    em_score = max(scores, key=lambda score: score[0])[0]\n",
        "    f1_score = max(scores, key=lambda score: score[1])[1]\n",
        "    return em_score, f1_score"
      ],
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmxMG01B5JEx"
      },
      "source": [
        "def metrics(predictions: dict, qas=valid_qas):\n",
        "    ground_truths = collections.defaultdict(lambda: [])\n",
        "    for qa in qas:\n",
        "        if qa['id'] in predictions:\n",
        "            ground_truths[qa['id']].append(qa['answer'].text)\n",
        "\n",
        "    em_scores, f1_scores, total = [], [], 0\n",
        "    for id in predictions:\n",
        "        em_score, f1_score = max_metrics_over_ground_truths(predictions[id], ground_truths[id])\n",
        "        em_scores.append(em_score); f1_scores.append(f1_score)\n",
        "        total += 1\n",
        "\n",
        "    em_score = 100.0 * sum(em_scores) / total\n",
        "    f1_score = 100.0 * sum(f1_scores) / total\n",
        "    return em_score, f1_score"
      ],
      "execution_count": 244,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHUdYB6f-NRJ"
      },
      "source": [
        "class Trainer:\n",
        "    \n",
        "    def __init__(self, model, optimizer, criterion, id_field, text_field):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.criterion = criterion\n",
        "        self.id_field = id_field\n",
        "        self.text_field = text_field\n",
        "        \n",
        "    def train_step(self, loader, epoch, grad_clip):\n",
        "        loss_tracker = AverageMeter()\n",
        "        self.model.train()\n",
        "        progress_bar = tqdm.tqdm(enumerate(loader), total=len(loader))\n",
        "        for i, batch in progress_bar:\n",
        "            self.optimizer.zero_grad()\n",
        "            starts, ends = self.model(*batch.ctx, *batch.qst, batch.em, batch.pos, batch.ner, batch.ntf) # [batch_size, ctx_len]\n",
        "            loss = self.criterion(starts, batch.trg[:, 0]) + self.criterion(ends, batch.trg[:, 1])\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(self.model.parameters(), grad_clip)\n",
        "            self.optimizer.step()\n",
        "            loss_tracker.update(loss.item())\n",
        "            progress_bar.set_description(f'Epoch: {epoch+1:02d} -     loss: {loss_tracker.average:.3f}')\n",
        "        return loss_tracker.average\n",
        "    \n",
        "    def validate(self, loader, epoch):\n",
        "        loss_tracker, predictions = AverageMeter(), {}\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            progress_bar = tqdm.tqdm(enumerate(loader), total=len(loader))\n",
        "            for i, batch in progress_bar:\n",
        "                starts, ends = self.model(*batch.ctx, *batch.qst, batch.em, batch.pos, batch.ner, batch.ntf) # [batch_size, ctx_len]\n",
        "                loss = self.criterion(starts, batch.trg[:, 0]) + self.criterion(ends, batch.trg[:, 1])\n",
        "                start_indexes, end_indexes, _ = DrQA.decode(starts=F.softmax(starts, dim=-1), ends=F.softmax(ends, dim=-1))\n",
        "                for i in range(starts.size(0)):\n",
        "                    id = self.id_field.itos(batch.id[i].item())\n",
        "                    prediction = batch.ctx[0][i][start_indexes[i]:end_indexes[i]+1]\n",
        "                    predictions[id] = ' '.join([self.text_field.itos(indice.item()) for indice in prediction])\n",
        "                loss_tracker.update(loss.item())\n",
        "                progress_bar.set_description(f'Epoch: {epoch+1:02d} - val_loss: {loss_tracker.average:.3f}')\n",
        "        return loss_tracker.average, predictions\n",
        "    \n",
        "    def train(self, train_loader, valid_loader, n_epochs, grad_clip):\n",
        "        history, best_loss = {'loss': [], 'val_loss': [], 'em': [], 'f1': []}, float('inf')\n",
        "        for epoch in range(n_epochs):\n",
        "            loss = self.train_step(train_loader, epoch, grad_clip)\n",
        "            val_loss, predictions = self.validate(valid_loader, epoch)\n",
        "            em_score, f1_score = metrics(predictions)\n",
        "            history['loss'].append(loss); history['val_loss'].append(val_loss)\n",
        "            history['em'].append(em_score); history['f1'].append(f1_score)\n",
        "            if best_loss > val_loss:\n",
        "                best_loss = val_loss\n",
        "                torch.save(self.model.state_dict(), './checkpoints/DrQA.pth')\n",
        "            time.sleep(1)\n",
        "            print(f'\\nEM={em_score:.3f}% - F1={f1_score:.3f}%')\n",
        "        return history"
      ],
      "execution_count": 250,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFzM-vWUAov9"
      },
      "source": [
        "***Train the model***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YCmJQLhAlqo"
      },
      "source": [
        "N_LAYERS = 3\n",
        "EMBED_SIZE = 300\n",
        "HIDDEN_SIZE = 256\n",
        "DROPOUT = 0.25\n",
        "N_EPOCHS = 5\n",
        "LR = 1e-3\n",
        "GRAD_CLIP = 1.0"
      ],
      "execution_count": 251,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ersGVmFxBwAV",
        "outputId": "82811505-826b-4309-b120-ab6905930bd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "drqa = DrQA(vocab_size=len(TEXT),\n",
        "            embedding_size=EMBED_SIZE,\n",
        "            n_extra_features=4,\n",
        "            hidden_size=HIDDEN_SIZE,\n",
        "            n_layers=N_LAYERS,\n",
        "            dropout=DROPOUT,\n",
        "            pad_index=TEXT.stoi(PAD_TOKEN))\n",
        "drqa.to(DEVICE)\n",
        "optimizer = optim.RMSprop(params=drqa.parameters(), lr=LR)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=TEXT.stoi(PAD_TOKEN))\n",
        "print(f'Number of parameters of the model: {sum(p.numel() for p in drqa.parameters() if p.requires_grad):,}')\n",
        "print(drqa)\n",
        "trainer = Trainer(model=drqa, optimizer=optimizer, criterion=criterion, id_field=ID, text_field=TEXT)"
      ],
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of parameters of the model: 41,017,285\n",
            "DrQA(\n",
            "  (dropout): Dropout(p=0.25, inplace=False)\n",
            "  (embedding): Embedding(26885, 300, padding_idx=1318)\n",
            "  (align_question_embedding_layer): AlignQuestionEmbeddingLayer(\n",
            "    (linear): Linear(in_features=300, out_features=300, bias=True)\n",
            "  )\n",
            "  (ctx_stacked_bi_lstm_layer): StackedBiLSTMsLayer(\n",
            "    (dropout): Dropout(p=0.25, inplace=False)\n",
            "    (lstms): ModuleList(\n",
            "      (0): LSTM(604, 256, num_layers=3, batch_first=True, bidirectional=True)\n",
            "      (1): LSTM(512, 256, num_layers=3, batch_first=True, bidirectional=True)\n",
            "      (2): LSTM(512, 256, num_layers=3, batch_first=True, bidirectional=True)\n",
            "    )\n",
            "  )\n",
            "  (qst_encoding_layer): QuestionEncodingLayer(\n",
            "    (stacked_bilstms_layer): StackedBiLSTMsLayer(\n",
            "      (dropout): Dropout(p=0.25, inplace=False)\n",
            "      (lstms): ModuleList(\n",
            "        (0): LSTM(300, 256, num_layers=3, batch_first=True, bidirectional=True)\n",
            "        (1): LSTM(512, 256, num_layers=3, batch_first=True, bidirectional=True)\n",
            "        (2): LSTM(512, 256, num_layers=3, batch_first=True, bidirectional=True)\n",
            "      )\n",
            "    )\n",
            "    (linear): Linear(in_features=300, out_features=1, bias=True)\n",
            "  )\n",
            "  (bilinear_attention_layer_start): BiLinearAttentionLayer(\n",
            "    (linear): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "  )\n",
            "  (bilinear_attention_layer_end): BiLinearAttentionLayer(\n",
            "    (linear): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giP1Ov5_DTGr",
        "outputId": "3131cc87-b9a6-4235-f681-aa26e6feb9c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!mkdir -p ./checkpoints\n",
        "history = trainer.train(train_loader=train_dataloader, valid_loader=valid_dataloader, n_epochs=N_EPOCHS, grad_clip=GRAD_CLIP)"
      ],
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 -     loss: 6.798: 100%|██████████| 1354/1354 [11:49<00:00,  1.91it/s]\n",
            "Epoch: 01 - val_loss: 4.883: 100%|██████████| 536/536 [01:53<00:00,  4.74it/s]\n",
            "  0%|          | 0/1354 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "EM=24.379% - F1=36.267%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 02 -     loss: 4.452: 100%|██████████| 1354/1354 [11:50<00:00,  1.90it/s]\n",
            "Epoch: 02 - val_loss: 4.583: 100%|██████████| 536/536 [01:52<00:00,  4.77it/s]\n",
            "  0%|          | 0/1354 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "EM=25.968% - F1=38.437%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 03 -     loss: 3.999: 100%|██████████| 1354/1354 [11:52<00:00,  1.90it/s]\n",
            "Epoch: 03 - val_loss: 4.256: 100%|██████████| 536/536 [01:53<00:00,  4.73it/s]\n",
            "  0%|          | 0/1354 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "EM=30.403% - F1=43.905%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 04 -     loss: 3.700: 100%|██████████| 1354/1354 [11:51<00:00,  1.90it/s]\n",
            "Epoch: 04 - val_loss: 4.047: 100%|██████████| 536/536 [01:51<00:00,  4.80it/s]\n",
            "  0%|          | 0/1354 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "EM=31.069% - F1=44.442%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 05 -     loss: 3.487: 100%|██████████| 1354/1354 [11:48<00:00,  1.91it/s]\n",
            "Epoch: 05 - val_loss: 4.088: 100%|██████████| 536/536 [01:50<00:00,  4.83it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "EM=32.401% - F1=45.959%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8C-bSJpY-qZM",
        "outputId": "5d1d9884-a176-4d92-f1b0-70df6907f896",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "_, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "axes[0].plot(history['loss'], label='train')\n",
        "axes[0].plot(history['val_loss'], label='valid')\n",
        "axes[0].set_title('Loss history')\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('Loss')\n",
        "axes[0].grid(True)\n",
        "axes[0].legend()\n",
        "\n",
        "axes[1].plot(history['em'], label='valid')\n",
        "axes[1].set_title('Exact match history')\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].set_ylabel('Exact match (%)')\n",
        "axes[1].grid(True)\n",
        "axes[1].legend()\n",
        "\n",
        "axes[2].plot(history['f1'], label='valid')\n",
        "axes[2].set_title('F1 history')\n",
        "axes[2].set_xlabel('Epoch')\n",
        "axes[2].set_ylabel('F1 (%)')\n",
        "axes[2].grid(True)\n",
        "axes[2].legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_99dtAVn5CL"
      },
      "source": [
        "***Inference***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gk9dSwSR_OM9",
        "outputId": "700b8c99-9861-4690-8429-fd0d268635cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "drqa.load_state_dict(torch.load('./checkpoints/DrQA.pth'))\n",
        "drqa.to(DEVICE)"
      ],
      "execution_count": 290,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DrQA(\n",
              "  (dropout): Dropout(p=0.25, inplace=False)\n",
              "  (embedding): Embedding(26885, 300, padding_idx=1318)\n",
              "  (align_question_embedding_layer): AlignQuestionEmbeddingLayer(\n",
              "    (linear): Linear(in_features=300, out_features=300, bias=True)\n",
              "  )\n",
              "  (ctx_stacked_bi_lstm_layer): StackedBiLSTMsLayer(\n",
              "    (dropout): Dropout(p=0.25, inplace=False)\n",
              "    (lstms): ModuleList(\n",
              "      (0): LSTM(604, 256, num_layers=3, batch_first=True, bidirectional=True)\n",
              "      (1): LSTM(512, 256, num_layers=3, batch_first=True, bidirectional=True)\n",
              "      (2): LSTM(512, 256, num_layers=3, batch_first=True, bidirectional=True)\n",
              "    )\n",
              "  )\n",
              "  (qst_encoding_layer): QuestionEncodingLayer(\n",
              "    (stacked_bilstms_layer): StackedBiLSTMsLayer(\n",
              "      (dropout): Dropout(p=0.25, inplace=False)\n",
              "      (lstms): ModuleList(\n",
              "        (0): LSTM(300, 256, num_layers=3, batch_first=True, bidirectional=True)\n",
              "        (1): LSTM(512, 256, num_layers=3, batch_first=True, bidirectional=True)\n",
              "        (2): LSTM(512, 256, num_layers=3, batch_first=True, bidirectional=True)\n",
              "      )\n",
              "    )\n",
              "    (linear): Linear(in_features=300, out_features=1, bias=True)\n",
              "  )\n",
              "  (bilinear_attention_layer_start): BiLinearAttentionLayer(\n",
              "    (linear): Linear(in_features=1536, out_features=1536, bias=True)\n",
              "  )\n",
              "  (bilinear_attention_layer_end): BiLinearAttentionLayer(\n",
              "    (linear): Linear(in_features=1536, out_features=1536, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 290
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1CVgakLDtsU"
      },
      "source": [
        "def inference(model: nn.Module, context: spacy.tokens.doc.Doc, question: spacy.tokens.doc.Doc,\n",
        "              text_vocab: Vocab, pos_vocab: Vocab, ner_vocab: Vocab, device: torch.device):\n",
        "    # Build extra features\n",
        "    question = [token.text.lower() for token in question]\n",
        "    counts = collections.Counter(map(lambda token: token.text.lower(), context))\n",
        "    freqs = {index: counts[token.text.lower()] for index, token in enumerate(context)}\n",
        "    freqs_norm = sum(freqs.values())\n",
        "    em, pos, ner, ntf = zip(\n",
        "        *map(lambda index: [\n",
        "            context[index].text.lower() in question, context[index].tag_,\n",
        "            context[index].ent_type_ or 'None',\n",
        "            freqs[index] / freqs_norm\n",
        "        ], range(len(context)))\n",
        "    )\n",
        "\n",
        "    # Build tensors\n",
        "    ctx = torch.LongTensor([*map(lambda word: text_vocab.stoi(word), context)]).unsqueeze(0).to(device)\n",
        "    qst = torch.LongTensor([*map(lambda word: text_vocab.stoi(word), question)]).unsqueeze(0).to(device)\n",
        "    len_ctx = torch.LongTensor([len(context)]).to(device)\n",
        "    len_qst = torch.LongTensor([len(question)]).to(device)\n",
        "    em = torch.LongTensor(em).unsqueeze(0).to(device)\n",
        "    pos = torch.LongTensor([*map(lambda x: pos_vocab.stoi(x), pos)]).unsqueeze(0).to(device)\n",
        "    ner = torch.LongTensor([*map(lambda x: ner_vocab.stoi(x), ner)]).unsqueeze(0).to(device)\n",
        "    ntf = torch.LongTensor(ntf).unsqueeze(0).to(device)\n",
        "\n",
        "    # Prediction\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Feed the model\n",
        "        start, end = model(ctx_sequences=ctx, ctx_lengths=len_ctx, qst_sequences=qst, qst_lengths=len_qst,\n",
        "                           em_sequences=em, pos_sequences=pos, ner_sequences=ner, ntf_sequences=ntf)\n",
        "    \n",
        "        # Decode the result indexes\n",
        "        start_index, end_index, proba = model.__class__.decode(starts=F.softmax(start, dim=-1), ends=F.softmax(end, dim=-1))\n",
        "\n",
        "        # Extract the answer\n",
        "        answer = context[start_index[0]:end_index[0] + 1]\n",
        "\n",
        "    return answer, proba[0]"
      ],
      "execution_count": 320,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dI-ME2Q1-WzB",
        "outputId": "7a617e72-0637-4d0e-d963-47b8d53028aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for index in np.random.choice(len(valid_qas), size=25, replace=False):\n",
        "    id = valid_qas[index]['id']\n",
        "    context = valid_qas[index]['context']\n",
        "    question = valid_qas[index]['question']\n",
        "\n",
        "    answers = []\n",
        "    for qa in valid_qas:\n",
        "        if id == qa['id']:\n",
        "            answers.append(qa['answer'])\n",
        "\n",
        "    prediction, proba = inference(model=drqa, context=context, question=question,\n",
        "                                  text_vocab=TEXT, pos_vocab=POS, ner_vocab=NER, device=DEVICE)\n",
        "    \n",
        "    html = f'<p><span><b>Context:</b> {context.text}</span><br />'\n",
        "    html += f'<span><b>Question:</b> {question.text}</span><br />'\n",
        "    html += f'<span style=\"color:blue\"><b>Answers:</b><br /><ul>'\n",
        "    for answer in answers:\n",
        "        html += f'<li style=\"color:blue\">{answer.text} - {normalize(answer.text)}</li>'\n",
        "    html += '</ul></span><br />'\n",
        "    html += f'<span style=\"color:green\"><b>Prediction:</b> {prediction}</span><br />'\n",
        "    html += f'<span style=\"color:green\"><b>Probability:</b> {proba * 100:.3f}%</span><br />'\n",
        "    display(HTML(html))\n",
        "    print('='*100)"
      ],
      "execution_count": 333,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span><b>Context:</b> After Malaysia's independence in 1957, the government instructed all schools to surrender their properties and be assimilated into the National School system. This caused an uproar among the Chinese and a compromise was achieved in that the schools would instead become \"National Type\" schools. Under such a system, the government is only in charge of the school curriculum and teaching personnel while the lands still belonged to the schools. While Chinese primary schools were allowed to retain Chinese as the medium of instruction, Chinese secondary schools are required to change into English-medium schools. Over 60 schools converted to become National Type schools.</span><br /><span><b>Question:</b> What language is used in Chinese secondary schools in Malaysia?</span><br /><span style=\"color:blue\"><b>Answers:</b><br /><ul><li style=\"color:blue\">English - english</li><li style=\"color:blue\">English - english</li><li style=\"color:blue\">English - english</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> Chinese</span><br /><span style=\"color:green\"><b>Probability:</b> 13.016%</span><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span><b>Context:</b> Highly combustible materials that leave little residue, such as wood or coal, were thought to be made mostly of phlogiston; whereas non-combustible substances that corrode, such as iron, contained very little. Air did not play a role in phlogiston theory, nor were any initial quantitative experiments conducted to test the idea; instead, it was based on observations of what happens when something burns, that most common objects appear to become lighter and seem to lose something in the process. The fact that a substance like wood gains overall weight in burning was hidden by the buoyancy of the gaseous combustion products. Indeed, one of the first clues that the phlogiston theory was incorrect was that metals, too, gain weight in rusting (when they were supposedly losing phlogiston).</span><br /><span><b>Question:</b> What material's weight gain during rusting was an early clue that philogiston theory was wrong?</span><br /><span style=\"color:blue\"><b>Answers:</b><br /><ul><li style=\"color:blue\">metals - metals</li><li style=\"color:blue\">metals - metals</li><li style=\"color:blue\">metals - metals</li><li style=\"color:blue\">metals - metals</li><li style=\"color:blue\">metals - metals</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> phlogiston</span><br /><span style=\"color:green\"><b>Probability:</b> 5.750%</span><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span><b>Context:</b> These attacks resonated with conservative Muslims and the problem did not go away with Saddam's defeat either, since American troops remained stationed in the kingdom, and a de facto cooperation with the Palestinian-Israeli peace process developed. Saudi Arabia attempted to compensate for its loss of prestige among these groups by repressing those domestic Islamists who attacked it (bin Laden being a prime example), and increasing aid to Islamic groups (Islamist madrassas around the world and even aiding some violent Islamist groups) that did not, but its pre-war influence on behalf of moderation was greatly reduced. One result of this was a campaign of attacks on government officials and tourists in Egypt, a bloody civil war in Algeria and Osama bin Laden's terror attacks climaxing in the 9/11 attack.</span><br /><span><b>Question:</b> Where did a bloody civil war break out?</span><br /><span style=\"color:blue\"><b>Answers:</b><br /><ul><li style=\"color:blue\">Algeria - algeria</li><li style=\"color:blue\">Algeria - algeria</li><li style=\"color:blue\">Algeria - algeria</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> Algeria</span><br /><span style=\"color:green\"><b>Probability:</b> 12.331%</span><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span><b>Context:</b> Cultural imperialism is when a country's influence is felt in social and cultural circles, i.e. its soft power, such that it changes the moral, cultural and societal worldview of another. This is more than just \"foreign\" music, television or film becoming popular with young people, but that popular culture changing their own expectations of life and their desire for their own country to become more like the foreign country depicted. For example, depictions of opulent American lifestyles in the soap opera Dallas during the Cold War changed the expectations of Romanians; a more recent example is the influence of smuggled South Korean drama series in North Korea. The importance of soft power is not lost on authoritarian regimes, fighting such influence with bans on foreign popular culture, control of the internet and unauthorised satellite dishes etc. Nor is such a usage of culture recent, as part of Roman imperialism local elites would be exposed to the benefits and luxuries of Roman culture and lifestyle, with the aim that they would then become willing participants.</span><br /><span><b>Question:</b> How do regimes fight against cultural imperialism?</span><br /><span style=\"color:blue\"><b>Answers:</b><br /><ul><li style=\"color:blue\">bans - bans</li><li style=\"color:blue\">bans on foreign popular culture, control of the internet and unauthorised satellite dishes - bans on foreign popular culture control of internet and unauthorised satellite dishes</li><li style=\"color:blue\">bans on foreign popular culture, control of the internet and unauthorised satellite dishes - bans on foreign popular culture control of internet and unauthorised satellite dishes</li><li style=\"color:blue\">bans - bans</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> it changes the moral</span><br /><span style=\"color:green\"><b>Probability:</b> 8.291%</span><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span><b>Context:</b> The collection includes about 1130 British and 650 European oil paintings, 6800 British watercolours, pastels and 2000 miniatures, for which the museum holds the national collection. Also on loan to the museum, from Her Majesty the Queen Elizabeth II, are the Raphael Cartoons: the seven surviving (there were ten) full scale designs for tapestries in the Sistine Chapel, of the lives of Peter and Paul from the Gospels and the Acts of the Apostles. There is also on display a fresco by Pietro Perugino dated 1522 from the church of Castello at Fontignano (Perugia) and is amongst the painter's last works. One of the largest objects in the collection is the Spanish tempera on wood, 670 x 486 cm, retable of St George, c. 1400, consisting of numerous scenes and painted by Andrés Marzal De Sax in Valencia.</span><br /><span><b>Question:</b> Approximately how many European oil paintings does the museum have?</span><br /><span style=\"color:blue\"><b>Answers:</b><br /><ul><li style=\"color:blue\">650 - 650</li><li style=\"color:blue\">650 - 650</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> 650</span><br /><span style=\"color:green\"><b>Probability:</b> 47.681%</span><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span><b>Context:</b> Tesla noted the hazards of working with his circuit and single-node X-ray-producing devices. In his many notes on the early investigation of this phenomenon, he attributed the skin damage to various causes. He believed early on that damage to the skin was not caused by the Roentgen rays, but by the ozone generated in contact with the skin, and to a lesser extent, by nitrous acid. Tesla incorrectly believed that X-rays were longitudinal waves, such as those produced in waves in plasmas. These plasma waves can occur in force-free magnetic fields.</span><br /><span><b>Question:</b> where do plasma waves occur? </span><br /><span style=\"color:blue\"><b>Answers:</b><br /><ul><li style=\"color:blue\">force-free magnetic fields - forcefree magnetic fields</li><li style=\"color:blue\">force-free magnetic fields - forcefree magnetic fields</li><li style=\"color:blue\">in force-free magnetic fields - in forcefree magnetic fields</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> force-free magnetic fields</span><br /><span style=\"color:green\"><b>Probability:</b> 33.809%</span><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span><b>Context:</b> Royal assent: After the bill has been passed, the Presiding Officer submits it to the Monarch for royal assent and it becomes an Act of the Scottish Parliament. However he cannot do so until a 4-week period has elapsed, during which the Law Officers of the Scottish Government or UK Government can refer the bill to the Supreme Court of the United Kingdom for a ruling on whether it is within the powers of the Parliament. Acts of the Scottish Parliament do not begin with a conventional enacting formula. Instead they begin with a phrase that reads: \"The Bill for this Act of the Scottish Parliament was passed by the Parliament on [Date] and received royal assent on [Date]\".</span><br /><span><b>Question:</b> What is the minimum amount of time before a bill can go into law?</span><br /><span style=\"color:blue\"><b>Answers:</b><br /><ul><li style=\"color:blue\">a 4-week period - 4week period</li><li style=\"color:blue\">a 4-week period - 4week period</li><li style=\"color:blue\">4-week period - 4week period</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> UK Government</span><br /><span style=\"color:green\"><b>Probability:</b> 11.676%</span><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span><b>Context:</b> Founded by the American Baptist Education Society with a donation from oil magnate and wealthiest man in history John D. Rockefeller, the University of Chicago was incorporated in 1890; William Rainey Harper became the university's first president in 1891, and the first classes were held in 1892. Both Harper and future president Robert Maynard Hutchins advocated for Chicago's curriculum to be based upon theoretical and perennial issues rather than on applied sciences and commercial utility. With Harper's vision in mind, the University of Chicago also became one of the 14 founding members of the Association of American Universities, an international organization of leading research universities, in 1900.</span><br /><span><b>Question:</b> What year was the first class taught at the University of Chicago?</span><br /><span style=\"color:blue\"><b>Answers:</b><br /><ul><li style=\"color:blue\">1892 - 1892</li><li style=\"color:blue\">1892 - 1892</li><li style=\"color:blue\">1892 - 1892</li><li style=\"color:blue\">1892 - 1892</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> 1892</span><br /><span style=\"color:green\"><b>Probability:</b> 27.348%</span><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span><b>Context:</b> Hence, 6 is not prime. The image at the right illustrates that 12 is not prime: 12 = 3 · 4. No even number greater than 2 is prime because by definition, any such number n has at least three distinct divisors, namely 1, 2, and n. This implies that n is not prime. Accordingly, the term odd prime refers to any prime number greater than 2. Similarly, when written in the usual decimal system, all prime numbers larger than 5 end in 1, 3, 7, or 9, since even numbers are multiples of 2 and numbers ending in 0 or 5 are multiples of 5.</span><br /><span><b>Question:</b> What type of numbers are always multiples of 2?</span><br /><span style=\"color:blue\"><b>Answers:</b><br /><ul><li style=\"color:blue\">even numbers - even numbers</li><li style=\"color:blue\">even - even</li><li style=\"color:blue\">even numbers - even numbers</li><li style=\"color:blue\">even - even</li><li style=\"color:blue\">even - even</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> </span><br /><span style=\"color:green\"><b>Probability:</b> 28.901%</span><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span><b>Context:</b> The delay in the CSM caused by the fire enabled NASA to catch up on man-rating the LM and Saturn V. Apollo 4 (AS-501) was the first unmanned flight of the Saturn V, carrying a Block I CSM on November 9, 1967. The capability of the Command Module's heat shield to survive a trans-lunar reentry was demonstrated by using the Service Module engine to ram it into the atmosphere at higher than the usual Earth-orbital reentry speed. This was followed on April 4, 1968, by Apollo 6 (AS-502) which carried a CSM and a LM Test Article as ballast. The intent of this mission was to achieve trans-lunar injection, followed closely by a simulated direct-return abort, using the Service Module engine to achieve another high-speed reentry. The Saturn V experienced pogo oscillation, a problem caused by non-steady engine combustion, which damaged fuel lines in the second and third stages. Two S-II engines shut down prematurely, but the remaining engines were able to compensate. The damage to the third stage engine was more severe, preventing it from restarting for trans-lunar injection. Mission controllers were able to use the Service Module engine to essentially repeat the flight profile of Apollo 4. Based on the good performance of Apollo 6 and identification of satisfactory fixes to the Apollo 6 problems, NASA declared the Saturn V ready to fly men, cancelling a third unmanned test.</span><br /><span><b>Question:</b> What was one thing that was specifically tested on the Apollo 4 test launch regarding the CM?</span><br /><span style=\"color:blue\"><b>Answers:</b><br /><ul><li style=\"color:blue\">heat shield - heat shield</li><li style=\"color:blue\">Service Module engine - service module engine</li><li style=\"color:blue\">heat shield - heat shield</li><li style=\"color:blue\">capability of the Command Module's heat shield to survive a trans-lunar reentry - capability of command modules heat shield to survive translunar reentry</li><li style=\"color:blue\">capability of the Command Module's heat shield to survive a trans-lunar reentry - capability of command modules heat shield to survive translunar reentry</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> </span><br /><span style=\"color:green\"><b>Probability:</b> 0.417%</span><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span><b>Context:</b> Founded by the American Baptist Education Society with a donation from oil magnate and wealthiest man in history John D. Rockefeller, the University of Chicago was incorporated in 1890; William Rainey Harper became the university's first president in 1891, and the first classes were held in 1892. Both Harper and future president Robert Maynard Hutchins advocated for Chicago's curriculum to be based upon theoretical and perennial issues rather than on applied sciences and commercial utility. With Harper's vision in mind, the University of Chicago also became one of the 14 founding members of the Association of American Universities, an international organization of leading research universities, in 1900.</span><br /><span><b>Question:</b> Who was the first president of the University of Chicago?</span><br /><span style=\"color:blue\"><b>Answers:</b><br /><ul><li style=\"color:blue\">William Rainey Harper - william rainey harper</li><li style=\"color:blue\">William Rainey Harper - william rainey harper</li><li style=\"color:blue\">William Rainey Harper - william rainey harper</li><li style=\"color:blue\">William Rainey Harper - william rainey harper</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> Harper</span><br /><span style=\"color:green\"><b>Probability:</b> 42.150%</span><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span><b>Context:</b> Central Banking economist Raghuram Rajan argues that \"systematic economic inequalities, within the United States and around the world, have created deep financial 'fault lines' that have made [financial] crises more likely to happen than in the past\" – the Financial crisis of 2007–08 being the most recent example. To compensate for stagnating and declining purchasing power, political pressure has developed to extend easier credit to the lower and middle income earners – particularly to buy homes – and easier credit in general to keep unemployment rates low. This has given the American economy a tendency to go \"from bubble to bubble\" fueled by unsustainable monetary stimulation.</span><br /><span><b>Question:</b> What is the most recent example of financial fault lines? </span><br /><span style=\"color:blue\"><b>Answers:</b><br /><ul><li style=\"color:blue\">the Financial crisis of 2007–08 - financial crisis of 2007–08</li><li style=\"color:blue\">Financial crisis of 2007–08 - financial crisis of 2007–08</li><li style=\"color:blue\">Financial crisis of 2007–08 - financial crisis of 2007–08</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> Financial crisis of 2007–08</span><br /><span style=\"color:green\"><b>Probability:</b> 25.799%</span><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span><b>Context:</b> Oxygen is a chemical element with symbol O and atomic number 8. It is a member of the chalcogen group on the periodic table and is a highly reactive nonmetal and oxidizing agent that readily forms compounds (notably oxides) with most elements. By mass, oxygen is the third-most abundant element in the universe, after hydrogen and helium. At standard temperature and pressure, two atoms of the element bind to form dioxygen, a colorless and odorless diatomic gas with the formula O\n",
              "2. Diatomic oxygen gas constitutes 20.8% of the Earth's atmosphere. However, monitoring of atmospheric oxygen levels show a global downward trend, because of fossil-fuel burning. Oxygen is the most abundant element by mass in the Earth's crust as part of oxide compounds such as silicon dioxide, making up almost half of the crust's mass.</span><br /><span><b>Question:</b> What is the atomic number for oxygen?</span><br /><span style=\"color:blue\"><b>Answers:</b><br /><ul><li style=\"color:blue\">8 - 8</li><li style=\"color:blue\">8 - 8</li><li style=\"color:blue\">8 - 8</li><li style=\"color:blue\">8 - 8</li><li style=\"color:blue\">8 - 8</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> 8</span><br /><span style=\"color:green\"><b>Probability:</b> 37.069%</span><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span><b>Context:</b> Following the Peterloo massacre of 1819, poet Percy Shelley wrote the political poem The Mask of Anarchy later that year, that begins with the images of what he thought to be the unjust forms of authority of his time—and then imagines the stirrings of a new form of social action. It is perhaps the first modern[vague] statement of the principle of nonviolent protest. A version was taken up by the author Henry David Thoreau in his essay Civil Disobedience, and later by Gandhi in his doctrine of Satyagraha. Gandhi's Satyagraha was partially influenced and inspired by Shelley's nonviolence in protest and political action. In particular, it is known that Gandhi would often quote Shelley's Masque of Anarchy to vast audiences during the campaign for a free India.</span><br /><span><b>Question:</b> Inspired by Shelley what was the name of Gandhi's doctrine?</span><br /><span style=\"color:blue\"><b>Answers:</b><br /><ul><li style=\"color:blue\">Satyagraha - satyagraha</li><li style=\"color:blue\">Satyagraha - satyagraha</li><li style=\"color:blue\">Satyagraha - satyagraha</li><li style=\"color:blue\">Satyagraha - satyagraha</li><li style=\"color:blue\">Satyagraha - satyagraha</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> Satyagraha</span><br /><span style=\"color:green\"><b>Probability:</b> 9.108%</span><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span><b>Context:</b> Private schools, also known as independent schools, non-governmental, or nonstate schools, are not administered by local, state or national governments; thus, they retain the right to select their students and are funded in whole or in part by charging their students tuition, rather than relying on mandatory taxation through public (government) funding; at some private schools students may be able to get a scholarship, which makes the cost cheaper, depending on a talent the student may have (e.g. sport scholarship, art scholarship, academic scholarship), financial need, or tax credit scholarships that might be available.</span><br /><span><b>Question:</b> Along with sport and art, what is a type of talent scholarship?</span><br /><span style=\"color:blue\"><b>Answers:</b><br /><ul><li style=\"color:blue\">academic - academic</li><li style=\"color:blue\">academic - academic</li><li style=\"color:blue\">academic - academic</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> academic</span><br /><span style=\"color:green\"><b>Probability:</b> 71.874%</span><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span><b>Context:</b> A wide selection of serials are available from BBC Video on DVD, on sale in the United Kingdom, Australia, Canada and the United States. Every fully extant serial has been released on VHS, and BBC Worldwide continues to regularly release serials on DVD. The 2005 series is also available in its entirety on UMD for the PlayStation Portable. Eight original series serials have been released on Laserdisc and many have also been released on Betamax tape and Video 2000. One episode of Doctor Who (The Infinite Quest) was released on VCD. Only the series from 2009 onwards are available on Blu-ray, except for the 1970 story Spearhead from Space, released in July 2013. Many early releases have been re-released as special editions, with more bonus features.</span><br /><span><b>Question:</b> What is the only episode released on VCD?</span><br /><span style=\"color:blue\"><b>Answers:</b><br /><ul><li style=\"color:blue\">The Infinite Quest - infinite quest</li><li style=\"color:blue\">The Infinite Quest - infinite quest</li><li style=\"color:blue\">The Infinite Quest - infinite quest</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> Doctor Who</span><br /><span style=\"color:green\"><b>Probability:</b> 13.408%</span><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span><b>Context:</b> The revived series has received recognition from critics and the public, across various awards ceremonies. It won five BAFTA TV Awards, including Best Drama Series, the highest-profile and most prestigious British television award for which the series has ever been nominated. It was very popular at the BAFTA Cymru Awards, with 25 wins overall including Best Drama Series (twice), Best Screenplay/Screenwriter (thrice) and Best Actor. It was also nominated for 7 Saturn Awards, winning the only Best International Series in the ceremony's history. In 2009, Doctor Who was voted the 3rd greatest show of the 2000s by Channel 4, behind Top Gear and The Apprentice. The episode \"Vincent and the Doctor\" was shortlisted for a Mind Award at the 2010 Mind Mental Health Media Awards for its \"touching\" portrayal of Vincent van Gogh.</span><br /><span><b>Question:</b> How many BAFTA TV awards has Doctor Who won?</span><br /><span style=\"color:blue\"><b>Answers:</b><br /><ul><li style=\"color:blue\">five - five</li><li style=\"color:blue\">25 - 25</li><li style=\"color:blue\">five - five</li><li style=\"color:blue\">five - five</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> Best</span><br /><span style=\"color:green\"><b>Probability:</b> 7.090%</span><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span><b>Context:</b> The university runs a number of academic institutions and programs apart from its undergraduate and postgraduate schools. It operates the University of Chicago Laboratory Schools (a private day school for K-12 students and day care), the Sonia Shankman Orthogenic School (a residential treatment program for those with behavioral and emotional problems), and four public charter schools on the South Side of Chicago administered by the university's Urban Education Institute. In addition, the Hyde Park Day School, a school for students with learning disabilities, maintains a location on the University of Chicago campus. Since 1983, the University of Chicago has maintained the University of Chicago School Mathematics Project, a mathematics program used in urban primary and secondary schools. The university runs a program called the Council on Advanced Studies in the Social Sciences and Humanities, which administers interdisciplinary workshops to provide a forum for graduate students, faculty, and visiting scholars to present scholarly work in progress. The university also operates the University of Chicago Press, the largest university press in the United States.</span><br /><span><b>Question:</b> What is the name of the residential treatment program the university runs?</span><br /><span style=\"color:blue\"><b>Answers:</b><br /><ul><li style=\"color:blue\">the Sonia Shankman Orthogenic School - sonia shankman orthogenic school</li><li style=\"color:blue\">Sonia Shankman Orthogenic School - sonia shankman orthogenic school</li><li style=\"color:blue\">the Sonia Shankman Orthogenic School - sonia shankman orthogenic school</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> the Council</span><br /><span style=\"color:green\"><b>Probability:</b> 14.402%</span><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span><b>Context:</b> Doctor Who is a British science-fiction television programme produced by the BBC since 1963. The programme depicts the adventures of the Doctor, a Time Lord—a space and time-travelling humanoid alien. He explores the universe in his TARDIS, a sentient time-travelling space ship. Its exterior appears as a blue British police box, which was a common sight in Britain in 1963 when the series first aired. Accompanied by companions, the Doctor combats a variety of foes, while working to save civilisations and help people in need.</span><br /><span><b>Question:</b> What is Doctor Who's space ship called?</span><br /><span style=\"color:blue\"><b>Answers:</b><br /><ul><li style=\"color:blue\">TARDIS - tardis</li><li style=\"color:blue\">TARDIS - tardis</li><li style=\"color:blue\">TARDIS - tardis</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> the Doctor</span><br /><span style=\"color:green\"><b>Probability:</b> 5.079%</span><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span><b>Context:</b> Kenyans generally have three meals in a day – breakfast in the morning (kiamsha kinywa), lunch in the afternoon (chakula cha mchana) and supper in the evening (chakula cha jioni or known simply as \"chajio\"). In between, they have the 10 o'clock tea (chai ya saa nne) and 4 pm tea (chai ya saa kumi). Breakfast is usually tea or porridge with bread, chapati, mahamri, boiled sweet potatoes or yams. Ugali with vegetables, sour milk, meat, fish or any other stew is generally eaten by much of the population for lunch or supper. Regional variations and dishes also exist.</span><br /><span><b>Question:</b> What time do they normally have tea?</span><br /><span style=\"color:blue\"><b>Answers:</b><br /><ul><li style=\"color:blue\">10 o'clock tea (chai ya saa nne) and 4 pm tea - 10 oclock tea chai ya saa nne and 4 pm tea</li><li style=\"color:blue\">10 o'clock - 10 oclock</li><li style=\"color:blue\">10 o'clock tea (chai ya saa nne) and 4 pm - 10 oclock tea chai ya saa nne and 4 pm</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> 4 pm</span><br /><span style=\"color:green\"><b>Probability:</b> 4.015%</span><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span><b>Context:</b> If the input size is n, the time taken can be expressed as a function of n. Since the time taken on different inputs of the same size can be different, the worst-case time complexity T(n) is defined to be the maximum time taken over all inputs of size n. If T(n) is a polynomial in n, then the algorithm is said to be a polynomial time algorithm. Cobham's thesis says that a problem can be solved with a feasible amount of resources if it admits a polynomial time algorithm.</span><br /><span><b>Question:</b> Assuming that T represents a polynomial in T(n), what is the term given to the corresponding algorithm?</span><br /><span style=\"color:blue\"><b>Answers:</b><br /><ul><li style=\"color:blue\">polynomial time algorithm - polynomial time algorithm</li><li style=\"color:blue\">polynomial time - polynomial time</li><li style=\"color:blue\">polynomial time algorithm - polynomial time algorithm</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> </span><br /><span style=\"color:green\"><b>Probability:</b> 3.532%</span><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span><b>Context:</b> Another important library – the University Library, founded in 1816, is home to over two million items. The building was designed by architects Marek Budzyński and Zbigniew Badowski and opened on 15 December 1999. It is surrounded by green. The University Library garden, designed by Irena Bajerska, was opened on 12 June 2002. It is one of the largest and most beautiful roof gardens in Europe with an area of more than 10,000 m2 (107,639.10 sq ft), and plants covering 5,111 m2 (55,014.35 sq ft). As the university garden it is open to the public every day.</span><br /><span><b>Question:</b> When was the University Library founded?</span><br /><span style=\"color:blue\"><b>Answers:</b><br /><ul><li style=\"color:blue\">1816 - 1816</li><li style=\"color:blue\">1816 - 1816</li><li style=\"color:blue\">1816 - 1816</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> 1816</span><br /><span style=\"color:green\"><b>Probability:</b> 37.463%</span><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span><b>Context:</b> The party, or parties, that hold the majority of seats in the Parliament forms the Scottish Government. In contrast to many other parliamentary systems, Parliament elects a First Minister from a number of candidates at the beginning of each parliamentary term (after a general election). Any member can put their name forward to be First Minister, and a vote is taken by all members of Parliament. Normally, the leader of the largest party is returned as First Minister, and head of the Scottish Government. Theoretically, Parliament also elects the Scottish Ministers who form the government of Scotland and sit in the Scottish cabinet, but such ministers are, in practice, appointed to their roles by the First Minister. Junior ministers, who do not attend cabinet, are also appointed to assist Scottish ministers in their departments. Most ministers and their juniors are drawn from amongst the elected MSPs, with the exception of Scotland's Chief Law Officers: the Lord Advocate and the Solicitor General. Whilst the First Minister chooses the ministers – and may decide to remove them at any time – the formal appointment or dismissal is made by the Sovereign.</span><br /><span><b>Question:</b> Other than Scotland's Chief Law Officer, from whence are most ministers drawn from amongst?</span><br /><span style=\"color:blue\"><b>Answers:</b><br /><ul><li style=\"color:blue\">elected MSPs - elected msps</li><li style=\"color:blue\">the elected MSPs - elected msps</li><li style=\"color:blue\">amongst the elected MSPs - amongst elected msps</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> elected MSPs</span><br /><span style=\"color:green\"><b>Probability:</b> 27.753%</span><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span><b>Context:</b> Following the Cretaceous–Paleogene extinction event, the extinction of the dinosaurs and the wetter climate may have allowed the tropical rainforest to spread out across the continent. From 66–34 Mya, the rainforest extended as far south as 45°. Climate fluctuations during the last 34 million years have allowed savanna regions to expand into the tropics. During the Oligocene, for example, the rainforest spanned a relatively narrow band. It expanded again during the Middle Miocene, then retracted to a mostly inland formation at the last glacial maximum. However, the rainforest still managed to thrive during these glacial periods, allowing for the survival and evolution of a broad diversity of species.</span><br /><span><b>Question:</b> How many degrees south did the Amazon rainforest reach from 66-34 Mya?</span><br /><span style=\"color:blue\"><b>Answers:</b><br /><ul><li style=\"color:blue\">45 - 45</li><li style=\"color:blue\">45° - 45°</li><li style=\"color:blue\">45° - 45°</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> Climate</span><br /><span style=\"color:green\"><b>Probability:</b> 13.697%</span><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span><b>Context:</b> Structural geologists use microscopic analysis of oriented thin sections of geologic samples to observe the fabric within the rocks which gives information about strain within the crystalline structure of the rocks. They also plot and combine measurements of geological structures in order to better understand the orientations of faults and folds in order to reconstruct the history of rock deformation in the area. In addition, they perform analog and numerical experiments of rock deformation in large and small settings.</span><br /><span><b>Question:</b> How do structural geologists observe the fabric within the rocks?</span><br /><span style=\"color:blue\"><b>Answers:</b><br /><ul><li style=\"color:blue\">microscopic analysis of oriented thin sections - microscopic analysis of oriented thin sections</li><li style=\"color:blue\">microscopic analysis - microscopic analysis</li><li style=\"color:blue\">use microscopic analysis of oriented thin sections of geologic samples - use microscopic analysis of oriented thin sections of geologic samples</li></ul></span><br /><span style=\"color:green\"><b>Prediction:</b> gives information about strain</span><br /><span style=\"color:green\"><b>Probability:</b> 32.454%</span><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jXLsXBe_kJD",
        "outputId": "e2299fe2-a5db-4cf8-a262-c8e9861a6aee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        ""
      ],
      "execution_count": 289,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('', [89.63230895996094])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 289
        }
      ]
    }
  ]
}